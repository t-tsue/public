{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-tsue/public/blob/main/PBL02_sample_code_effb6_mix_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArdZhaEEUbtV"
      },
      "source": [
        "# PBL_02 不良箇所自動検出 良否判定モデル構築用サンプルコード\n",
        "\n",
        "このコードはGoogle Colaboratory用に作成しています。\n",
        "\n",
        "当サンプルコードは、PBL02のデジタル課題（演習03）において、課題「出荷検査工程のコスト・負荷がかかり、検品精度にばらつきがある」に対し、出荷検査工程の画像AIモデルの構築と精度検証を目的としたものです。検証の方法論の足掛かりとしてご利用ください。当サンプルコードは以下の流れで構成されています。\n",
        "\n",
        "1. [Googleドライブと接続](#1)</li>\n",
        "    Googleドライブとサンプルコードを接続する。\n",
        "1. [ライブラリimport](#2)</li>\n",
        "    必要なライブラリのimportを行う。\n",
        "1. [パラメータ設定](#3)</li>\n",
        "    画像分類アルゴリズム\"VGG\"に関する設定とデータ、ウェイトのパス設定を行う。\n",
        "1. [VGGのネットワーク定義](#4)</li>\n",
        "    VGGのネットワークを本課題向けにカスタマイズし、カスタマイズしたVGGを宣言する。<br>\n",
        "    具体的には、VGGの基本設定、事前重み有無設定、出力層のカスタマイズを行う。\n",
        "1. [学習・検証データの読み込み](#5)</li>\n",
        "    3. で指定した格納先の学習・検証データを読み込む。\n",
        "1. [モデルの学習](#6)</li>\n",
        "    読み込んだデータを用いてVGGを学習させる。\n",
        "1. [モデルによる判定](#7)</li>\n",
        "    構築したモデルによる判定を実施する。\n",
        "1. [学習・検証データに対する精度評価](#8)</li>\n",
        "    学習・検証データに対する精度をF1-score、Precision、Recallで評価します\n",
        "1. [提出ファイルの出力](#9)</li>\n",
        "    テストデータに対して良否判定を行い、その結果を提出フォーマットであるtsv形式で出力を行う。\n",
        "</ol>\n",
        "\n",
        "\n",
        "\n",
        "使用するデータは以下です。\n",
        "\n",
        "- train_master.tsv\n",
        "- sample_submit.tsv\n",
        "- train フォルダ内の画像データ\n",
        "- test  フォルダ内の画像データ\n",
        "\n",
        "学習ポータル（moodle）からダウンロードし、Google Driveの直下に「DXQuest_PBL02」というフォルダを作成いただき、当該フォルダ内に当ノートブックおよび上記ファイルを配置してください。なお、以下のようなフォルダ構成を前提としています。\n",
        "\n",
        "```\n",
        "DXQuest_PBL02\n",
        "│  PBL02_sample_code.ipynb\n",
        "│  requirements.txt\n",
        "│  参考) データ説明.txt\n",
        "│  train_master.tsv\n",
        "│  sample_submit.tsv\n",
        "│\n",
        "└─train\n",
        "│   └─regular\n",
        "│   │      regular_000.jpeg~regular_099\n",
        "│   │  \n",
        "│   └─potato\n",
        "│   │      potato_000.jpeg~potato_102.jpeg\n",
        "│   │  \n",
        "│   └─horn\n",
        "│   │      horn_000.jpeg~horn_056.jpeg\n",
        "│   │  \n",
        "│   └─bridge\n",
        "│          bridge_000.jpeg~bridge_029.jpeg\n",
        "│  \n",
        "└─test\n",
        "│    000.jpeg ~ 212.jpeg\n",
        "│\n",
        "└─weights\n",
        "\n",
        "```\n",
        "\n",
        "⭐️初学者の方へ<br>\n",
        "わからない単語やエラーメッセージが出た際は、積極的に生成AIを活用してみましょう。\n",
        "\n",
        "生成AI活用ガイド\n",
        "https://lifeistech.notion.site/AI-0dc27ac2252342598a46b6948ff2e683?pvs=74"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Googleドライブと接続\n",
        "学習データなどを読み込めるようにするため、Googleドライブとサンプルコードを接続します。"
      ],
      "metadata": {
        "id": "ue3CS1RtXK0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveに接続できるdriveというモジュールをgoogle.colabというライブラリからインポートする。\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Driveにマウント（接続）する。これにより、Colab上でGoogle Drive内のファイルにアクセスできるようになる。\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Hxr3Vq3-XLQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6742854a-6dd4-4b4e-ec1f-5930a364f7b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説\n",
        "<br>\n",
        "```\n",
        "パッケージ：Pythonにおける「パッケージ」とは、便利なツールの詰め合わせのようなものです。Pythonにはたくさんの機能があって、例えば\n",
        "数学の計算やデータの扱い、グラフを描くことなどができます。でも、そのすべての機能を最初から使うのは難しいので、必要な機能だけを\n",
        "まとめて持ってくる方法がパッケージです。\n",
        "\n",
        "このパッケージを使うためには、まずはpipというコマンドを実行することで、必要なパッケージをインストールします。\n",
        "pipを使うと、Pythonパッケージを簡単にインストールしたり、\n",
        "アンインストールしたり、アップデートすることができます。\n",
        "\n",
        "!pip install パッケージ名\n",
        "\n",
        "でインストールします。\n",
        "```\n",
        "</br>"
      ],
      "metadata": {
        "id": "SsbjS9oRpPdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 各パッケージの名前とバージョンを設定\n",
        "packages = {\n",
        "    \"Keras\": \"2.15.0\",\n",
        "    \"tensorflow\": \"2.15.0\"\n",
        "}\n",
        "\n",
        "# 各パッケージをインストール（依存関係を無視）\n",
        "for package, version in packages.items():\n",
        "    try:\n",
        "        # パッケージをインストール\n",
        "        !pip install {package}=={version} --no-deps -q\n",
        "        # うまく行ったらInstalledと表示\n",
        "        print(f\"Installed {package}=={version}\")\n",
        "    except:\n",
        "        # 失敗すればFailedと表示\n",
        "        print(f\"Failed to install {package}=={version}\")"
      ],
      "metadata": {
        "id": "vMcmLnQHhpDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e731826-110a-4933-9e7c-773d1647dd37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalled Keras==2.15.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalled tensorflow==2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####Google Driveと接続した上で、必要なパッケージも揃い、環境が用意できました。次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "yLlwarqmOvMm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6j1AR-XUbta"
      },
      "source": [
        "## 2. ライブラリimport\n",
        "本サンプルコードで使用するライブラリのバージョンを指定します。<br>\n",
        "便利なプログラムをひとまとめにし、誰でも使いやすい状態にしたものを\"ライブラリ\"と読んでいます。<br>\n",
        "本サンプルコードでは、いくつかの\"ライブラリ\"を使用するため、使用するライブラリが何かをこちらで宣言（import ~~）しています。<br>\n",
        "宣言することでgoogle colaboratoryはどのライブラリを使用するのか認識し、ライブラリのプログラムを使用できるようになります。<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（import）\n",
        "```\n",
        "Pythonにおけるimportとはパッケージを持ってきて使うためのコマンドです。\n",
        "\n",
        "from ~ import ~は、特定のパッケージから、必要な関数などを取り込むための文です。\n",
        "これを使うと、パッケージ全体ではなく、必要な部分だけを使うことができ、コードをすっきりさせるのに役立ちます。\n",
        "\n",
        "たとえば、\n",
        "from tensorflow import keras\n",
        "は、tensorflowというパッケージからkerasというモジュール（特定の機能や役割をもったプログラムをまとめたもの）を\n",
        "インポートするという意味です。\n",
        "```\n"
      ],
      "metadata": {
        "id": "WL9BeDs5tVmZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IsFcSwAeUbta"
      },
      "outputs": [],
      "source": [
        "# 今回使うライブラリをインポートする\n",
        "import os #ファイルの操作ができるライブラリ\n",
        "import glob\n",
        "import cv2 #画像処理をするライブラリ\n",
        "import numpy as np #大量の数字の計算が高速にできるライブラリをnpとしてインポートする\n",
        "import pandas as pd #表形式のデータを扱うためのライブラリをpdとしてインポートする\n",
        "import matplotlib.pyplot as plt #グラフを描画するためのライブラリをpltとしてインポートする\n",
        "from PIL import Image #画像処理のためのライブラリPILから画像の読み込みや保存をするImageモジュールをインポートする\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ") #評価指標を計算するためのライブラリsklearn.metricsから、使用する評価指標の計算モジュールをインポートする\n",
        "\n",
        "# 機械学習のためのツールをインポートする\n",
        "import tensorflow as tf # TensorFlowはAIや機械学習のモデルを作るためのライブラリ\n",
        "from tensorflow import keras # KerasはTensorFlowの中で、簡単にモデルを作るためのモジュール\n",
        "from keras import optimizers # モデルの学習を助ける最適化アルゴリズム（効率的に学習を進めるやり方）を提供するモジュールをインポートする\n",
        "from keras.preprocessing.image import ImageDataGenerator # 画像データの前処理や水増し（データオーギュメンテーション）を行うモジュールをインポートする\n",
        "from keras.models import Sequential, Model # ニューラルネットワークモデルを作るための基本的なツールをインポートする\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Input # 画像データの学習に欠かせない処理（畳み込み層やプーリング層）を作るモジュールをインポートする\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense # 画像データの学習に欠かせない処理（活性化関数やドロップアウト層、全結合層など）を追加するためのモジュールをインポートする\n",
        "from keras import backend as K # Kerasが裏で使っている仕組みにアクセスし、高度な設定やカスタマイズを行うためのモジュールをインポートする\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# from tensorflow.keras.utils import np_utils # クラスの名前を数字のリストに変えるためのモジュールをインポートする\n",
        "from keras.applications.vgg16 import VGG16 # 事前に学習されたVGG16モデルをインポートし、それを使って学習を進める（転移学習）\n",
        "from keras.applications import EfficientNetB6 # 事前に学習されたEFFB6モデルをインポートし、それを使って学習を進める（転移学習）\n",
        "tf.random.set_seed(1) # 実験の結果が毎回同じになるようにする（乱数シードを固定する）\n",
        "plt.style.use('ggplot') # グラフのスタイルを「ggplot」に設定して、視覚的に見やすくする"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####今回使用するライブラリをインポートしました。これにより、ファイルの操作、画像処理、数値計算、データの可視化、機械学習モデルの構築と評価など、さまざまな作業を行う準備が整いました。<br>また、TensorFlowとKerasというライブラリをインポートしたことで、機械学習モデルを簡単に構築・学習できる環境も設定されました。次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "6pvy9OEDPA0y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8E9Kbl0Ubtc"
      },
      "source": [
        "## 3. パラメータ設定\n",
        "画像分類アルゴリズム\"VGG\"に関する設定とデータ・ウェイトのパス設定を行います。<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（アルゴリズム / パラメータ）\n",
        "```\n",
        "アルゴリズムとは、コンピュータがデータからパターンを学んで、新しいデータに対して予測や判断を行うための「ルール」や「計算の手順」のことです。\n",
        "パラメータとは、モデルがデータから学習するための「ルール」や「パターン」を表す値と考えてください。\n",
        "ここでは、入力画像サイズや判定分類数、エポック数、バッチサイズを指定しています。\n",
        "```"
      ],
      "metadata": {
        "id": "bvVCelo0-KSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（エポック数 / バッチサイズ）\n",
        "```\n",
        "エポック数とバッチサイズは、機械学習、特にディープラーニングで使われる言葉です。\n",
        "エポック数は、データを使ってモデルが学習をする回数のことです。\n",
        "バッチサイズは、一度に学習させるデータの量のことです。\n",
        "\n",
        "＜エポック数とバッチサイズの関係＞\n",
        "問題集を解くことに例えると、エポック数は、全部の問題集を何回解くかという「全体の学習回数」。\n",
        "バッチサイズは、一度に解く問題の量という「分けて解く量」。\n",
        "例えば、問題集が100問あり、バッチサイズが10なら、1エポック（問題集全体を1周）には10回の学習ステップが必要です。\n",
        "エポック数が2なら、全体で20回の学習を行います。\n",
        "```"
      ],
      "metadata": {
        "id": "0UeZk1W2emMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（VGG16）\n",
        "```\n",
        "VGG16は、画像の特徴を何層にも分けて分析し、最終的に「この画像は何か？」を判断するための計算の流れ（ネットワーク）です。\n",
        "最初の方では、画像の細かい特徴（色や線）を見つけ、次第にその特徴を組み合わせて、最終的に「これは猫だ」「これは車だ」と判断します。\n",
        "たくさんの「パラメータ」（学習する情報）を使って、コンピュータは正確に物体を見分けることができるようになります。\n",
        "\n",
        "例えば、block1_conv1という名前の層は、VGG16の最初のブロックの中で最初に出てくる畳み込み層です。\n",
        "このように、VGG16は5つのブロックに分かれていて、それぞれが画像を段階的に処理していきます。\n",
        "\n",
        "畳み込み層は、画像の特徴（色や形、線など）を見つける場所です。\n",
        "モデルには、たくさんの畳み込み層があり、それぞれが画像の違った特徴を学びます。たとえば、最初の畳み込み層では、\n",
        "画像の基本的な輪郭を探し、次の層ではもっと細かい部分（耳や目の形など）を探します。\n",
        "```"
      ],
      "metadata": {
        "id": "JKFbBSKuk3V4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f8obf27iUbtd"
      },
      "outputs": [],
      "source": [
        "# 画像分類アルゴリズム\"VGG\"に関する設定をする\n",
        "# 入力画像サイズの高さと幅（サイズを大きくするとより画像の特徴が明らかになり、特徴を学習しやすくなる可能性がある。しかし、学習に要する時間が増えてしまう。\n",
        "IMG_WIDTH, IMG_HEIGHT = 528, 528\n",
        "TARGET_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
        "\n",
        "# 判定分類数（4分類を判定するモデルを構築し、その4つの判別結果を最後に良品、不良品の2分類に変換する前提）\n",
        "NB_CLASSES = 4\n",
        "\n",
        "# 学習時のエポック数\n",
        "# （学習データを何回学習させるかのパラメータ。回数を増やすとその分モデルは学習データの特徴を学習できる\n",
        "# ただし、学習用データに過度に適合しテスト用データには適合しないモデルになる可能性がある。）\n",
        "EPOCHS = 80\n",
        "\n",
        "# バッチサイズ\n",
        "# （一度の学習で何枚の画像データを使用するかというパラメータ。100枚の学習データがあった際にバッチサイズを5とすると、5枚ずつ20回学習することを意味する。\n",
        "# ここで言う\"一度の学習\"とは、VGGモデルを更新するタイミングのことを言う。バッチサイズ5のときは、5枚のデータ毎に更新されることになる。）\n",
        "BATCH_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####画像分類アルゴリズムの準備として、モデルの学習に必要な設定を行いました。<br>画像サイズや分類数、学習の回数（エポック数）、一度に処理するデータの量（バッチサイズ）を指定し、<br>モデルが学習する際の基本条件を決めました。<br>これらの設定により、画像を効率よく処理し、適切に学習できるようにするための土台が整いました。\n",
        "---"
      ],
      "metadata": {
        "id": "osZuxz33Pj6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "画像データがどういう順番で保存されているかを確認しています。\n",
        "channels_firstなら、色が最初に来る → (3, 横幅, 縦幅)\n",
        "channels_lastなら、色が最後に来る → (横幅, 縦幅, 3)\n",
        "この違いを正しく判定することで、画像データを正しい形で機械学習モデルに入力できるようにしています。\n",
        "このコードは、画像を使ってAIモデルを作るときに、画像データがどういう形式で保存されているかに応じて、適切な形を決めるために必要です。\n",
        "```"
      ],
      "metadata": {
        "id": "MEg58Ajrfj6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JtGj7wTTUbtd"
      },
      "outputs": [],
      "source": [
        "# データの形を判定する（色のデータが最初か最後か判定している）\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, IMG_WIDTH, IMG_HEIGHT)\n",
        "else:\n",
        "    input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1jpvB_h-Ubte"
      },
      "outputs": [],
      "source": [
        "# 学習データ保存場所のパスを格納する。bridge, horn, potato, regularのフォルダがあり、各フォルダの中に画像が格納されている想定\n",
        "train_data_dir = '/content/drive/MyDrive/DXQuest_PBL02/train_conv'\n",
        "\n",
        "train_data_dir2 = '/content/drive/MyDrive/DXQuest_PBL02/train'\n",
        "\n",
        "# 検証用データ保存場所のパスを格納する。bridge, horn, potato, regularのフォルダがあり、各フォルダの中に画像が格納されている想定\n",
        "# 本サンプルコードでは、簡便さを重視し、検証用データも学習データと同じものを使用。通常、学習と検証用のデータは任意の割合で分割する\n",
        "validation_data_dir = '/content/drive/MyDrive/DXQuest_PBL02/train_conv'\n",
        "\n",
        "# テストデータ保存場所のパスを格納する。画像データが格納されている想定\n",
        "test_data_dir = '/content/drive/MyDrive/DXQuest_PBL02/test_conv'\n",
        "\n",
        "# 画像分類アルゴリズムのweightファイル保存場所のパスを格納する\n",
        "# モデルの「重み（weight）」とは、モデルが学習を通じて得たパラメータのこと。例えば、画像を「猫」と「犬」に分類するモデルがあったとすると、\n",
        "# 学習を通じて「耳の形」「毛の質感」などの特徴に基づいて分類するルールを学習し、そのルールが重みとして保存される。\n",
        "# これらの重みを保存することで、後でモデルを再利用したり、学習を続けることができる。\n",
        "weight_dir = '/content/drive/MyDrive/DXQuest_PBL02/weights'\n",
        "\n",
        "# weightファイルの名前\n",
        "save_weights_path = os.path.join(weight_dir, 'weights.weights_effb6.h5') # 'weights.h5'のファイル名は変更可"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = list(sorted(glob.glob(os.path.join(train_data_dir, '*/*.jpeg'))))+list(sorted(glob.glob(os.path.join(train_data_dir2, '*/*.jpeg'))))\n",
        "test_files = sorted(glob.glob(os.path.join(test_data_dir, '*.jpeg')))\n",
        "\n",
        "train_df = pd.DataFrame({'x': train_files})\n",
        "test_df = pd.DataFrame({'x': test_files})\n",
        "train_df['y'] = train_df['x'].apply(lambda x: x.split('/')[-2])"
      ],
      "metadata": {
        "id": "FXZoiktIZxGy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####画像データの形式を確認し、学習や検証、テスト用のデータ保存場所を設定しました。また、モデルの重みを保存する場所も指定しました。<br>これにより、モデルの学習や評価に必要なデータの準備と、学習結果の保存が可能になりました。\n",
        "---"
      ],
      "metadata": {
        "id": "LXQhRnz9P0Tg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FwdPDKXUbtg"
      },
      "source": [
        "## 4. VGGのネットワーク定義\n",
        "VGGのネットワークを本課題向けにカスタマイズします。<br>\n",
        "具体的には、VGGの基本設定と事前重みの設定（以下「weights='imagenet'」がこれに相当）、出力層のカスタマイズなどを行います。<br>\n",
        "事前重みの設定とは、あらかじめ様々なデータでVGGを学習させて見つけ出した良いパラメータ値をパラメータの初期値として設定することを意味します。これにより、始めからある程度汎用性のあるモデルになります。\n",
        "更に、今回のデータでこのモデルを学習させることで学習速度を速め、かつ安定したモデルにすることを目指します。<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（ネットワーク）\n",
        "```\n",
        "「ネットワーク」という言葉は、コンピュータがデータを処理するための計算の流れや構造を指しています。VGGでは、画像を何段階にも分けて処理し、\n",
        "最終的にその画像が何かを判断する流れが「ネットワーク」です。\n",
        "\n",
        "VGGネットワークを例えると…\n",
        "VGGネットワークを人間の目に例えると、次のような流れです：\n",
        "\n",
        "最初に画像をざっくり見る（「これは何かの写真だな」）。\n",
        "細かい部分を見て特徴を確認する（「これは耳だ」「これは四角い形だ」）。\n",
        "全体を見て判断する（「耳があるし、丸い形があるから、これは猫だ！」）。\n",
        "コンピュータはこの「画像を見て特徴を見つける」という流れを、VGGネットワークの層を使って行っているのです。\n",
        "\n",
        "つまり、VGGのネットワークは、コンピュータが画像の中から特徴を見つけて、それが何かを判断するための「層を積み重ねた計算の仕組み」です。\n",
        "```\n"
      ],
      "metadata": {
        "id": "aA1FBJkBAQmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "VGG16モデルを設定して、事前に学習された知識を使って画像を分類する準備をしています。\n",
        "・ImageNetで学習された重みを使うことで、モデルはすでに基本的な画像分類ができるようになっています。\n",
        "ImageNetとは、何百万枚もの画像が入ったデータベースで、いろいろな物体（犬、車、花など）を識別できるようにモデルが事前に学習されています。\n",
        "つまり、今回のVGG16はすでに学習された知識を使って画像を分類することを示しています・\n",
        "・include_top=Falseで、モデルの最後の分類部分を外し、自分の用途に合わせてカスタマイズできるようにしています。\n",
        "・画像のサイズを「224×224ピクセルのRGB画像」として設定しています。\n",
        "```"
      ],
      "metadata": {
        "id": "bu3e1jqHgUUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ZVpu08cUbth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd0fe00-beb7-42e7-f1e0-7bba1d9b8d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb6_notop.h5\n",
            "165234480/165234480 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# VGG16という画像分類アルゴリズムの基本モデルの初期設定をする\n",
        "base_model = EfficientNetB6(\n",
        "    # 学習済みの重みを利用する。'imagenet'は、画像データベースImageNetで事前に学習された重みを使う設定。\n",
        "    weights='imagenet',\n",
        "\n",
        "    # モデルの最上位の全結合層（分類を行う部分）を除外する設定。この後、自分で分類層を追加してカスタマイズするために使う。\n",
        "    include_top=False,\n",
        "\n",
        "    # モデルの入力サイズを指定する。ここでは、224x224ピクセルのRGB画像を入力として受け取るように設定している。\n",
        "    input_tensor=Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "summary() の結果を見ると、各レイヤーの形状（サイズやパラメータ数）と順序が確認できます。\n",
        "各層の出力サイズや学習可能なパラメータ数も表示され、モデルの全体像が把握できます。\n",
        "\n",
        "畳み込み層（Conv2D）で画像から特徴を抽出し、プーリング層（MaxPooling2D）で画像を圧縮して、特徴を少しずつ絞り込んでいきます。\n",
        "VGG16には、約1470万個のパラメータがあり、それを使って画像を分類する方法を学びます。\n",
        "データの形は、処理が進むにつれてどんどん小さくなり、最終的には小さな特徴の集まりに変わります。\n",
        "簡単に言うと、VGG16は、画像をたくさんの層で処理しながら、少しずつ「これは何か？」を理解していくモデルです。\n",
        "```"
      ],
      "metadata": {
        "id": "G4VwApCwg60G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "91Lvn-FDUbth",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbcd509-af9f-4fbf-9a2d-faf81385b04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"efficientnetb6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 528, 528, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)       (None, 528, 528, 3)          0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " normalization (Normalizati  (None, 528, 528, 3)          7         ['rescaling[0][0]']           \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " rescaling_1 (Rescaling)     (None, 528, 528, 3)          0         ['normalization[0][0]']       \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding  (None, 529, 529, 3)          0         ['rescaling_1[0][0]']         \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)          (None, 264, 264, 56)         1512      ['stem_conv_pad[0][0]']       \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalizatio  (None, 264, 264, 56)         224       ['stem_conv[0][0]']           \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " stem_activation (Activatio  (None, 264, 264, 56)         0         ['stem_bn[0][0]']             \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseC  (None, 264, 264, 56)         504       ['stem_activation[0][0]']     \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormaliza  (None, 264, 264, 56)         224       ['block1a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1a_activation (Activa  (None, 264, 264, 56)         0         ['block1a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (Global  (None, 56)                   0         ['block1a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshap  (None, 1, 1, 56)             0         ['block1a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)  (None, 1, 1, 14)             798       ['block1a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)  (None, 1, 1, 56)             840       ['block1a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multipl  (None, 264, 264, 56)         0         ['block1a_activation[0][0]',  \n",
            " y)                                                                  'block1a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv  (None, 264, 264, 32)         1792      ['block1a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1b_dwconv (DepthwiseC  (None, 264, 264, 32)         288       ['block1a_project_bn[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1b_bn (BatchNormaliza  (None, 264, 264, 32)         128       ['block1b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1b_activation (Activa  (None, 264, 264, 32)         0         ['block1b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1b_se_squeeze (Global  (None, 32)                   0         ['block1b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1b_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1b_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1b_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1b_se_excite (Multipl  (None, 264, 264, 32)         0         ['block1b_activation[0][0]',  \n",
            " y)                                                                  'block1b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1b_project_conv (Conv  (None, 264, 264, 32)         1024      ['block1b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1b_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1b_drop (Dropout)      (None, 264, 264, 32)         0         ['block1b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1b_add (Add)           (None, 264, 264, 32)         0         ['block1b_drop[0][0]',        \n",
            "                                                                     'block1a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_dwconv (DepthwiseC  (None, 264, 264, 32)         288       ['block1b_add[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1c_bn (BatchNormaliza  (None, 264, 264, 32)         128       ['block1c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1c_activation (Activa  (None, 264, 264, 32)         0         ['block1c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1c_se_squeeze (Global  (None, 32)                   0         ['block1c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1c_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1c_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1c_se_excite (Multipl  (None, 264, 264, 32)         0         ['block1c_activation[0][0]',  \n",
            " y)                                                                  'block1c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1c_project_conv (Conv  (None, 264, 264, 32)         1024      ['block1c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1c_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1c_drop (Dropout)      (None, 264, 264, 32)         0         ['block1c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_add (Add)           (None, 264, 264, 32)         0         ['block1c_drop[0][0]',        \n",
            "                                                                     'block1b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2  (None, 264, 264, 192)        6144      ['block1c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNo  (None, 264, 264, 192)        768       ['block2a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2a_expand_activation   (None, 264, 264, 192)        0         ['block2a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPa  (None, 265, 265, 192)        0         ['block2a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseC  (None, 132, 132, 192)        1728      ['block2a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormaliza  (None, 132, 132, 192)        768       ['block2a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2a_activation (Activa  (None, 132, 132, 192)        0         ['block2a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (Global  (None, 192)                  0         ['block2a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshap  (None, 1, 1, 192)            0         ['block2a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)  (None, 1, 1, 8)              1544      ['block2a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)  (None, 1, 1, 192)            1728      ['block2a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multipl  (None, 132, 132, 192)        0         ['block2a_activation[0][0]',  \n",
            " y)                                                                  'block2a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv  (None, 132, 132, 40)         7680      ['block2a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2b_expand_activation   (None, 132, 132, 240)        0         ['block2b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2b_activation (Activa  (None, 132, 132, 240)        0         ['block2b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (Global  (None, 240)                  0         ['block2b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2b_activation[0][0]',  \n",
            " y)                                                                  'block2b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)      (None, 132, 132, 40)         0         ['block2b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2b_add (Add)           (None, 132, 132, 40)         0         ['block2b_drop[0][0]',        \n",
            "                                                                     'block2a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2c_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2c_expand_activation   (None, 132, 132, 240)        0         ['block2c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2c_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2c_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2c_activation (Activa  (None, 132, 132, 240)        0         ['block2c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2c_se_squeeze (Global  (None, 240)                  0         ['block2c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2c_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2c_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2c_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2c_activation[0][0]',  \n",
            " y)                                                                  'block2c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2c_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2c_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2c_drop (Dropout)      (None, 132, 132, 40)         0         ['block2c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_add (Add)           (None, 132, 132, 40)         0         ['block2c_drop[0][0]',        \n",
            "                                                                     'block2b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2d_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2d_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2d_expand_activation   (None, 132, 132, 240)        0         ['block2d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2d_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2d_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2d_activation (Activa  (None, 132, 132, 240)        0         ['block2d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2d_se_squeeze (Global  (None, 240)                  0         ['block2d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2d_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2d_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2d_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2d_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2d_activation[0][0]',  \n",
            " y)                                                                  'block2d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2d_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2d_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2d_drop (Dropout)      (None, 132, 132, 40)         0         ['block2d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2d_add (Add)           (None, 132, 132, 40)         0         ['block2d_drop[0][0]',        \n",
            "                                                                     'block2c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2e_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2e_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2e_expand_activation   (None, 132, 132, 240)        0         ['block2e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2e_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2e_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2e_activation (Activa  (None, 132, 132, 240)        0         ['block2e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2e_se_squeeze (Global  (None, 240)                  0         ['block2e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2e_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2e_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2e_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2e_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2e_activation[0][0]',  \n",
            " y)                                                                  'block2e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2e_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2e_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2e_drop (Dropout)      (None, 132, 132, 40)         0         ['block2e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2e_add (Add)           (None, 132, 132, 40)         0         ['block2e_drop[0][0]',        \n",
            "                                                                     'block2d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2f_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2f_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2f_expand_activation   (None, 132, 132, 240)        0         ['block2f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2f_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2f_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2f_activation (Activa  (None, 132, 132, 240)        0         ['block2f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2f_se_squeeze (Global  (None, 240)                  0         ['block2f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2f_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2f_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2f_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2f_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2f_activation[0][0]',  \n",
            " y)                                                                  'block2f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2f_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2f_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2f_drop (Dropout)      (None, 132, 132, 40)         0         ['block2f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2f_add (Add)           (None, 132, 132, 40)         0         ['block2f_drop[0][0]',        \n",
            "                                                                     'block2e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block3a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3a_expand_activation   (None, 132, 132, 240)        0         ['block3a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPa  (None, 135, 135, 240)        0         ['block3a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseC  (None, 66, 66, 240)          6000      ['block3a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormaliza  (None, 66, 66, 240)          960       ['block3a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3a_activation (Activa  (None, 66, 66, 240)          0         ['block3a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (Global  (None, 240)                  0         ['block3a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multipl  (None, 66, 66, 240)          0         ['block3a_activation[0][0]',  \n",
            " y)                                                                  'block3a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv  (None, 66, 66, 72)           17280     ['block3a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3b_expand_activation   (None, 66, 66, 432)          0         ['block3b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3b_activation (Activa  (None, 66, 66, 432)          0         ['block3b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (Global  (None, 432)                  0         ['block3b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3b_activation[0][0]',  \n",
            " y)                                                                  'block3b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)      (None, 66, 66, 72)           0         ['block3b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3b_add (Add)           (None, 66, 66, 72)           0         ['block3b_drop[0][0]',        \n",
            "                                                                     'block3a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3c_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3c_expand_activation   (None, 66, 66, 432)          0         ['block3c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3c_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3c_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3c_activation (Activa  (None, 66, 66, 432)          0         ['block3c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3c_se_squeeze (Global  (None, 432)                  0         ['block3c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3c_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3c_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3c_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3c_activation[0][0]',  \n",
            " y)                                                                  'block3c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3c_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3c_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3c_drop (Dropout)      (None, 66, 66, 72)           0         ['block3c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_add (Add)           (None, 66, 66, 72)           0         ['block3c_drop[0][0]',        \n",
            "                                                                     'block3b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3d_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3d_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3d_expand_activation   (None, 66, 66, 432)          0         ['block3d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3d_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3d_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3d_activation (Activa  (None, 66, 66, 432)          0         ['block3d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3d_se_squeeze (Global  (None, 432)                  0         ['block3d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3d_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3d_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3d_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3d_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3d_activation[0][0]',  \n",
            " y)                                                                  'block3d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3d_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3d_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3d_drop (Dropout)      (None, 66, 66, 72)           0         ['block3d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3d_add (Add)           (None, 66, 66, 72)           0         ['block3d_drop[0][0]',        \n",
            "                                                                     'block3c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3e_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3e_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3e_expand_activation   (None, 66, 66, 432)          0         ['block3e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3e_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3e_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3e_activation (Activa  (None, 66, 66, 432)          0         ['block3e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3e_se_squeeze (Global  (None, 432)                  0         ['block3e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3e_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3e_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3e_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3e_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3e_activation[0][0]',  \n",
            " y)                                                                  'block3e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3e_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3e_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3e_drop (Dropout)      (None, 66, 66, 72)           0         ['block3e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3e_add (Add)           (None, 66, 66, 72)           0         ['block3e_drop[0][0]',        \n",
            "                                                                     'block3d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3f_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3f_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3f_expand_activation   (None, 66, 66, 432)          0         ['block3f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3f_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3f_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3f_activation (Activa  (None, 66, 66, 432)          0         ['block3f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3f_se_squeeze (Global  (None, 432)                  0         ['block3f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3f_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3f_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3f_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3f_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3f_activation[0][0]',  \n",
            " y)                                                                  'block3f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3f_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3f_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3f_drop (Dropout)      (None, 66, 66, 72)           0         ['block3f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3f_add (Add)           (None, 66, 66, 72)           0         ['block3f_drop[0][0]',        \n",
            "                                                                     'block3e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block4a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4a_expand_activation   (None, 66, 66, 432)          0         ['block4a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPa  (None, 67, 67, 432)          0         ['block4a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseC  (None, 33, 33, 432)          3888      ['block4a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormaliza  (None, 33, 33, 432)          1728      ['block4a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4a_activation (Activa  (None, 33, 33, 432)          0         ['block4a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (Global  (None, 432)                  0         ['block4a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block4a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block4a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block4a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multipl  (None, 33, 33, 432)          0         ['block4a_activation[0][0]',  \n",
            " y)                                                                  'block4a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv  (None, 33, 33, 144)          62208     ['block4a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4b_expand_activation   (None, 33, 33, 864)          0         ['block4b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4b_activation (Activa  (None, 33, 33, 864)          0         ['block4b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (Global  (None, 864)                  0         ['block4b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4b_activation[0][0]',  \n",
            " y)                                                                  'block4b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)      (None, 33, 33, 144)          0         ['block4b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4b_add (Add)           (None, 33, 33, 144)          0         ['block4b_drop[0][0]',        \n",
            "                                                                     'block4a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4c_expand_activation   (None, 33, 33, 864)          0         ['block4c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4c_activation (Activa  (None, 33, 33, 864)          0         ['block4c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (Global  (None, 864)                  0         ['block4c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4c_activation[0][0]',  \n",
            " y)                                                                  'block4c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)      (None, 33, 33, 144)          0         ['block4c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_add (Add)           (None, 33, 33, 144)          0         ['block4c_drop[0][0]',        \n",
            "                                                                     'block4b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4d_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4d_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4d_expand_activation   (None, 33, 33, 864)          0         ['block4d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4d_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4d_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4d_activation (Activa  (None, 33, 33, 864)          0         ['block4d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4d_se_squeeze (Global  (None, 864)                  0         ['block4d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4d_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4d_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4d_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4d_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4d_activation[0][0]',  \n",
            " y)                                                                  'block4d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4d_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4d_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4d_drop (Dropout)      (None, 33, 33, 144)          0         ['block4d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4d_add (Add)           (None, 33, 33, 144)          0         ['block4d_drop[0][0]',        \n",
            "                                                                     'block4c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4e_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4e_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4e_expand_activation   (None, 33, 33, 864)          0         ['block4e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4e_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4e_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4e_activation (Activa  (None, 33, 33, 864)          0         ['block4e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4e_se_squeeze (Global  (None, 864)                  0         ['block4e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4e_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4e_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4e_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4e_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4e_activation[0][0]',  \n",
            " y)                                                                  'block4e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4e_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4e_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4e_drop (Dropout)      (None, 33, 33, 144)          0         ['block4e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4e_add (Add)           (None, 33, 33, 144)          0         ['block4e_drop[0][0]',        \n",
            "                                                                     'block4d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4f_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4f_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4f_expand_activation   (None, 33, 33, 864)          0         ['block4f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4f_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4f_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4f_activation (Activa  (None, 33, 33, 864)          0         ['block4f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4f_se_squeeze (Global  (None, 864)                  0         ['block4f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4f_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4f_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4f_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4f_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4f_activation[0][0]',  \n",
            " y)                                                                  'block4f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4f_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4f_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4f_drop (Dropout)      (None, 33, 33, 144)          0         ['block4f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4f_add (Add)           (None, 33, 33, 144)          0         ['block4f_drop[0][0]',        \n",
            "                                                                     'block4e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4g_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4g_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4g_expand_activation   (None, 33, 33, 864)          0         ['block4g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4g_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4g_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4g_activation (Activa  (None, 33, 33, 864)          0         ['block4g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4g_se_squeeze (Global  (None, 864)                  0         ['block4g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4g_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4g_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4g_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4g_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4g_activation[0][0]',  \n",
            " y)                                                                  'block4g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4g_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4g_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4g_drop (Dropout)      (None, 33, 33, 144)          0         ['block4g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4g_add (Add)           (None, 33, 33, 144)          0         ['block4g_drop[0][0]',        \n",
            "                                                                     'block4f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4h_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4h_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4h_expand_activation   (None, 33, 33, 864)          0         ['block4h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4h_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4h_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4h_activation (Activa  (None, 33, 33, 864)          0         ['block4h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4h_se_squeeze (Global  (None, 864)                  0         ['block4h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4h_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4h_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4h_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4h_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4h_activation[0][0]',  \n",
            " y)                                                                  'block4h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4h_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4h_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4h_drop (Dropout)      (None, 33, 33, 144)          0         ['block4h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4h_add (Add)           (None, 33, 33, 144)          0         ['block4h_drop[0][0]',        \n",
            "                                                                     'block4g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block5a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5a_expand_activation   (None, 33, 33, 864)          0         ['block5a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseC  (None, 33, 33, 864)          21600     ['block5a_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block5a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5a_activation (Activa  (None, 33, 33, 864)          0         ['block5a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (Global  (None, 864)                  0         ['block5a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block5a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block5a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block5a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multipl  (None, 33, 33, 864)          0         ['block5a_activation[0][0]',  \n",
            " y)                                                                  'block5a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv  (None, 33, 33, 200)          172800    ['block5a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5b_expand_activation   (None, 33, 33, 1200)         0         ['block5b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5b_activation (Activa  (None, 33, 33, 1200)         0         ['block5b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (Global  (None, 1200)                 0         ['block5b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5b_activation[0][0]',  \n",
            " y)                                                                  'block5b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)      (None, 33, 33, 200)          0         ['block5b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5b_add (Add)           (None, 33, 33, 200)          0         ['block5b_drop[0][0]',        \n",
            "                                                                     'block5a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5c_expand_activation   (None, 33, 33, 1200)         0         ['block5c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5c_activation (Activa  (None, 33, 33, 1200)         0         ['block5c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (Global  (None, 1200)                 0         ['block5c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5c_activation[0][0]',  \n",
            " y)                                                                  'block5c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)      (None, 33, 33, 200)          0         ['block5c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_add (Add)           (None, 33, 33, 200)          0         ['block5c_drop[0][0]',        \n",
            "                                                                     'block5b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5d_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5d_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5d_expand_activation   (None, 33, 33, 1200)         0         ['block5d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5d_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5d_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5d_activation (Activa  (None, 33, 33, 1200)         0         ['block5d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5d_se_squeeze (Global  (None, 1200)                 0         ['block5d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5d_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5d_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5d_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5d_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5d_activation[0][0]',  \n",
            " y)                                                                  'block5d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5d_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5d_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5d_drop (Dropout)      (None, 33, 33, 200)          0         ['block5d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5d_add (Add)           (None, 33, 33, 200)          0         ['block5d_drop[0][0]',        \n",
            "                                                                     'block5c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5e_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5e_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5e_expand_activation   (None, 33, 33, 1200)         0         ['block5e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5e_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5e_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5e_activation (Activa  (None, 33, 33, 1200)         0         ['block5e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5e_se_squeeze (Global  (None, 1200)                 0         ['block5e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5e_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5e_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5e_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5e_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5e_activation[0][0]',  \n",
            " y)                                                                  'block5e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5e_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5e_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5e_drop (Dropout)      (None, 33, 33, 200)          0         ['block5e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5e_add (Add)           (None, 33, 33, 200)          0         ['block5e_drop[0][0]',        \n",
            "                                                                     'block5d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5f_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5f_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5f_expand_activation   (None, 33, 33, 1200)         0         ['block5f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5f_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5f_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5f_activation (Activa  (None, 33, 33, 1200)         0         ['block5f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5f_se_squeeze (Global  (None, 1200)                 0         ['block5f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5f_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5f_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5f_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5f_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5f_activation[0][0]',  \n",
            " y)                                                                  'block5f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5f_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5f_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5f_drop (Dropout)      (None, 33, 33, 200)          0         ['block5f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5f_add (Add)           (None, 33, 33, 200)          0         ['block5f_drop[0][0]',        \n",
            "                                                                     'block5e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5g_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5g_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5g_expand_activation   (None, 33, 33, 1200)         0         ['block5g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5g_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5g_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5g_activation (Activa  (None, 33, 33, 1200)         0         ['block5g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5g_se_squeeze (Global  (None, 1200)                 0         ['block5g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5g_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5g_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5g_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5g_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5g_activation[0][0]',  \n",
            " y)                                                                  'block5g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5g_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5g_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5g_drop (Dropout)      (None, 33, 33, 200)          0         ['block5g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5g_add (Add)           (None, 33, 33, 200)          0         ['block5g_drop[0][0]',        \n",
            "                                                                     'block5f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5h_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5h_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5h_expand_activation   (None, 33, 33, 1200)         0         ['block5h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5h_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5h_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5h_activation (Activa  (None, 33, 33, 1200)         0         ['block5h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5h_se_squeeze (Global  (None, 1200)                 0         ['block5h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5h_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5h_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5h_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5h_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5h_activation[0][0]',  \n",
            " y)                                                                  'block5h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5h_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5h_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5h_drop (Dropout)      (None, 33, 33, 200)          0         ['block5h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5h_add (Add)           (None, 33, 33, 200)          0         ['block5h_drop[0][0]',        \n",
            "                                                                     'block5g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block6a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6a_expand_activation   (None, 33, 33, 1200)         0         ['block6a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPa  (None, 37, 37, 1200)         0         ['block6a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseC  (None, 17, 17, 1200)         30000     ['block6a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormaliza  (None, 17, 17, 1200)         4800      ['block6a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6a_activation (Activa  (None, 17, 17, 1200)         0         ['block6a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (Global  (None, 1200)                 0         ['block6a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block6a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block6a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block6a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multipl  (None, 17, 17, 1200)         0         ['block6a_activation[0][0]',  \n",
            " y)                                                                  'block6a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv  (None, 17, 17, 344)          412800    ['block6a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6b_expand_activation   (None, 17, 17, 2064)         0         ['block6b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6b_activation (Activa  (None, 17, 17, 2064)         0         ['block6b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (Global  (None, 2064)                 0         ['block6b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6b_activation[0][0]',  \n",
            " y)                                                                  'block6b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)      (None, 17, 17, 344)          0         ['block6b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6b_add (Add)           (None, 17, 17, 344)          0         ['block6b_drop[0][0]',        \n",
            "                                                                     'block6a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6c_expand_activation   (None, 17, 17, 2064)         0         ['block6c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6c_activation (Activa  (None, 17, 17, 2064)         0         ['block6c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (Global  (None, 2064)                 0         ['block6c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6c_activation[0][0]',  \n",
            " y)                                                                  'block6c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)      (None, 17, 17, 344)          0         ['block6c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_add (Add)           (None, 17, 17, 344)          0         ['block6c_drop[0][0]',        \n",
            "                                                                     'block6b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6d_expand_activation   (None, 17, 17, 2064)         0         ['block6d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6d_activation (Activa  (None, 17, 17, 2064)         0         ['block6d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (Global  (None, 2064)                 0         ['block6d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6d_activation[0][0]',  \n",
            " y)                                                                  'block6d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)      (None, 17, 17, 344)          0         ['block6d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6d_add (Add)           (None, 17, 17, 344)          0         ['block6d_drop[0][0]',        \n",
            "                                                                     'block6c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6e_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6e_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6e_expand_activation   (None, 17, 17, 2064)         0         ['block6e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6e_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6e_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6e_activation (Activa  (None, 17, 17, 2064)         0         ['block6e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6e_se_squeeze (Global  (None, 2064)                 0         ['block6e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6e_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6e_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6e_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6e_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6e_activation[0][0]',  \n",
            " y)                                                                  'block6e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6e_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6e_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6e_drop (Dropout)      (None, 17, 17, 344)          0         ['block6e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6e_add (Add)           (None, 17, 17, 344)          0         ['block6e_drop[0][0]',        \n",
            "                                                                     'block6d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6f_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6f_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6f_expand_activation   (None, 17, 17, 2064)         0         ['block6f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6f_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6f_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6f_activation (Activa  (None, 17, 17, 2064)         0         ['block6f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6f_se_squeeze (Global  (None, 2064)                 0         ['block6f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6f_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6f_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6f_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6f_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6f_activation[0][0]',  \n",
            " y)                                                                  'block6f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6f_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6f_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6f_drop (Dropout)      (None, 17, 17, 344)          0         ['block6f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6f_add (Add)           (None, 17, 17, 344)          0         ['block6f_drop[0][0]',        \n",
            "                                                                     'block6e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6g_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6g_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6g_expand_activation   (None, 17, 17, 2064)         0         ['block6g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6g_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6g_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6g_activation (Activa  (None, 17, 17, 2064)         0         ['block6g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6g_se_squeeze (Global  (None, 2064)                 0         ['block6g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6g_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6g_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6g_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6g_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6g_activation[0][0]',  \n",
            " y)                                                                  'block6g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6g_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6g_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6g_drop (Dropout)      (None, 17, 17, 344)          0         ['block6g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6g_add (Add)           (None, 17, 17, 344)          0         ['block6g_drop[0][0]',        \n",
            "                                                                     'block6f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6h_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6h_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6h_expand_activation   (None, 17, 17, 2064)         0         ['block6h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6h_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6h_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6h_activation (Activa  (None, 17, 17, 2064)         0         ['block6h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6h_se_squeeze (Global  (None, 2064)                 0         ['block6h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6h_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6h_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6h_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6h_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6h_activation[0][0]',  \n",
            " y)                                                                  'block6h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6h_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6h_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6h_drop (Dropout)      (None, 17, 17, 344)          0         ['block6h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6h_add (Add)           (None, 17, 17, 344)          0         ['block6h_drop[0][0]',        \n",
            "                                                                     'block6g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6i_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6i_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6i_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6i_expand_activation   (None, 17, 17, 2064)         0         ['block6i_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6i_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6i_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6i_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6i_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6i_activation (Activa  (None, 17, 17, 2064)         0         ['block6i_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6i_se_squeeze (Global  (None, 2064)                 0         ['block6i_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6i_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6i_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6i_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6i_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6i_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6i_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6i_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6i_activation[0][0]',  \n",
            " y)                                                                  'block6i_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6i_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6i_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6i_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6i_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6i_drop (Dropout)      (None, 17, 17, 344)          0         ['block6i_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6i_add (Add)           (None, 17, 17, 344)          0         ['block6i_drop[0][0]',        \n",
            "                                                                     'block6h_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6j_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6i_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6j_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6j_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6j_expand_activation   (None, 17, 17, 2064)         0         ['block6j_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6j_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6j_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6j_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6j_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6j_activation (Activa  (None, 17, 17, 2064)         0         ['block6j_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6j_se_squeeze (Global  (None, 2064)                 0         ['block6j_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6j_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6j_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6j_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6j_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6j_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6j_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6j_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6j_activation[0][0]',  \n",
            " y)                                                                  'block6j_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6j_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6j_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6j_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6j_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6j_drop (Dropout)      (None, 17, 17, 344)          0         ['block6j_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6j_add (Add)           (None, 17, 17, 344)          0         ['block6j_drop[0][0]',        \n",
            "                                                                     'block6i_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6k_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6j_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6k_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6k_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6k_expand_activation   (None, 17, 17, 2064)         0         ['block6k_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6k_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6k_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6k_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6k_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6k_activation (Activa  (None, 17, 17, 2064)         0         ['block6k_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6k_se_squeeze (Global  (None, 2064)                 0         ['block6k_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6k_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6k_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6k_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6k_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6k_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6k_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6k_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6k_activation[0][0]',  \n",
            " y)                                                                  'block6k_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6k_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6k_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6k_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6k_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6k_drop (Dropout)      (None, 17, 17, 344)          0         ['block6k_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6k_add (Add)           (None, 17, 17, 344)          0         ['block6k_drop[0][0]',        \n",
            "                                                                     'block6j_add[0][0]']         \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6k_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block7a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7a_expand_activation   (None, 17, 17, 2064)         0         ['block7a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseC  (None, 17, 17, 2064)         18576     ['block7a_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block7a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7a_activation (Activa  (None, 17, 17, 2064)         0         ['block7a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (Global  (None, 2064)                 0         ['block7a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block7a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block7a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block7a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block7a_activation[0][0]',  \n",
            " y)                                                                  'block7a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv  (None, 17, 17, 576)          1188864   ['block7a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7b_expand_conv (Conv2  (None, 17, 17, 3456)         1990656   ['block7a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7b_expand_bn (BatchNo  (None, 17, 17, 3456)         13824     ['block7b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7b_expand_activation   (None, 17, 17, 3456)         0         ['block7b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7b_dwconv (DepthwiseC  (None, 17, 17, 3456)         31104     ['block7b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7b_bn (BatchNormaliza  (None, 17, 17, 3456)         13824     ['block7b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7b_activation (Activa  (None, 17, 17, 3456)         0         ['block7b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7b_se_squeeze (Global  (None, 3456)                 0         ['block7b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7b_se_reshape (Reshap  (None, 1, 1, 3456)           0         ['block7b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7b_se_reduce (Conv2D)  (None, 1, 1, 144)            497808    ['block7b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7b_se_expand (Conv2D)  (None, 1, 1, 3456)           501120    ['block7b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7b_se_excite (Multipl  (None, 17, 17, 3456)         0         ['block7b_activation[0][0]',  \n",
            " y)                                                                  'block7b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7b_project_conv (Conv  (None, 17, 17, 576)          1990656   ['block7b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7b_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7b_drop (Dropout)      (None, 17, 17, 576)          0         ['block7b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7b_add (Add)           (None, 17, 17, 576)          0         ['block7b_drop[0][0]',        \n",
            "                                                                     'block7a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_expand_conv (Conv2  (None, 17, 17, 3456)         1990656   ['block7b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7c_expand_bn (BatchNo  (None, 17, 17, 3456)         13824     ['block7c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7c_expand_activation   (None, 17, 17, 3456)         0         ['block7c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7c_dwconv (DepthwiseC  (None, 17, 17, 3456)         31104     ['block7c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7c_bn (BatchNormaliza  (None, 17, 17, 3456)         13824     ['block7c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7c_activation (Activa  (None, 17, 17, 3456)         0         ['block7c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7c_se_squeeze (Global  (None, 3456)                 0         ['block7c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7c_se_reshape (Reshap  (None, 1, 1, 3456)           0         ['block7c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7c_se_reduce (Conv2D)  (None, 1, 1, 144)            497808    ['block7c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_se_expand (Conv2D)  (None, 1, 1, 3456)           501120    ['block7c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7c_se_excite (Multipl  (None, 17, 17, 3456)         0         ['block7c_activation[0][0]',  \n",
            " y)                                                                  'block7c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7c_project_conv (Conv  (None, 17, 17, 576)          1990656   ['block7c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7c_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7c_drop (Dropout)      (None, 17, 17, 576)          0         ['block7c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_add (Add)           (None, 17, 17, 576)          0         ['block7c_drop[0][0]',        \n",
            "                                                                     'block7b_add[0][0]']         \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)           (None, 17, 17, 2304)         1327104   ['block7c_add[0][0]']         \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization  (None, 17, 17, 2304)         9216      ['top_conv[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " top_activation (Activation  (None, 17, 17, 2304)         0         ['top_bn[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 40960143 (156.25 MB)\n",
            "Trainable params: 40735704 (155.39 MB)\n",
            "Non-trainable params: 224439 (876.72 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# ネットワーク構造の確認\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "このコードでは、以下のように画像分類モデルの出力部分をカスタマイズして、特定の課題に合った予測ができるように変更する作業です。\n",
        "ここでは、既存のVGG16というモデルに新しい「出力層」を追加して、自分が分類したいクラス（4種類など）に合わせて、\n",
        "最終的な予測を行う部分を作っています。\n",
        "\n",
        "・VGG16の出力を1列に並べる：まず、画像データを計算しやすい形（1次元）に変換します。\n",
        "・新しい層を追加：512個のノード（計算するパーツ）を持つ層を追加し、ReLUという方法でデータを整理します。\n",
        "・過学習を防ぐためのDropout：50%のノードをランダムに無効にして、学習しすぎを防ぎます。\n",
        "・最終的な出力層を作成：4つのクラスに分類するための出力層を追加し、各クラスの確率を計算します。\n",
        "```"
      ],
      "metadata": {
        "id": "KkrYx1TXZsuZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UR1hJQ2jUbti"
      },
      "outputs": [],
      "source": [
        "# 出力層のカスタマイズ（出力に近い層を本課題に合わせて変更）\n",
        "# ベースモデルの出力を取得する。ここから出力層をカスタマイズする処理を開始する。\n",
        "top_model = base_model.output\n",
        "\n",
        "top_model = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(top_model)\n",
        "top_model = tf.keras.layers.BatchNormalization()(top_model)\n",
        "\n",
        "top_dropout_rate = 0.2\n",
        "top_model = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(top_model)\n",
        "top_model = tf.keras.layers.Dense(NB_CLASSES, activation=\"softmax\", name=\"pred\")(top_model)\n",
        "\n",
        "# まずは次の層が処理しやすいように画像を1画素ずつ並べる\n",
        "#top_model = Flatten(name='flatten')(top_model)\n",
        "\n",
        "# 512個のノード（計算するための小さなパーツ）を持つ新しい層を追加する。\n",
        "# ReLUという方法で、データを次の層に渡す前に、マイナスの値をゼロにして整理する。\n",
        "#top_model = Dense(512, activation='relu')(top_model)\n",
        "\n",
        "# 過学習（学習しすぎて新しいデータでうまく予測できなくなること）を防ぐため、\n",
        "# この層のうち50%のニューロンをランダムに無効にする。\n",
        "#top_model = Dropout(0.5)(top_model)\n",
        "\n",
        "# 最後の出力層を追加する。この層は、最終的な予測結果（4つのクラスのうちどれか）を出力する。\n",
        "# softmaxという方法で、各クラスの確率を計算して出力する。\n",
        "#top_model = Dense(NB_CLASSES, activation='softmax')(top_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HcMTHJol42QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "このコードは、事前に学習されたVGG16モデルと、自分でカスタマイズした新しい出力層を組み合わせて、新しい画像分類モデルを作成するためのものです。\n",
        "さらに、VGG16の部分は固定して、追加した新しい層だけを学習させるようにしています。\n",
        "VGG16の知識を使って、最後の部分だけを今回の目的に合わせてカスタマイズしているということです。\n",
        "```"
      ],
      "metadata": {
        "id": "tqcRLkyyZyxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UI-4FV6VUbti"
      },
      "outputs": [],
      "source": [
        "# ベースモデルとカスタムした出力層を組み合わせて新しいモデルを作成する。\n",
        "def gen_model():\n",
        "  base_model = EfficientNetB6(\n",
        "    # 学習済みの重みを利用する。'imagenet'は、画像データベースImageNetで事前に学習された重みを使う設定。\n",
        "    weights='imagenet',\n",
        "\n",
        "    # モデルの最上位の全結合層（分類を行う部分）を除外する設定。この後、自分で分類層を追加してカスタマイズするために使う。\n",
        "    include_top=False,\n",
        "\n",
        "    # モデルの入力サイズを指定する。ここでは、224x224ピクセルのRGB画像を入力として受け取るように設定している。\n",
        "    input_tensor=Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "  )\n",
        "\n",
        "  top_model = base_model.output\n",
        "  top_model = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(top_model)\n",
        "  top_model = tf.keras.layers.BatchNormalization()(top_model)\n",
        "  top_dropout_rate = 0.2\n",
        "  top_model = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(top_model)\n",
        "  top_model = tf.keras.layers.Dense(NB_CLASSES, activation=\"softmax\", name=\"pred\")(top_model)\n",
        "\n",
        "  model = Model(\n",
        "      # モデルの入力部分を設定する。VGG16の入力部分をそのまま使う。\n",
        "      inputs=base_model.input,\n",
        "      # モデルの出力部分を設定する。先ほどカスタマイズした出力層をここで使う。\n",
        "      outputs=top_model\n",
        "  )\n",
        "\n",
        "  # ベースモデル（VGG16）の各層を繰り返し処理する。\n",
        "  for layer in base_model.layers:\n",
        "\n",
        "      # ベースモデルの層を固定（凍結）して、学習中に重みが更新されないようにする。\n",
        "      # これにより、事前学習された特徴をそのまま利用し、追加した層のみを学習させることができる。\n",
        "      layer.trainable = False\n",
        "  model.compile(\n",
        "    # モデルが学習するときに使用する損失関数を設定する\n",
        "    # 'categorical_crossentropy'は、複数のクラスに分類するための損失関数で、分類がどれだけ正確かを測る指標として使われ、これを元にモデルが変化する\n",
        "    loss='categorical_crossentropy',\n",
        "\n",
        "    # 最適化アルゴリズムと学習率を調整することで、効率的に学習させている\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    # モデルの学習中に計測する指標として、'accuracy'（正解率）を指定する\n",
        "    # これにより、学習過程でどれだけモデルが正確に予測できているかを確認できる\n",
        "    # こちらはユーザの確認用なのでモデルの変更には影響しない\n",
        "    metrics=['accuracy'],\n",
        "  )\n",
        "  return model\n",
        "\n",
        "model = gen_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "このコードは、VGGモデルがどのように学習するかを定義する部分です。簡単に言うと、モデルが「学習する方法」を決めています。\n",
        "この設定によって、モデルがデータを見て、どのように改善していくかを指示しています。\n",
        "\n",
        "・損失関数（categorical_crossentropy）：モデルが学習する際に、予測の誤差（どれだけ間違っているか）を計算し、誤差を小さくするように調整します。\n",
        "これは、複数のクラスに分類するために使われます。\n",
        "・最適化アルゴリズム（RMSprop）：モデルが学習していく際に、データを見ながらどうやって調整していくかを決める方法です。\n",
        "・指標（accuracy）：モデルがどれだけ正しく予測できているかを測るための指標で、学習の進行状況を確認するために使われます。\n",
        "```"
      ],
      "metadata": {
        "id": "n86VXfZHZ4qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UZDR-BDkUbti"
      },
      "outputs": [],
      "source": [
        "# VGGモデルの学習方法を定義する\n",
        "model.compile(\n",
        "    # モデルが学習するときに使用する損失関数を設定する\n",
        "    # 'categorical_crossentropy'は、複数のクラスに分類するための損失関数で、分類がどれだけ正確かを測る指標として使われ、これを元にモデルが変化する\n",
        "    loss='categorical_crossentropy',\n",
        "\n",
        "    # 最適化アルゴリズムと学習率を調整することで、効率的に学習させている\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "\n",
        "    # モデルの学習中に計測する指標として、'accuracy'（正解率）を指定する\n",
        "    # これにより、学習過程でどれだけモデルが正確に予測できているかを確認できる\n",
        "    # こちらはユーザの確認用なのでモデルの変更には影響しない\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコードの解説\n",
        "```\n",
        "新しい画像分類モデルのネットワーク構造を確認するコードです。\n",
        "新しいモデルでは、VGG16に加えて、新しい全結合層（denseとdense_1）が追加されています。\n",
        "具体的には、512ユニットの全結合層と、最終的に4クラスに分類するための出力層（dense_1）があります。\n",
        "また、Dropout層も追加されて、過学習を防ぐ工夫がされています。\n",
        "```"
      ],
      "metadata": {
        "id": "X28zvMdOZ9bH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cpe8gzfsUbti",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e935167-f107-414c-fab3-c0b5b8893d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 528, 528, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " rescaling_2 (Rescaling)     (None, 528, 528, 3)          0         ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " normalization_1 (Normaliza  (None, 528, 528, 3)          7         ['rescaling_2[0][0]']         \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " rescaling_3 (Rescaling)     (None, 528, 528, 3)          0         ['normalization_1[0][0]']     \n",
            "                                                                                                  \n",
            " stem_conv_pad (ZeroPadding  (None, 529, 529, 3)          0         ['rescaling_3[0][0]']         \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)          (None, 264, 264, 56)         1512      ['stem_conv_pad[0][0]']       \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalizatio  (None, 264, 264, 56)         224       ['stem_conv[0][0]']           \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " stem_activation (Activatio  (None, 264, 264, 56)         0         ['stem_bn[0][0]']             \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block1a_dwconv (DepthwiseC  (None, 264, 264, 56)         504       ['stem_activation[0][0]']     \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1a_bn (BatchNormaliza  (None, 264, 264, 56)         224       ['block1a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1a_activation (Activa  (None, 264, 264, 56)         0         ['block1a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1a_se_squeeze (Global  (None, 56)                   0         ['block1a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1a_se_reshape (Reshap  (None, 1, 1, 56)             0         ['block1a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1a_se_reduce (Conv2D)  (None, 1, 1, 14)             798       ['block1a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1a_se_expand (Conv2D)  (None, 1, 1, 56)             840       ['block1a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1a_se_excite (Multipl  (None, 264, 264, 56)         0         ['block1a_activation[0][0]',  \n",
            " y)                                                                  'block1a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv  (None, 264, 264, 32)         1792      ['block1a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1b_dwconv (DepthwiseC  (None, 264, 264, 32)         288       ['block1a_project_bn[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1b_bn (BatchNormaliza  (None, 264, 264, 32)         128       ['block1b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1b_activation (Activa  (None, 264, 264, 32)         0         ['block1b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1b_se_squeeze (Global  (None, 32)                   0         ['block1b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1b_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1b_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1b_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1b_se_excite (Multipl  (None, 264, 264, 32)         0         ['block1b_activation[0][0]',  \n",
            " y)                                                                  'block1b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1b_project_conv (Conv  (None, 264, 264, 32)         1024      ['block1b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1b_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1b_drop (Dropout)      (None, 264, 264, 32)         0         ['block1b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1b_add (Add)           (None, 264, 264, 32)         0         ['block1b_drop[0][0]',        \n",
            "                                                                     'block1a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_dwconv (DepthwiseC  (None, 264, 264, 32)         288       ['block1b_add[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block1c_bn (BatchNormaliza  (None, 264, 264, 32)         128       ['block1c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1c_activation (Activa  (None, 264, 264, 32)         0         ['block1c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block1c_se_squeeze (Global  (None, 32)                   0         ['block1c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block1c_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block1c_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block1c_se_excite (Multipl  (None, 264, 264, 32)         0         ['block1c_activation[0][0]',  \n",
            " y)                                                                  'block1c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block1c_project_conv (Conv  (None, 264, 264, 32)         1024      ['block1c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block1c_project_bn (BatchN  (None, 264, 264, 32)         128       ['block1c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block1c_drop (Dropout)      (None, 264, 264, 32)         0         ['block1c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block1c_add (Add)           (None, 264, 264, 32)         0         ['block1c_drop[0][0]',        \n",
            "                                                                     'block1b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2  (None, 264, 264, 192)        6144      ['block1c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNo  (None, 264, 264, 192)        768       ['block2a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2a_expand_activation   (None, 264, 264, 192)        0         ['block2a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2a_dwconv_pad (ZeroPa  (None, 265, 265, 192)        0         ['block2a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block2a_dwconv (DepthwiseC  (None, 132, 132, 192)        1728      ['block2a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block2a_bn (BatchNormaliza  (None, 132, 132, 192)        768       ['block2a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2a_activation (Activa  (None, 132, 132, 192)        0         ['block2a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2a_se_squeeze (Global  (None, 192)                  0         ['block2a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2a_se_reshape (Reshap  (None, 1, 1, 192)            0         ['block2a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2a_se_reduce (Conv2D)  (None, 1, 1, 8)              1544      ['block2a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2a_se_expand (Conv2D)  (None, 1, 1, 192)            1728      ['block2a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2a_se_excite (Multipl  (None, 132, 132, 192)        0         ['block2a_activation[0][0]',  \n",
            " y)                                                                  'block2a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv  (None, 132, 132, 40)         7680      ['block2a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2b_expand_activation   (None, 132, 132, 240)        0         ['block2b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2b_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2b_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2b_activation (Activa  (None, 132, 132, 240)        0         ['block2b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2b_se_squeeze (Global  (None, 240)                  0         ['block2b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2b_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2b_activation[0][0]',  \n",
            " y)                                                                  'block2b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)      (None, 132, 132, 40)         0         ['block2b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2b_add (Add)           (None, 132, 132, 40)         0         ['block2b_drop[0][0]',        \n",
            "                                                                     'block2a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2c_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2c_expand_activation   (None, 132, 132, 240)        0         ['block2c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2c_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2c_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2c_activation (Activa  (None, 132, 132, 240)        0         ['block2c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2c_se_squeeze (Global  (None, 240)                  0         ['block2c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2c_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2c_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2c_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2c_activation[0][0]',  \n",
            " y)                                                                  'block2c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2c_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2c_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2c_drop (Dropout)      (None, 132, 132, 40)         0         ['block2c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2c_add (Add)           (None, 132, 132, 40)         0         ['block2c_drop[0][0]',        \n",
            "                                                                     'block2b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2d_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2d_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2d_expand_activation   (None, 132, 132, 240)        0         ['block2d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2d_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2d_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2d_activation (Activa  (None, 132, 132, 240)        0         ['block2d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2d_se_squeeze (Global  (None, 240)                  0         ['block2d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2d_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2d_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2d_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2d_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2d_activation[0][0]',  \n",
            " y)                                                                  'block2d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2d_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2d_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2d_drop (Dropout)      (None, 132, 132, 40)         0         ['block2d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2d_add (Add)           (None, 132, 132, 40)         0         ['block2d_drop[0][0]',        \n",
            "                                                                     'block2c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2e_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2e_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2e_expand_activation   (None, 132, 132, 240)        0         ['block2e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2e_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2e_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2e_activation (Activa  (None, 132, 132, 240)        0         ['block2e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2e_se_squeeze (Global  (None, 240)                  0         ['block2e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2e_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2e_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2e_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2e_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2e_activation[0][0]',  \n",
            " y)                                                                  'block2e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2e_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2e_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2e_drop (Dropout)      (None, 132, 132, 40)         0         ['block2e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2e_add (Add)           (None, 132, 132, 40)         0         ['block2e_drop[0][0]',        \n",
            "                                                                     'block2d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block2f_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block2f_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block2f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block2f_expand_activation   (None, 132, 132, 240)        0         ['block2f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block2f_dwconv (DepthwiseC  (None, 132, 132, 240)        2160      ['block2f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block2f_bn (BatchNormaliza  (None, 132, 132, 240)        960       ['block2f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2f_activation (Activa  (None, 132, 132, 240)        0         ['block2f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block2f_se_squeeze (Global  (None, 240)                  0         ['block2f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block2f_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block2f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block2f_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block2f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block2f_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block2f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block2f_se_excite (Multipl  (None, 132, 132, 240)        0         ['block2f_activation[0][0]',  \n",
            " y)                                                                  'block2f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block2f_project_conv (Conv  (None, 132, 132, 40)         9600      ['block2f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2f_project_bn (BatchN  (None, 132, 132, 40)         160       ['block2f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block2f_drop (Dropout)      (None, 132, 132, 40)         0         ['block2f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block2f_add (Add)           (None, 132, 132, 40)         0         ['block2f_drop[0][0]',        \n",
            "                                                                     'block2e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2  (None, 132, 132, 240)        9600      ['block2f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNo  (None, 132, 132, 240)        960       ['block3a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3a_expand_activation   (None, 132, 132, 240)        0         ['block3a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3a_dwconv_pad (ZeroPa  (None, 135, 135, 240)        0         ['block3a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block3a_dwconv (DepthwiseC  (None, 66, 66, 240)          6000      ['block3a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block3a_bn (BatchNormaliza  (None, 66, 66, 240)          960       ['block3a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3a_activation (Activa  (None, 66, 66, 240)          0         ['block3a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3a_se_squeeze (Global  (None, 240)                  0         ['block3a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3a_se_excite (Multipl  (None, 66, 66, 240)          0         ['block3a_activation[0][0]',  \n",
            " y)                                                                  'block3a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv  (None, 66, 66, 72)           17280     ['block3a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3b_expand_activation   (None, 66, 66, 432)          0         ['block3b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3b_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3b_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3b_activation (Activa  (None, 66, 66, 432)          0         ['block3b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3b_se_squeeze (Global  (None, 432)                  0         ['block3b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3b_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3b_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3b_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3b_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3b_activation[0][0]',  \n",
            " y)                                                                  'block3b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)      (None, 66, 66, 72)           0         ['block3b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3b_add (Add)           (None, 66, 66, 72)           0         ['block3b_drop[0][0]',        \n",
            "                                                                     'block3a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3c_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3c_expand_activation   (None, 66, 66, 432)          0         ['block3c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3c_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3c_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3c_activation (Activa  (None, 66, 66, 432)          0         ['block3c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3c_se_squeeze (Global  (None, 432)                  0         ['block3c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3c_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3c_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3c_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3c_activation[0][0]',  \n",
            " y)                                                                  'block3c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3c_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3c_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3c_drop (Dropout)      (None, 66, 66, 72)           0         ['block3c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3c_add (Add)           (None, 66, 66, 72)           0         ['block3c_drop[0][0]',        \n",
            "                                                                     'block3b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3d_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3d_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3d_expand_activation   (None, 66, 66, 432)          0         ['block3d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3d_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3d_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3d_activation (Activa  (None, 66, 66, 432)          0         ['block3d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3d_se_squeeze (Global  (None, 432)                  0         ['block3d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3d_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3d_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3d_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3d_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3d_activation[0][0]',  \n",
            " y)                                                                  'block3d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3d_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3d_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3d_drop (Dropout)      (None, 66, 66, 72)           0         ['block3d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3d_add (Add)           (None, 66, 66, 72)           0         ['block3d_drop[0][0]',        \n",
            "                                                                     'block3c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3e_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3e_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3e_expand_activation   (None, 66, 66, 432)          0         ['block3e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3e_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3e_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3e_activation (Activa  (None, 66, 66, 432)          0         ['block3e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3e_se_squeeze (Global  (None, 432)                  0         ['block3e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3e_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3e_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3e_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3e_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3e_activation[0][0]',  \n",
            " y)                                                                  'block3e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3e_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3e_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3e_drop (Dropout)      (None, 66, 66, 72)           0         ['block3e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3e_add (Add)           (None, 66, 66, 72)           0         ['block3e_drop[0][0]',        \n",
            "                                                                     'block3d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block3f_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block3f_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block3f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block3f_expand_activation   (None, 66, 66, 432)          0         ['block3f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block3f_dwconv (DepthwiseC  (None, 66, 66, 432)          10800     ['block3f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block3f_bn (BatchNormaliza  (None, 66, 66, 432)          1728      ['block3f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3f_activation (Activa  (None, 66, 66, 432)          0         ['block3f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block3f_se_squeeze (Global  (None, 432)                  0         ['block3f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block3f_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block3f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block3f_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block3f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block3f_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block3f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block3f_se_excite (Multipl  (None, 66, 66, 432)          0         ['block3f_activation[0][0]',  \n",
            " y)                                                                  'block3f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block3f_project_conv (Conv  (None, 66, 66, 72)           31104     ['block3f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3f_project_bn (BatchN  (None, 66, 66, 72)           288       ['block3f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block3f_drop (Dropout)      (None, 66, 66, 72)           0         ['block3f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block3f_add (Add)           (None, 66, 66, 72)           0         ['block3f_drop[0][0]',        \n",
            "                                                                     'block3e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2  (None, 66, 66, 432)          31104     ['block3f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNo  (None, 66, 66, 432)          1728      ['block4a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4a_expand_activation   (None, 66, 66, 432)          0         ['block4a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4a_dwconv_pad (ZeroPa  (None, 67, 67, 432)          0         ['block4a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block4a_dwconv (DepthwiseC  (None, 33, 33, 432)          3888      ['block4a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormaliza  (None, 33, 33, 432)          1728      ['block4a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4a_activation (Activa  (None, 33, 33, 432)          0         ['block4a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (Global  (None, 432)                  0         ['block4a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshap  (None, 1, 1, 432)            0         ['block4a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)  (None, 1, 1, 18)             7794      ['block4a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)  (None, 1, 1, 432)            8208      ['block4a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multipl  (None, 33, 33, 432)          0         ['block4a_activation[0][0]',  \n",
            " y)                                                                  'block4a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv  (None, 33, 33, 144)          62208     ['block4a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4b_expand_activation   (None, 33, 33, 864)          0         ['block4b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4b_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4b_activation (Activa  (None, 33, 33, 864)          0         ['block4b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (Global  (None, 864)                  0         ['block4b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4b_activation[0][0]',  \n",
            " y)                                                                  'block4b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)      (None, 33, 33, 144)          0         ['block4b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4b_add (Add)           (None, 33, 33, 144)          0         ['block4b_drop[0][0]',        \n",
            "                                                                     'block4a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4c_expand_activation   (None, 33, 33, 864)          0         ['block4c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4c_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4c_activation (Activa  (None, 33, 33, 864)          0         ['block4c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (Global  (None, 864)                  0         ['block4c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4c_activation[0][0]',  \n",
            " y)                                                                  'block4c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)      (None, 33, 33, 144)          0         ['block4c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4c_add (Add)           (None, 33, 33, 144)          0         ['block4c_drop[0][0]',        \n",
            "                                                                     'block4b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4d_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4d_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4d_expand_activation   (None, 33, 33, 864)          0         ['block4d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4d_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4d_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4d_activation (Activa  (None, 33, 33, 864)          0         ['block4d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4d_se_squeeze (Global  (None, 864)                  0         ['block4d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4d_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4d_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4d_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4d_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4d_activation[0][0]',  \n",
            " y)                                                                  'block4d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4d_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4d_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4d_drop (Dropout)      (None, 33, 33, 144)          0         ['block4d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4d_add (Add)           (None, 33, 33, 144)          0         ['block4d_drop[0][0]',        \n",
            "                                                                     'block4c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4e_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4e_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4e_expand_activation   (None, 33, 33, 864)          0         ['block4e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4e_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4e_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4e_activation (Activa  (None, 33, 33, 864)          0         ['block4e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4e_se_squeeze (Global  (None, 864)                  0         ['block4e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4e_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4e_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4e_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4e_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4e_activation[0][0]',  \n",
            " y)                                                                  'block4e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4e_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4e_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4e_drop (Dropout)      (None, 33, 33, 144)          0         ['block4e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4e_add (Add)           (None, 33, 33, 144)          0         ['block4e_drop[0][0]',        \n",
            "                                                                     'block4d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4f_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4f_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4f_expand_activation   (None, 33, 33, 864)          0         ['block4f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4f_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4f_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4f_activation (Activa  (None, 33, 33, 864)          0         ['block4f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4f_se_squeeze (Global  (None, 864)                  0         ['block4f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4f_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4f_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4f_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4f_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4f_activation[0][0]',  \n",
            " y)                                                                  'block4f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4f_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4f_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4f_drop (Dropout)      (None, 33, 33, 144)          0         ['block4f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4f_add (Add)           (None, 33, 33, 144)          0         ['block4f_drop[0][0]',        \n",
            "                                                                     'block4e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4g_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4g_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4g_expand_activation   (None, 33, 33, 864)          0         ['block4g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4g_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4g_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4g_activation (Activa  (None, 33, 33, 864)          0         ['block4g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4g_se_squeeze (Global  (None, 864)                  0         ['block4g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4g_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4g_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4g_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4g_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4g_activation[0][0]',  \n",
            " y)                                                                  'block4g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4g_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4g_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4g_drop (Dropout)      (None, 33, 33, 144)          0         ['block4g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4g_add (Add)           (None, 33, 33, 144)          0         ['block4g_drop[0][0]',        \n",
            "                                                                     'block4f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block4h_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block4h_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block4h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block4h_expand_activation   (None, 33, 33, 864)          0         ['block4h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block4h_dwconv (DepthwiseC  (None, 33, 33, 864)          7776      ['block4h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block4h_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block4h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4h_activation (Activa  (None, 33, 33, 864)          0         ['block4h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block4h_se_squeeze (Global  (None, 864)                  0         ['block4h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block4h_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block4h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block4h_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block4h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block4h_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block4h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block4h_se_excite (Multipl  (None, 33, 33, 864)          0         ['block4h_activation[0][0]',  \n",
            " y)                                                                  'block4h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block4h_project_conv (Conv  (None, 33, 33, 144)          124416    ['block4h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4h_project_bn (BatchN  (None, 33, 33, 144)          576       ['block4h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block4h_drop (Dropout)      (None, 33, 33, 144)          0         ['block4h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block4h_add (Add)           (None, 33, 33, 144)          0         ['block4h_drop[0][0]',        \n",
            "                                                                     'block4g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2  (None, 33, 33, 864)          124416    ['block4h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNo  (None, 33, 33, 864)          3456      ['block5a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5a_expand_activation   (None, 33, 33, 864)          0         ['block5a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5a_dwconv (DepthwiseC  (None, 33, 33, 864)          21600     ['block5a_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormaliza  (None, 33, 33, 864)          3456      ['block5a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5a_activation (Activa  (None, 33, 33, 864)          0         ['block5a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (Global  (None, 864)                  0         ['block5a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshap  (None, 1, 1, 864)            0         ['block5a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)  (None, 1, 1, 36)             31140     ['block5a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)  (None, 1, 1, 864)            31968     ['block5a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multipl  (None, 33, 33, 864)          0         ['block5a_activation[0][0]',  \n",
            " y)                                                                  'block5a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv  (None, 33, 33, 200)          172800    ['block5a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5b_expand_activation   (None, 33, 33, 1200)         0         ['block5b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5b_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5b_activation (Activa  (None, 33, 33, 1200)         0         ['block5b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (Global  (None, 1200)                 0         ['block5b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5b_activation[0][0]',  \n",
            " y)                                                                  'block5b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)      (None, 33, 33, 200)          0         ['block5b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5b_add (Add)           (None, 33, 33, 200)          0         ['block5b_drop[0][0]',        \n",
            "                                                                     'block5a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5c_expand_activation   (None, 33, 33, 1200)         0         ['block5c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5c_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5c_activation (Activa  (None, 33, 33, 1200)         0         ['block5c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (Global  (None, 1200)                 0         ['block5c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5c_activation[0][0]',  \n",
            " y)                                                                  'block5c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)      (None, 33, 33, 200)          0         ['block5c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5c_add (Add)           (None, 33, 33, 200)          0         ['block5c_drop[0][0]',        \n",
            "                                                                     'block5b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5d_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5d_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5d_expand_activation   (None, 33, 33, 1200)         0         ['block5d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5d_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5d_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5d_activation (Activa  (None, 33, 33, 1200)         0         ['block5d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5d_se_squeeze (Global  (None, 1200)                 0         ['block5d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5d_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5d_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5d_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5d_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5d_activation[0][0]',  \n",
            " y)                                                                  'block5d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5d_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5d_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5d_drop (Dropout)      (None, 33, 33, 200)          0         ['block5d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5d_add (Add)           (None, 33, 33, 200)          0         ['block5d_drop[0][0]',        \n",
            "                                                                     'block5c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5e_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5e_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5e_expand_activation   (None, 33, 33, 1200)         0         ['block5e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5e_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5e_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5e_activation (Activa  (None, 33, 33, 1200)         0         ['block5e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5e_se_squeeze (Global  (None, 1200)                 0         ['block5e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5e_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5e_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5e_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5e_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5e_activation[0][0]',  \n",
            " y)                                                                  'block5e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5e_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5e_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5e_drop (Dropout)      (None, 33, 33, 200)          0         ['block5e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5e_add (Add)           (None, 33, 33, 200)          0         ['block5e_drop[0][0]',        \n",
            "                                                                     'block5d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5f_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5f_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5f_expand_activation   (None, 33, 33, 1200)         0         ['block5f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5f_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5f_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5f_activation (Activa  (None, 33, 33, 1200)         0         ['block5f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5f_se_squeeze (Global  (None, 1200)                 0         ['block5f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5f_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5f_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5f_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5f_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5f_activation[0][0]',  \n",
            " y)                                                                  'block5f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5f_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5f_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5f_drop (Dropout)      (None, 33, 33, 200)          0         ['block5f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5f_add (Add)           (None, 33, 33, 200)          0         ['block5f_drop[0][0]',        \n",
            "                                                                     'block5e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5g_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5g_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5g_expand_activation   (None, 33, 33, 1200)         0         ['block5g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5g_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5g_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5g_activation (Activa  (None, 33, 33, 1200)         0         ['block5g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5g_se_squeeze (Global  (None, 1200)                 0         ['block5g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5g_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5g_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5g_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5g_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5g_activation[0][0]',  \n",
            " y)                                                                  'block5g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5g_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5g_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5g_drop (Dropout)      (None, 33, 33, 200)          0         ['block5g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5g_add (Add)           (None, 33, 33, 200)          0         ['block5g_drop[0][0]',        \n",
            "                                                                     'block5f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block5h_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block5h_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block5h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block5h_expand_activation   (None, 33, 33, 1200)         0         ['block5h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block5h_dwconv (DepthwiseC  (None, 33, 33, 1200)         30000     ['block5h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block5h_bn (BatchNormaliza  (None, 33, 33, 1200)         4800      ['block5h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5h_activation (Activa  (None, 33, 33, 1200)         0         ['block5h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block5h_se_squeeze (Global  (None, 1200)                 0         ['block5h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block5h_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block5h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block5h_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block5h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block5h_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block5h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block5h_se_excite (Multipl  (None, 33, 33, 1200)         0         ['block5h_activation[0][0]',  \n",
            " y)                                                                  'block5h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block5h_project_conv (Conv  (None, 33, 33, 200)          240000    ['block5h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5h_project_bn (BatchN  (None, 33, 33, 200)          800       ['block5h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block5h_drop (Dropout)      (None, 33, 33, 200)          0         ['block5h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block5h_add (Add)           (None, 33, 33, 200)          0         ['block5h_drop[0][0]',        \n",
            "                                                                     'block5g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2  (None, 33, 33, 1200)         240000    ['block5h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNo  (None, 33, 33, 1200)         4800      ['block6a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6a_expand_activation   (None, 33, 33, 1200)         0         ['block6a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6a_dwconv_pad (ZeroPa  (None, 37, 37, 1200)         0         ['block6a_expand_activation[0]\n",
            " dding2D)                                                           [0]']                         \n",
            "                                                                                                  \n",
            " block6a_dwconv (DepthwiseC  (None, 17, 17, 1200)         30000     ['block6a_dwconv_pad[0][0]']  \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormaliza  (None, 17, 17, 1200)         4800      ['block6a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6a_activation (Activa  (None, 17, 17, 1200)         0         ['block6a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (Global  (None, 1200)                 0         ['block6a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshap  (None, 1, 1, 1200)           0         ['block6a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)  (None, 1, 1, 50)             60050     ['block6a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)  (None, 1, 1, 1200)           61200     ['block6a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multipl  (None, 17, 17, 1200)         0         ['block6a_activation[0][0]',  \n",
            " y)                                                                  'block6a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv  (None, 17, 17, 344)          412800    ['block6a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6b_expand_activation   (None, 17, 17, 2064)         0         ['block6b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6b_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6b_activation (Activa  (None, 17, 17, 2064)         0         ['block6b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (Global  (None, 2064)                 0         ['block6b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6b_activation[0][0]',  \n",
            " y)                                                                  'block6b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)      (None, 17, 17, 344)          0         ['block6b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6b_add (Add)           (None, 17, 17, 344)          0         ['block6b_drop[0][0]',        \n",
            "                                                                     'block6a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6c_expand_activation   (None, 17, 17, 2064)         0         ['block6c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6c_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6c_activation (Activa  (None, 17, 17, 2064)         0         ['block6c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (Global  (None, 2064)                 0         ['block6c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6c_activation[0][0]',  \n",
            " y)                                                                  'block6c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)      (None, 17, 17, 344)          0         ['block6c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6c_add (Add)           (None, 17, 17, 344)          0         ['block6c_drop[0][0]',        \n",
            "                                                                     'block6b_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6c_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6d_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6d_expand_activation   (None, 17, 17, 2064)         0         ['block6d_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6d_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6d_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6d_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6d_activation (Activa  (None, 17, 17, 2064)         0         ['block6d_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (Global  (None, 2064)                 0         ['block6d_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6d_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6d_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6d_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6d_activation[0][0]',  \n",
            " y)                                                                  'block6d_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6d_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6d_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)      (None, 17, 17, 344)          0         ['block6d_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6d_add (Add)           (None, 17, 17, 344)          0         ['block6d_drop[0][0]',        \n",
            "                                                                     'block6c_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6e_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6d_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6e_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6e_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6e_expand_activation   (None, 17, 17, 2064)         0         ['block6e_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6e_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6e_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6e_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6e_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6e_activation (Activa  (None, 17, 17, 2064)         0         ['block6e_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6e_se_squeeze (Global  (None, 2064)                 0         ['block6e_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6e_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6e_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6e_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6e_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6e_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6e_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6e_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6e_activation[0][0]',  \n",
            " y)                                                                  'block6e_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6e_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6e_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6e_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6e_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6e_drop (Dropout)      (None, 17, 17, 344)          0         ['block6e_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6e_add (Add)           (None, 17, 17, 344)          0         ['block6e_drop[0][0]',        \n",
            "                                                                     'block6d_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6f_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6e_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6f_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6f_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6f_expand_activation   (None, 17, 17, 2064)         0         ['block6f_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6f_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6f_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6f_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6f_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6f_activation (Activa  (None, 17, 17, 2064)         0         ['block6f_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6f_se_squeeze (Global  (None, 2064)                 0         ['block6f_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6f_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6f_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6f_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6f_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6f_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6f_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6f_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6f_activation[0][0]',  \n",
            " y)                                                                  'block6f_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6f_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6f_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6f_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6f_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6f_drop (Dropout)      (None, 17, 17, 344)          0         ['block6f_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6f_add (Add)           (None, 17, 17, 344)          0         ['block6f_drop[0][0]',        \n",
            "                                                                     'block6e_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6g_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6f_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6g_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6g_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6g_expand_activation   (None, 17, 17, 2064)         0         ['block6g_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6g_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6g_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6g_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6g_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6g_activation (Activa  (None, 17, 17, 2064)         0         ['block6g_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6g_se_squeeze (Global  (None, 2064)                 0         ['block6g_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6g_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6g_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6g_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6g_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6g_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6g_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6g_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6g_activation[0][0]',  \n",
            " y)                                                                  'block6g_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6g_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6g_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6g_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6g_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6g_drop (Dropout)      (None, 17, 17, 344)          0         ['block6g_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6g_add (Add)           (None, 17, 17, 344)          0         ['block6g_drop[0][0]',        \n",
            "                                                                     'block6f_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6h_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6g_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6h_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6h_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6h_expand_activation   (None, 17, 17, 2064)         0         ['block6h_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6h_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6h_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6h_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6h_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6h_activation (Activa  (None, 17, 17, 2064)         0         ['block6h_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6h_se_squeeze (Global  (None, 2064)                 0         ['block6h_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6h_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6h_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6h_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6h_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6h_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6h_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6h_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6h_activation[0][0]',  \n",
            " y)                                                                  'block6h_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6h_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6h_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6h_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6h_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6h_drop (Dropout)      (None, 17, 17, 344)          0         ['block6h_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6h_add (Add)           (None, 17, 17, 344)          0         ['block6h_drop[0][0]',        \n",
            "                                                                     'block6g_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6i_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6h_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6i_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6i_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6i_expand_activation   (None, 17, 17, 2064)         0         ['block6i_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6i_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6i_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6i_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6i_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6i_activation (Activa  (None, 17, 17, 2064)         0         ['block6i_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6i_se_squeeze (Global  (None, 2064)                 0         ['block6i_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6i_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6i_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6i_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6i_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6i_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6i_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6i_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6i_activation[0][0]',  \n",
            " y)                                                                  'block6i_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6i_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6i_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6i_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6i_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6i_drop (Dropout)      (None, 17, 17, 344)          0         ['block6i_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6i_add (Add)           (None, 17, 17, 344)          0         ['block6i_drop[0][0]',        \n",
            "                                                                     'block6h_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6j_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6i_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6j_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6j_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6j_expand_activation   (None, 17, 17, 2064)         0         ['block6j_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6j_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6j_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6j_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6j_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6j_activation (Activa  (None, 17, 17, 2064)         0         ['block6j_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6j_se_squeeze (Global  (None, 2064)                 0         ['block6j_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6j_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6j_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6j_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6j_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6j_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6j_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6j_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6j_activation[0][0]',  \n",
            " y)                                                                  'block6j_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6j_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6j_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6j_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6j_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6j_drop (Dropout)      (None, 17, 17, 344)          0         ['block6j_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6j_add (Add)           (None, 17, 17, 344)          0         ['block6j_drop[0][0]',        \n",
            "                                                                     'block6i_add[0][0]']         \n",
            "                                                                                                  \n",
            " block6k_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6j_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block6k_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block6k_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block6k_expand_activation   (None, 17, 17, 2064)         0         ['block6k_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block6k_dwconv (DepthwiseC  (None, 17, 17, 2064)         51600     ['block6k_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block6k_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block6k_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6k_activation (Activa  (None, 17, 17, 2064)         0         ['block6k_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block6k_se_squeeze (Global  (None, 2064)                 0         ['block6k_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block6k_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block6k_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block6k_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block6k_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block6k_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block6k_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block6k_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block6k_activation[0][0]',  \n",
            " y)                                                                  'block6k_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block6k_project_conv (Conv  (None, 17, 17, 344)          710016    ['block6k_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6k_project_bn (BatchN  (None, 17, 17, 344)          1376      ['block6k_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block6k_drop (Dropout)      (None, 17, 17, 344)          0         ['block6k_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block6k_add (Add)           (None, 17, 17, 344)          0         ['block6k_drop[0][0]',        \n",
            "                                                                     'block6j_add[0][0]']         \n",
            "                                                                                                  \n",
            " block7a_expand_conv (Conv2  (None, 17, 17, 2064)         710016    ['block6k_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7a_expand_bn (BatchNo  (None, 17, 17, 2064)         8256      ['block7a_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7a_expand_activation   (None, 17, 17, 2064)         0         ['block7a_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7a_dwconv (DepthwiseC  (None, 17, 17, 2064)         18576     ['block7a_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7a_bn (BatchNormaliza  (None, 17, 17, 2064)         8256      ['block7a_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7a_activation (Activa  (None, 17, 17, 2064)         0         ['block7a_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7a_se_squeeze (Global  (None, 2064)                 0         ['block7a_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7a_se_reshape (Reshap  (None, 1, 1, 2064)           0         ['block7a_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7a_se_reduce (Conv2D)  (None, 1, 1, 86)             177590    ['block7a_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7a_se_expand (Conv2D)  (None, 1, 1, 2064)           179568    ['block7a_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7a_se_excite (Multipl  (None, 17, 17, 2064)         0         ['block7a_activation[0][0]',  \n",
            " y)                                                                  'block7a_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7a_project_conv (Conv  (None, 17, 17, 576)          1188864   ['block7a_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7a_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7a_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7b_expand_conv (Conv2  (None, 17, 17, 3456)         1990656   ['block7a_project_bn[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7b_expand_bn (BatchNo  (None, 17, 17, 3456)         13824     ['block7b_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7b_expand_activation   (None, 17, 17, 3456)         0         ['block7b_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7b_dwconv (DepthwiseC  (None, 17, 17, 3456)         31104     ['block7b_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7b_bn (BatchNormaliza  (None, 17, 17, 3456)         13824     ['block7b_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7b_activation (Activa  (None, 17, 17, 3456)         0         ['block7b_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7b_se_squeeze (Global  (None, 3456)                 0         ['block7b_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7b_se_reshape (Reshap  (None, 1, 1, 3456)           0         ['block7b_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7b_se_reduce (Conv2D)  (None, 1, 1, 144)            497808    ['block7b_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7b_se_expand (Conv2D)  (None, 1, 1, 3456)           501120    ['block7b_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7b_se_excite (Multipl  (None, 17, 17, 3456)         0         ['block7b_activation[0][0]',  \n",
            " y)                                                                  'block7b_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7b_project_conv (Conv  (None, 17, 17, 576)          1990656   ['block7b_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7b_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7b_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7b_drop (Dropout)      (None, 17, 17, 576)          0         ['block7b_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7b_add (Add)           (None, 17, 17, 576)          0         ['block7b_drop[0][0]',        \n",
            "                                                                     'block7a_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_expand_conv (Conv2  (None, 17, 17, 3456)         1990656   ['block7b_add[0][0]']         \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block7c_expand_bn (BatchNo  (None, 17, 17, 3456)         13824     ['block7c_expand_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block7c_expand_activation   (None, 17, 17, 3456)         0         ['block7c_expand_bn[0][0]']   \n",
            " (Activation)                                                                                     \n",
            "                                                                                                  \n",
            " block7c_dwconv (DepthwiseC  (None, 17, 17, 3456)         31104     ['block7c_expand_activation[0]\n",
            " onv2D)                                                             [0]']                         \n",
            "                                                                                                  \n",
            " block7c_bn (BatchNormaliza  (None, 17, 17, 3456)         13824     ['block7c_dwconv[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7c_activation (Activa  (None, 17, 17, 3456)         0         ['block7c_bn[0][0]']          \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " block7c_se_squeeze (Global  (None, 3456)                 0         ['block7c_activation[0][0]']  \n",
            " AveragePooling2D)                                                                                \n",
            "                                                                                                  \n",
            " block7c_se_reshape (Reshap  (None, 1, 1, 3456)           0         ['block7c_se_squeeze[0][0]']  \n",
            " e)                                                                                               \n",
            "                                                                                                  \n",
            " block7c_se_reduce (Conv2D)  (None, 1, 1, 144)            497808    ['block7c_se_reshape[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_se_expand (Conv2D)  (None, 1, 1, 3456)           501120    ['block7c_se_reduce[0][0]']   \n",
            "                                                                                                  \n",
            " block7c_se_excite (Multipl  (None, 17, 17, 3456)         0         ['block7c_activation[0][0]',  \n",
            " y)                                                                  'block7c_se_expand[0][0]']   \n",
            "                                                                                                  \n",
            " block7c_project_conv (Conv  (None, 17, 17, 576)          1990656   ['block7c_se_excite[0][0]']   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7c_project_bn (BatchN  (None, 17, 17, 576)          2304      ['block7c_project_conv[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block7c_drop (Dropout)      (None, 17, 17, 576)          0         ['block7c_project_bn[0][0]']  \n",
            "                                                                                                  \n",
            " block7c_add (Add)           (None, 17, 17, 576)          0         ['block7c_drop[0][0]',        \n",
            "                                                                     'block7b_add[0][0]']         \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)           (None, 17, 17, 2304)         1327104   ['block7c_add[0][0]']         \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization  (None, 17, 17, 2304)         9216      ['top_conv[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " top_activation (Activation  (None, 17, 17, 2304)         0         ['top_bn[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePoo  (None, 2304)                 0         ['top_activation[0][0]']      \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 2304)                 9216      ['avg_pool[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " top_dropout (Dropout)       (None, 2304)                 0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " pred (Dense)                (None, 4)                    9220      ['top_dropout[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 40978579 (156.32 MB)\n",
            "Trainable params: 13828 (54.02 KB)\n",
            "Non-trainable params: 40964751 (156.27 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# ネットワーク構造の確認\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####VGG16という画像分類アルゴリズムの基本的な設定を行い、既に学習済みの情報を活用しました。<br>また、画像分類のためにモデルをカスタマイズし、過学習しないように（学習しすぎないように）一部の処理を無効にしました。<br>加えて学習時に変えたくない部分を固定し、正解率を確認しながら効率的に学習できるように準備しました。<br>これにより、カスタマイズされた画像分類のモデルが完成しました。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "mr3XQckIRrBH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x05p82lFUbtj"
      },
      "source": [
        "## 5. 学習・検証データの読み込み\n",
        "3.で指定した格納先の学習・検証データを読み込みます。<br>\n",
        "読み込み前、読み込み時にこれらのデータに前処理（クラス分布の平準化、データの分布平準化）を施すことで精度向上が期待できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "画像はコンピュータで扱うとき、色を数値で表します。例えば、1つのピクセルの色は0から255までの数字で表現されます。0は真っ黒、255は真っ白、\n",
        "そしてその間の数字は、様々な明るさの色を表します。\n",
        "\n",
        "しかし、機械学習のモデルは、0から1の範囲の数のほうが計算しやすいんです。だから、元々0から255の値で表されている\n",
        "画像のデータを0から1の範囲に変換する必要があり、それをこのコードが行なっています。\n",
        "```"
      ],
      "metadata": {
        "id": "ORzpJnlerLFa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1YfGacQFUbtj"
      },
      "outputs": [],
      "source": [
        "# EFFB6に入力するための画像サイズに圧縮\n",
        "train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,height_shift_range=0.1,width_shift_range=0.1) # 前処理を（）内に追加可能\n",
        "valid_datagen = ImageDataGenerator() # 前処理を（）内に追加可能"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、機械学習モデルを学習させるために、画像データを読み込む部分です。画像データを適切に読み込んで、\n",
        "モデルに与える準備をしています。学習用のデータと、モデルがどれくらい上手く学習できたかをチェックするための検証用データを扱っています。\n",
        "\n",
        "・train_generatorとvalidation_generatorは、それぞれ学習データと検証データを読み込むための仕組みです。\n",
        "・画像データは指定したサイズにリサイズされ、指定した枚数（バッチサイズ）ごとにモデルに渡されます。\n",
        "・データをシャッフルすることで、学習が偏らず、より良い結果が得られるようにしています。\n",
        "まとめると、このコードは「画像データを指定したサイズと枚数で読み込み、ランダムに並べ替えて、モデルに渡す準備」をしています。\n",
        "\n",
        "このコードを実行した結果、\n",
        "Found 290 images belonging to 4 classes.\n",
        "Found 290 images belonging to 4 classes.\n",
        "が返されますが、これは\n",
        "「学習用と検証用のデータは、両方とも290枚の画像を持っていて、それらが4つのクラスに分類されている。」\n",
        "ということを表しており、画像データの読み込みが正常に行われたことが確認できます。\n",
        "次に進むのは、モデルを使ってこのデータを基に学習させたり、検証を行うステップです。\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "SGfcWPjOaXQN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hSYeC6mHUbtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf4d3ac-106a-4210-f989-3afbab93975e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 290 images belonging to 4 classes.\n",
            "Found 290 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#学習・検証データの読み込み\n",
        "# 保存先、画像サイズ、バッチサイズをそれぞれ設定し、学習が偏らないようにシャッフルさせる\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、学習用データと検証用データの枚数を取得して、それぞれいくつの画像があるかを確認する部分です。\n",
        "具体的には、train_generatorとvalidation_generatorというデータ読み込みの仕組みから、何枚の画像が学習用・検証用に使われるかを数えています。\n",
        "\n",
        "＜どうして画像の枚数を知る必要があるのか？＞\n",
        "学習の設定を行う際には、学習に使う画像の数や検証に使う画像の数を知ることが重要です。これにより、モデルがどのくらいのデータを使って学習し、\n",
        "どのくらいのデータで検証されるかを確認できます。\n",
        "特に、1回のエポック（学習の1サイクル）でどれくらいのデータを使うかを設定するために、この枚数が必要です。\n",
        "\n",
        "・nb_train_samplesは、学習に使う画像の総枚数を取得します。\n",
        "・nb_validation_samplesは、検証に使う画像の総枚数を取得します。\n",
        "・これらの枚数を使って、モデルが学習するときにどれくらいの画像を使うか、どれくらいの画像で正確さを検証するかを把握します。\n",
        "まとめると、「学習用と検証用のフォルダに何枚の画像が入っているかを数えている」ということです。\n",
        "```"
      ],
      "metadata": {
        "id": "4ea3R-SqtDVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ndrJnZeXUbtk"
      },
      "outputs": [],
      "source": [
        "# 学習・検証データとして上記で設定した画像の枚数を取得する\n",
        "nb_train_samples = train_generator.samples\n",
        "nb_validation_samples = validation_generator.samples"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####VGGに入力するために画像を小さくし、データの準備をしました。<br>学習用と確認用のデータを、それぞれ決まったサイズで取り込み、順番が偏らないようにシャッフルしました。<br>また、使う画像の枚数も確認しました。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "GK_vmggWUsT5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6NoNeHgUbtk"
      },
      "source": [
        "## 6. モデルの学習\n",
        "読み込んだ学習データを用いてVGGを学習させます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "❗️このコードはVGGの学習（ディープラーニング）を行うコードになり、環境によっては実行に1時間以上かかる場合もありますのでご注意ください。\n",
        "❗️VGGの学習中、エポックが進むたびに正解率（accuracy）が上がっていくことを直接確認できる興味深いコードになります。ぜひご注目ください。\n",
        "\n",
        "このコードは、機械学習モデルを実際に学習させるための設定を行い、学習を開始する部分です。\n",
        "ここで設定しているのは、学習するデータの流れや、学習の回数（エポック数）、検証用データを使ってどれくらいモデルが上手に\n",
        "学習できているか確認する方法などです。\n",
        "\n",
        "・train_generatorを使って、コンピュータに画像を少しずつ見せて学ばせます。\n",
        "・steps_per_epochで、1回の学習サイクル（エポック）で何枚の画像を使うか決めます。\n",
        "・epochsで、モデルを何回繰り返して学習させるかを指定します。\n",
        "・validation_dataで、検証用のデータを渡して、モデルがどれくらい正確に学習できたかを確認します。\n",
        "・validation_stepsで、検証データを何回に分けて処理するかを指定します。\n",
        "\n",
        "このコードでは、学習データと検証データを使って、モデルがどんどん賢くなるように学習させ、結果を確認するための設定を行っています。\n",
        "まとめると、「どれくらいのデータを何回学習するか」「学習の進捗を検証するために、どれくらいデータをチェックするか」を決めている部分です。\n",
        "\n",
        "※このコードを実行したときに、\n",
        "loss：損失関数の値\n",
        "accuracy：正解率\n",
        "val_loss：検証データに対する損失関数の値\n",
        "val_accuracy：検証データに対する正解率\n",
        "これらの値がどうなっていくかを確認してみましょう。\n",
        "```"
      ],
      "metadata": {
        "id": "YfhoU4ODu-eI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8TbLthD6Ubtk",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7663a4df-e69b-470f-de30-53a75841bc9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 507 validated image filenames belonging to 4 classes.\n",
            "Found 73 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 309s 5s/step - loss: 1.7348 - accuracy: 0.3687 - val_loss: 1.2317 - val_accuracy: 0.4722\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.2259 - accuracy: 0.5251 - val_loss: 1.2368 - val_accuracy: 0.4722\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.2037 - accuracy: 0.5230 - val_loss: 1.0854 - val_accuracy: 0.5417\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.1131 - accuracy: 0.5531 - val_loss: 1.0451 - val_accuracy: 0.4861\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 1.0075 - accuracy: 0.5992 - val_loss: 0.9018 - val_accuracy: 0.6667\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.9420 - accuracy: 0.6353 - val_loss: 0.9039 - val_accuracy: 0.6389\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.9533 - accuracy: 0.6132 - val_loss: 0.9210 - val_accuracy: 0.6389\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8609 - accuracy: 0.6353 - val_loss: 0.8618 - val_accuracy: 0.6806\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 76s 1s/step - loss: 0.8465 - accuracy: 0.6673 - val_loss: 0.7589 - val_accuracy: 0.7222\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7893 - accuracy: 0.7014 - val_loss: 0.7894 - val_accuracy: 0.7500\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8505 - accuracy: 0.6613 - val_loss: 0.9594 - val_accuracy: 0.6389\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7572 - accuracy: 0.6854 - val_loss: 0.7498 - val_accuracy: 0.7222\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 76s 1s/step - loss: 0.8573 - accuracy: 0.6774 - val_loss: 1.0646 - val_accuracy: 0.6528\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8391 - accuracy: 0.6754 - val_loss: 0.8759 - val_accuracy: 0.6528\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8257 - accuracy: 0.6794 - val_loss: 0.8185 - val_accuracy: 0.6667\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8171 - accuracy: 0.7074 - val_loss: 0.8185 - val_accuracy: 0.6806\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8507 - accuracy: 0.6854 - val_loss: 0.9110 - val_accuracy: 0.6944\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7969 - accuracy: 0.7074 - val_loss: 0.7519 - val_accuracy: 0.7222\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7291 - accuracy: 0.6974 - val_loss: 0.8738 - val_accuracy: 0.7222\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7099 - accuracy: 0.7275 - val_loss: 0.7474 - val_accuracy: 0.6806\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7129 - accuracy: 0.7315 - val_loss: 0.9096 - val_accuracy: 0.6944\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7452 - accuracy: 0.7234 - val_loss: 0.7995 - val_accuracy: 0.7083\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6857 - accuracy: 0.7395 - val_loss: 0.7623 - val_accuracy: 0.6944\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7184 - accuracy: 0.7435 - val_loss: 0.8308 - val_accuracy: 0.6528\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7049 - accuracy: 0.7435 - val_loss: 0.8334 - val_accuracy: 0.7222\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6575 - accuracy: 0.7435 - val_loss: 0.8773 - val_accuracy: 0.6528\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8194 - accuracy: 0.7174 - val_loss: 0.8846 - val_accuracy: 0.7500\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7524 - accuracy: 0.7134 - val_loss: 0.9858 - val_accuracy: 0.7222\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6829 - accuracy: 0.7495 - val_loss: 0.8670 - val_accuracy: 0.7222\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6841 - accuracy: 0.7375 - val_loss: 0.7842 - val_accuracy: 0.7500\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7371 - accuracy: 0.7395 - val_loss: 0.7865 - val_accuracy: 0.7222\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7784 - accuracy: 0.7234 - val_loss: 0.6857 - val_accuracy: 0.7361\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6322 - accuracy: 0.7816 - val_loss: 0.9193 - val_accuracy: 0.6528\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6926 - accuracy: 0.7275 - val_loss: 0.8508 - val_accuracy: 0.6806\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7469 - accuracy: 0.7234 - val_loss: 0.7655 - val_accuracy: 0.7222\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7630 - accuracy: 0.7214 - val_loss: 0.7926 - val_accuracy: 0.7083\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7007 - accuracy: 0.7395 - val_loss: 0.6389 - val_accuracy: 0.7361\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6599 - accuracy: 0.7735 - val_loss: 0.8353 - val_accuracy: 0.7361\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7036 - accuracy: 0.7535 - val_loss: 0.8418 - val_accuracy: 0.7500\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7918 - accuracy: 0.7255 - val_loss: 0.8460 - val_accuracy: 0.7500\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6247 - accuracy: 0.7856 - val_loss: 1.0996 - val_accuracy: 0.6389\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7446 - accuracy: 0.7174 - val_loss: 0.9164 - val_accuracy: 0.6806\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6726 - accuracy: 0.7455 - val_loss: 0.8959 - val_accuracy: 0.6806\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6429 - accuracy: 0.7675 - val_loss: 0.7056 - val_accuracy: 0.7222\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 67s 1s/step - loss: 0.7207 - accuracy: 0.7375 - val_loss: 0.7389 - val_accuracy: 0.7083\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7207 - accuracy: 0.7234 - val_loss: 0.8642 - val_accuracy: 0.6944\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6589 - accuracy: 0.7695 - val_loss: 0.8798 - val_accuracy: 0.7222\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7248 - accuracy: 0.7475 - val_loss: 0.7758 - val_accuracy: 0.7639\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6339 - accuracy: 0.7615 - val_loss: 0.8040 - val_accuracy: 0.6944\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6488 - accuracy: 0.7575 - val_loss: 0.8792 - val_accuracy: 0.7361\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6680 - accuracy: 0.7475 - val_loss: 0.7586 - val_accuracy: 0.7917\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7989 - accuracy: 0.7194 - val_loss: 0.7888 - val_accuracy: 0.7917\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6430 - accuracy: 0.7555 - val_loss: 0.6476 - val_accuracy: 0.8056\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6298 - accuracy: 0.7856 - val_loss: 0.6266 - val_accuracy: 0.7639\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6120 - accuracy: 0.7735 - val_loss: 0.6393 - val_accuracy: 0.7917\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6109 - accuracy: 0.7575 - val_loss: 0.7327 - val_accuracy: 0.7639\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 67s 1s/step - loss: 0.6261 - accuracy: 0.7555 - val_loss: 0.7602 - val_accuracy: 0.7222\n",
            "Epoch 58/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.6487 - accuracy: 0.7615 - val_loss: 0.6674 - val_accuracy: 0.7500\n",
            "Epoch 59/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7317 - accuracy: 0.7615 - val_loss: 0.7034 - val_accuracy: 0.7500\n",
            "Epoch 60/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7033 - accuracy: 0.7475 - val_loss: 0.9414 - val_accuracy: 0.6667\n",
            "Epoch 61/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6733 - accuracy: 0.7515 - val_loss: 0.7404 - val_accuracy: 0.7222\n",
            "Epoch 62/80\n",
            "63/63 [==============================] - 78s 1s/step - loss: 0.6558 - accuracy: 0.7655 - val_loss: 0.7511 - val_accuracy: 0.7639\n",
            "Epoch 63/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6567 - accuracy: 0.7635 - val_loss: 0.8369 - val_accuracy: 0.7361\n",
            "Epoch 64/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6291 - accuracy: 0.7515 - val_loss: 0.6660 - val_accuracy: 0.7917\n",
            "Epoch 65/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6903 - accuracy: 0.7635 - val_loss: 0.7987 - val_accuracy: 0.7778\n",
            "Epoch 66/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6647 - accuracy: 0.7735 - val_loss: 0.6727 - val_accuracy: 0.7639\n",
            "Epoch 67/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6419 - accuracy: 0.7936 - val_loss: 0.8739 - val_accuracy: 0.7222\n",
            "Epoch 68/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6847 - accuracy: 0.7555 - val_loss: 0.6414 - val_accuracy: 0.7917\n",
            "Epoch 69/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6466 - accuracy: 0.7876 - val_loss: 0.7798 - val_accuracy: 0.7500\n",
            "Epoch 70/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6653 - accuracy: 0.7695 - val_loss: 0.6839 - val_accuracy: 0.7917\n",
            "Epoch 71/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6671 - accuracy: 0.7615 - val_loss: 0.6251 - val_accuracy: 0.8194\n",
            "Epoch 72/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6332 - accuracy: 0.7796 - val_loss: 0.9863 - val_accuracy: 0.6944\n",
            "Epoch 73/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.5942 - accuracy: 0.7776 - val_loss: 0.9490 - val_accuracy: 0.6944\n",
            "Epoch 74/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.5960 - accuracy: 0.7698 - val_loss: 0.7072 - val_accuracy: 0.7222\n",
            "Epoch 75/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.5866 - accuracy: 0.7976 - val_loss: 0.6604 - val_accuracy: 0.7778\n",
            "Epoch 76/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6253 - accuracy: 0.7735 - val_loss: 0.7938 - val_accuracy: 0.7361\n",
            "Epoch 77/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6468 - accuracy: 0.7715 - val_loss: 0.8004 - val_accuracy: 0.7639\n",
            "Epoch 78/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7939 - accuracy: 0.7154 - val_loss: 0.7251 - val_accuracy: 0.7778\n",
            "Epoch 79/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7510 - accuracy: 0.7575 - val_loss: 0.6950 - val_accuracy: 0.7361\n",
            "Epoch 80/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6007 - accuracy: 0.7735 - val_loss: 0.8244 - val_accuracy: 0.7639\n",
            "Found 507 validated image filenames belonging to 4 classes.\n",
            "Found 73 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 95s 1s/step - loss: 1.6615 - accuracy: 0.3727 - val_loss: 1.1972 - val_accuracy: 0.4306\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.2539 - accuracy: 0.5090 - val_loss: 1.1705 - val_accuracy: 0.4583\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.1957 - accuracy: 0.5351 - val_loss: 1.0896 - val_accuracy: 0.5833\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.0659 - accuracy: 0.5832 - val_loss: 1.0383 - val_accuracy: 0.6111\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 78s 1s/step - loss: 1.0382 - accuracy: 0.6152 - val_loss: 0.9888 - val_accuracy: 0.5972\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 1.0160 - accuracy: 0.6032 - val_loss: 0.8660 - val_accuracy: 0.6667\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.9194 - accuracy: 0.6293 - val_loss: 0.8031 - val_accuracy: 0.7222\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.9727 - accuracy: 0.6012 - val_loss: 0.8287 - val_accuracy: 0.6944\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8933 - accuracy: 0.6533 - val_loss: 0.8974 - val_accuracy: 0.6667\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.9661 - accuracy: 0.6333 - val_loss: 0.7071 - val_accuracy: 0.7083\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8516 - accuracy: 0.6774 - val_loss: 0.6686 - val_accuracy: 0.7361\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7785 - accuracy: 0.7054 - val_loss: 0.8369 - val_accuracy: 0.7639\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8371 - accuracy: 0.6733 - val_loss: 0.7141 - val_accuracy: 0.6944\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8260 - accuracy: 0.6894 - val_loss: 0.6576 - val_accuracy: 0.7778\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7197 - accuracy: 0.7154 - val_loss: 0.6744 - val_accuracy: 0.7361\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.8172 - accuracy: 0.7034 - val_loss: 0.8258 - val_accuracy: 0.7222\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7728 - accuracy: 0.6974 - val_loss: 0.8793 - val_accuracy: 0.6667\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7775 - accuracy: 0.6894 - val_loss: 0.9158 - val_accuracy: 0.6667\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7975 - accuracy: 0.6794 - val_loss: 0.7525 - val_accuracy: 0.7083\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7273 - accuracy: 0.7375 - val_loss: 0.5946 - val_accuracy: 0.7917\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6778 - accuracy: 0.7655 - val_loss: 0.8067 - val_accuracy: 0.7222\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7841 - accuracy: 0.7154 - val_loss: 0.8701 - val_accuracy: 0.7222\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6638 - accuracy: 0.7315 - val_loss: 0.6643 - val_accuracy: 0.7361\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7696 - accuracy: 0.7214 - val_loss: 0.9898 - val_accuracy: 0.6111\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7557 - accuracy: 0.7395 - val_loss: 0.7082 - val_accuracy: 0.7500\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7422 - accuracy: 0.6994 - val_loss: 0.7690 - val_accuracy: 0.7361\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8626 - accuracy: 0.7074 - val_loss: 0.6305 - val_accuracy: 0.8056\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7235 - accuracy: 0.7415 - val_loss: 0.5953 - val_accuracy: 0.7917\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6450 - accuracy: 0.7415 - val_loss: 0.6883 - val_accuracy: 0.7500\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 79s 1s/step - loss: 0.7124 - accuracy: 0.7495 - val_loss: 0.7326 - val_accuracy: 0.6944\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.6618 - accuracy: 0.7455 - val_loss: 1.1527 - val_accuracy: 0.6528\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7936 - accuracy: 0.7154 - val_loss: 1.0457 - val_accuracy: 0.6667\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7843 - accuracy: 0.7255 - val_loss: 0.7028 - val_accuracy: 0.7361\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.6741 - accuracy: 0.7595 - val_loss: 0.7237 - val_accuracy: 0.6944\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7201 - accuracy: 0.7255 - val_loss: 0.5976 - val_accuracy: 0.8056\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6768 - accuracy: 0.7295 - val_loss: 0.8714 - val_accuracy: 0.6944\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7518 - accuracy: 0.7295 - val_loss: 0.8418 - val_accuracy: 0.6806\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 78s 1s/step - loss: 0.6764 - accuracy: 0.7515 - val_loss: 0.6253 - val_accuracy: 0.7917\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6494 - accuracy: 0.7455 - val_loss: 0.7074 - val_accuracy: 0.7500\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7408 - accuracy: 0.7355 - val_loss: 0.6719 - val_accuracy: 0.7639\n",
            "Found 507 validated image filenames belonging to 4 classes.\n",
            "Found 73 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 97s 1s/step - loss: 1.6620 - accuracy: 0.3768 - val_loss: 1.2460 - val_accuracy: 0.4306\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.3208 - accuracy: 0.5150 - val_loss: 1.1673 - val_accuracy: 0.5000\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.1555 - accuracy: 0.5431 - val_loss: 1.1222 - val_accuracy: 0.5278\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.0519 - accuracy: 0.5752 - val_loss: 1.0464 - val_accuracy: 0.5556\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.9224 - accuracy: 0.6313 - val_loss: 0.9648 - val_accuracy: 0.6250\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.0177 - accuracy: 0.6032 - val_loss: 0.8788 - val_accuracy: 0.7083\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.9192 - accuracy: 0.6553 - val_loss: 0.8294 - val_accuracy: 0.7083\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8689 - accuracy: 0.6473 - val_loss: 1.2345 - val_accuracy: 0.5833\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.8577 - accuracy: 0.6533 - val_loss: 0.8289 - val_accuracy: 0.7083\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.9098 - accuracy: 0.6373 - val_loss: 0.8007 - val_accuracy: 0.7500\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8122 - accuracy: 0.6954 - val_loss: 0.8279 - val_accuracy: 0.6944\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8494 - accuracy: 0.6673 - val_loss: 0.9533 - val_accuracy: 0.7639\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7067 - accuracy: 0.7315 - val_loss: 1.0085 - val_accuracy: 0.6806\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7308 - accuracy: 0.7275 - val_loss: 0.9041 - val_accuracy: 0.6944\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7873 - accuracy: 0.7134 - val_loss: 1.0306 - val_accuracy: 0.6528\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8026 - accuracy: 0.6954 - val_loss: 0.8341 - val_accuracy: 0.7222\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7641 - accuracy: 0.7114 - val_loss: 1.0166 - val_accuracy: 0.6250\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8544 - accuracy: 0.6854 - val_loss: 0.8623 - val_accuracy: 0.7500\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7832 - accuracy: 0.6954 - val_loss: 1.0854 - val_accuracy: 0.6528\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7214 - accuracy: 0.7174 - val_loss: 0.7960 - val_accuracy: 0.7639\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7824 - accuracy: 0.6794 - val_loss: 0.8975 - val_accuracy: 0.7500\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7196 - accuracy: 0.7114 - val_loss: 0.8496 - val_accuracy: 0.6944\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7284 - accuracy: 0.7194 - val_loss: 0.7855 - val_accuracy: 0.7778\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6520 - accuracy: 0.7615 - val_loss: 0.9988 - val_accuracy: 0.7083\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.9314 - accuracy: 0.6814 - val_loss: 1.2073 - val_accuracy: 0.6667\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6786 - accuracy: 0.7555 - val_loss: 0.8738 - val_accuracy: 0.7917\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7403 - accuracy: 0.7174 - val_loss: 0.8841 - val_accuracy: 0.7361\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7319 - accuracy: 0.7255 - val_loss: 1.1527 - val_accuracy: 0.6667\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8257 - accuracy: 0.6974 - val_loss: 0.8740 - val_accuracy: 0.7222\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7063 - accuracy: 0.7575 - val_loss: 0.9869 - val_accuracy: 0.7083\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6200 - accuracy: 0.7575 - val_loss: 1.0255 - val_accuracy: 0.6250\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6500 - accuracy: 0.7475 - val_loss: 1.0047 - val_accuracy: 0.6528\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6592 - accuracy: 0.7435 - val_loss: 0.8737 - val_accuracy: 0.7222\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6706 - accuracy: 0.7355 - val_loss: 0.9593 - val_accuracy: 0.6944\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7553 - accuracy: 0.7134 - val_loss: 0.8908 - val_accuracy: 0.7917\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.5920 - accuracy: 0.7595 - val_loss: 0.8605 - val_accuracy: 0.7639\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6943 - accuracy: 0.7214 - val_loss: 0.8645 - val_accuracy: 0.7500\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7194 - accuracy: 0.7615 - val_loss: 0.9842 - val_accuracy: 0.7222\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6887 - accuracy: 0.7295 - val_loss: 0.8464 - val_accuracy: 0.7361\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8051 - accuracy: 0.7174 - val_loss: 0.8939 - val_accuracy: 0.7500\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.5974 - accuracy: 0.7555 - val_loss: 0.9060 - val_accuracy: 0.7083\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6865 - accuracy: 0.7335 - val_loss: 0.9157 - val_accuracy: 0.7500\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6990 - accuracy: 0.7555 - val_loss: 0.9200 - val_accuracy: 0.7083\n",
            "Found 507 validated image filenames belonging to 4 classes.\n",
            "Found 73 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 94s 1s/step - loss: 1.7031 - accuracy: 0.3828 - val_loss: 1.2168 - val_accuracy: 0.5000\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 1.3132 - accuracy: 0.5010 - val_loss: 1.1799 - val_accuracy: 0.4861\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 1.1698 - accuracy: 0.5571 - val_loss: 1.0510 - val_accuracy: 0.5694\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 1.0193 - accuracy: 0.5992 - val_loss: 0.9453 - val_accuracy: 0.5972\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 1.0131 - accuracy: 0.5912 - val_loss: 1.0354 - val_accuracy: 0.5556\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.0078 - accuracy: 0.6293 - val_loss: 0.9000 - val_accuracy: 0.6250\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.9744 - accuracy: 0.6293 - val_loss: 0.8601 - val_accuracy: 0.5972\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.9486 - accuracy: 0.6293 - val_loss: 0.7197 - val_accuracy: 0.7083\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8343 - accuracy: 0.6693 - val_loss: 0.8573 - val_accuracy: 0.7083\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8615 - accuracy: 0.6573 - val_loss: 0.7014 - val_accuracy: 0.7083\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8616 - accuracy: 0.6693 - val_loss: 0.6787 - val_accuracy: 0.6389\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.8628 - accuracy: 0.6673 - val_loss: 0.6730 - val_accuracy: 0.7361\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8675 - accuracy: 0.6874 - val_loss: 0.6510 - val_accuracy: 0.7222\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8801 - accuracy: 0.6533 - val_loss: 0.5955 - val_accuracy: 0.7917\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7688 - accuracy: 0.6974 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.9025 - accuracy: 0.6854 - val_loss: 0.7249 - val_accuracy: 0.6944\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8261 - accuracy: 0.6894 - val_loss: 0.6078 - val_accuracy: 0.7500\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7452 - accuracy: 0.7114 - val_loss: 0.6280 - val_accuracy: 0.7639\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7800 - accuracy: 0.7154 - val_loss: 0.5947 - val_accuracy: 0.7500\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8963 - accuracy: 0.6974 - val_loss: 0.5877 - val_accuracy: 0.7778\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7411 - accuracy: 0.7315 - val_loss: 0.6608 - val_accuracy: 0.7500\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7717 - accuracy: 0.7114 - val_loss: 0.7206 - val_accuracy: 0.7083\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8175 - accuracy: 0.6934 - val_loss: 0.5986 - val_accuracy: 0.7222\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7503 - accuracy: 0.7415 - val_loss: 0.5283 - val_accuracy: 0.8056\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7573 - accuracy: 0.7255 - val_loss: 0.5336 - val_accuracy: 0.8194\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8414 - accuracy: 0.7034 - val_loss: 0.6512 - val_accuracy: 0.7222\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8155 - accuracy: 0.6934 - val_loss: 0.5616 - val_accuracy: 0.7917\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6882 - accuracy: 0.7114 - val_loss: 0.6798 - val_accuracy: 0.7361\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7760 - accuracy: 0.6974 - val_loss: 0.5342 - val_accuracy: 0.8056\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7638 - accuracy: 0.7114 - val_loss: 0.5595 - val_accuracy: 0.7639\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7400 - accuracy: 0.7234 - val_loss: 0.6142 - val_accuracy: 0.7500\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6629 - accuracy: 0.7535 - val_loss: 0.4820 - val_accuracy: 0.8056\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6716 - accuracy: 0.7575 - val_loss: 0.6315 - val_accuracy: 0.7500\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6716 - accuracy: 0.7515 - val_loss: 0.6170 - val_accuracy: 0.7222\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7468 - accuracy: 0.7174 - val_loss: 0.7559 - val_accuracy: 0.6667\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6874 - accuracy: 0.7395 - val_loss: 0.5782 - val_accuracy: 0.7639\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6698 - accuracy: 0.7515 - val_loss: 0.4720 - val_accuracy: 0.8472\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6858 - accuracy: 0.7615 - val_loss: 0.6644 - val_accuracy: 0.7361\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7162 - accuracy: 0.7355 - val_loss: 0.5756 - val_accuracy: 0.8333\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7588 - accuracy: 0.7275 - val_loss: 0.5174 - val_accuracy: 0.8333\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7122 - accuracy: 0.7615 - val_loss: 0.7339 - val_accuracy: 0.7222\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 67s 1s/step - loss: 0.7908 - accuracy: 0.7014 - val_loss: 0.6175 - val_accuracy: 0.8056\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8034 - accuracy: 0.7134 - val_loss: 0.5276 - val_accuracy: 0.7917\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6873 - accuracy: 0.7655 - val_loss: 0.4794 - val_accuracy: 0.7639\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6267 - accuracy: 0.7836 - val_loss: 0.5268 - val_accuracy: 0.7917\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7071 - accuracy: 0.7375 - val_loss: 0.8239 - val_accuracy: 0.7222\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7327 - accuracy: 0.7355 - val_loss: 0.5177 - val_accuracy: 0.7778\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6442 - accuracy: 0.7615 - val_loss: 0.5521 - val_accuracy: 0.7639\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7046 - accuracy: 0.7715 - val_loss: 0.5772 - val_accuracy: 0.7639\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7131 - accuracy: 0.7375 - val_loss: 0.8294 - val_accuracy: 0.7222\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7540 - accuracy: 0.7174 - val_loss: 0.6288 - val_accuracy: 0.7222\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 67s 1s/step - loss: 0.8038 - accuracy: 0.7315 - val_loss: 0.5622 - val_accuracy: 0.7917\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7033 - accuracy: 0.7655 - val_loss: 0.5351 - val_accuracy: 0.7778\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6066 - accuracy: 0.7876 - val_loss: 0.5028 - val_accuracy: 0.7917\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.5952 - accuracy: 0.7695 - val_loss: 0.6103 - val_accuracy: 0.8056\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7229 - accuracy: 0.7335 - val_loss: 0.5192 - val_accuracy: 0.7917\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 79s 1s/step - loss: 0.6973 - accuracy: 0.7315 - val_loss: 0.7212 - val_accuracy: 0.7500\n",
            "Found 508 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 94s 1s/step - loss: 1.6836 - accuracy: 0.3580 - val_loss: 1.2302 - val_accuracy: 0.4583\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.2206 - accuracy: 0.5020 - val_loss: 1.1235 - val_accuracy: 0.5556\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 1.1154 - accuracy: 0.5600 - val_loss: 1.0706 - val_accuracy: 0.5833\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.0407 - accuracy: 0.5940 - val_loss: 1.0243 - val_accuracy: 0.5972\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 1.0781 - accuracy: 0.5760 - val_loss: 1.0338 - val_accuracy: 0.5556\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.9838 - accuracy: 0.6140 - val_loss: 0.8053 - val_accuracy: 0.6944\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.9476 - accuracy: 0.6400 - val_loss: 0.8805 - val_accuracy: 0.6389\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8261 - accuracy: 0.6420 - val_loss: 1.0226 - val_accuracy: 0.5694\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.9216 - accuracy: 0.6560 - val_loss: 0.7728 - val_accuracy: 0.7639\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.8128 - accuracy: 0.6760 - val_loss: 0.7165 - val_accuracy: 0.7083\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8070 - accuracy: 0.6820 - val_loss: 0.8761 - val_accuracy: 0.5972\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7605 - accuracy: 0.7140 - val_loss: 0.8385 - val_accuracy: 0.7222\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8063 - accuracy: 0.6940 - val_loss: 0.8100 - val_accuracy: 0.6806\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8398 - accuracy: 0.6860 - val_loss: 0.7923 - val_accuracy: 0.7500\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8756 - accuracy: 0.6820 - val_loss: 0.7688 - val_accuracy: 0.7500\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8259 - accuracy: 0.7000 - val_loss: 1.4004 - val_accuracy: 0.5833\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8181 - accuracy: 0.6880 - val_loss: 1.1486 - val_accuracy: 0.6389\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7939 - accuracy: 0.7020 - val_loss: 0.8309 - val_accuracy: 0.7639\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7788 - accuracy: 0.7200 - val_loss: 1.0100 - val_accuracy: 0.6389\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8556 - accuracy: 0.6780 - val_loss: 0.7475 - val_accuracy: 0.7639\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8118 - accuracy: 0.6840 - val_loss: 0.7705 - val_accuracy: 0.6806\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8518 - accuracy: 0.6740 - val_loss: 1.1181 - val_accuracy: 0.5417\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 78s 1s/step - loss: 0.7220 - accuracy: 0.7380 - val_loss: 0.7463 - val_accuracy: 0.7083\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7636 - accuracy: 0.7060 - val_loss: 0.8017 - val_accuracy: 0.6806\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7585 - accuracy: 0.7220 - val_loss: 0.9266 - val_accuracy: 0.6806\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7446 - accuracy: 0.7240 - val_loss: 0.6335 - val_accuracy: 0.7778\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7141 - accuracy: 0.7260 - val_loss: 0.7324 - val_accuracy: 0.7361\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6965 - accuracy: 0.7240 - val_loss: 0.7196 - val_accuracy: 0.7222\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7256 - accuracy: 0.7240 - val_loss: 0.7868 - val_accuracy: 0.7361\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7606 - accuracy: 0.7120 - val_loss: 0.8092 - val_accuracy: 0.6944\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7243 - accuracy: 0.7320 - val_loss: 0.5934 - val_accuracy: 0.7917\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6738 - accuracy: 0.7700 - val_loss: 0.8812 - val_accuracy: 0.7083\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6350 - accuracy: 0.7640 - val_loss: 0.6300 - val_accuracy: 0.8056\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7078 - accuracy: 0.7280 - val_loss: 0.6635 - val_accuracy: 0.7222\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6424 - accuracy: 0.7640 - val_loss: 0.6770 - val_accuracy: 0.7222\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8052 - accuracy: 0.7180 - val_loss: 0.6238 - val_accuracy: 0.7639\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6854 - accuracy: 0.7400 - val_loss: 0.6327 - val_accuracy: 0.7778\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6440 - accuracy: 0.7440 - val_loss: 0.6476 - val_accuracy: 0.7778\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7223 - accuracy: 0.7220 - val_loss: 0.7439 - val_accuracy: 0.7500\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7215 - accuracy: 0.7280 - val_loss: 0.6090 - val_accuracy: 0.8194\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6301 - accuracy: 0.7840 - val_loss: 0.6530 - val_accuracy: 0.7639\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6572 - accuracy: 0.7540 - val_loss: 0.6323 - val_accuracy: 0.7778\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 78s 1s/step - loss: 0.6999 - accuracy: 0.7160 - val_loss: 0.8141 - val_accuracy: 0.7083\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6644 - accuracy: 0.7560 - val_loss: 0.8805 - val_accuracy: 0.7083\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 67s 1s/step - loss: 0.6539 - accuracy: 0.7720 - val_loss: 0.7772 - val_accuracy: 0.7361\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7260 - accuracy: 0.7360 - val_loss: 0.6851 - val_accuracy: 0.7639\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7075 - accuracy: 0.7320 - val_loss: 0.7071 - val_accuracy: 0.7639\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7011 - accuracy: 0.7440 - val_loss: 0.7113 - val_accuracy: 0.7500\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6671 - accuracy: 0.7560 - val_loss: 0.8053 - val_accuracy: 0.7639\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6336 - accuracy: 0.7620 - val_loss: 0.7593 - val_accuracy: 0.7500\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7022 - accuracy: 0.7480 - val_loss: 0.7930 - val_accuracy: 0.7500\n",
            "Found 508 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 92s 1s/step - loss: 1.6758 - accuracy: 0.3740 - val_loss: 1.2577 - val_accuracy: 0.4167\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.3592 - accuracy: 0.4720 - val_loss: 1.1416 - val_accuracy: 0.4583\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 1.0914 - accuracy: 0.5700 - val_loss: 1.0539 - val_accuracy: 0.5417\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.0768 - accuracy: 0.5660 - val_loss: 0.9501 - val_accuracy: 0.6389\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.0781 - accuracy: 0.6100 - val_loss: 0.8717 - val_accuracy: 0.6250\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 1.0633 - accuracy: 0.5760 - val_loss: 0.7374 - val_accuracy: 0.7083\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.8795 - accuracy: 0.6620 - val_loss: 0.8142 - val_accuracy: 0.6389\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.9232 - accuracy: 0.6540 - val_loss: 0.7218 - val_accuracy: 0.6944\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8728 - accuracy: 0.6520 - val_loss: 0.7005 - val_accuracy: 0.6806\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.9234 - accuracy: 0.6440 - val_loss: 0.7848 - val_accuracy: 0.7083\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8813 - accuracy: 0.6420 - val_loss: 0.7433 - val_accuracy: 0.6944\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8942 - accuracy: 0.6440 - val_loss: 0.6883 - val_accuracy: 0.6944\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8180 - accuracy: 0.6980 - val_loss: 0.8372 - val_accuracy: 0.6806\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7860 - accuracy: 0.7280 - val_loss: 0.6420 - val_accuracy: 0.7639\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8129 - accuracy: 0.6900 - val_loss: 0.6666 - val_accuracy: 0.7639\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7750 - accuracy: 0.7220 - val_loss: 0.7855 - val_accuracy: 0.6806\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.8033 - accuracy: 0.7200 - val_loss: 0.6229 - val_accuracy: 0.7222\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7925 - accuracy: 0.7020 - val_loss: 0.7861 - val_accuracy: 0.7222\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7069 - accuracy: 0.7180 - val_loss: 0.7926 - val_accuracy: 0.7222\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6860 - accuracy: 0.7420 - val_loss: 0.6395 - val_accuracy: 0.6806\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7264 - accuracy: 0.7220 - val_loss: 0.6694 - val_accuracy: 0.7361\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.8421 - accuracy: 0.6780 - val_loss: 0.5370 - val_accuracy: 0.8056\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7497 - accuracy: 0.7280 - val_loss: 0.6288 - val_accuracy: 0.7500\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7285 - accuracy: 0.7020 - val_loss: 0.7076 - val_accuracy: 0.7222\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7086 - accuracy: 0.7340 - val_loss: 0.8815 - val_accuracy: 0.7222\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8083 - accuracy: 0.7060 - val_loss: 0.6272 - val_accuracy: 0.7083\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7026 - accuracy: 0.7302 - val_loss: 0.5495 - val_accuracy: 0.7361\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7138 - accuracy: 0.7420 - val_loss: 0.7535 - val_accuracy: 0.7083\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7392 - accuracy: 0.7200 - val_loss: 0.7709 - val_accuracy: 0.6806\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7981 - accuracy: 0.7020 - val_loss: 0.7584 - val_accuracy: 0.7083\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7691 - accuracy: 0.7020 - val_loss: 0.7204 - val_accuracy: 0.7639\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8139 - accuracy: 0.6840 - val_loss: 0.7249 - val_accuracy: 0.6944\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7364 - accuracy: 0.7180 - val_loss: 1.0867 - val_accuracy: 0.6667\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6653 - accuracy: 0.7420 - val_loss: 0.7024 - val_accuracy: 0.7083\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7666 - accuracy: 0.7260 - val_loss: 0.6267 - val_accuracy: 0.7361\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7291 - accuracy: 0.7280 - val_loss: 0.7711 - val_accuracy: 0.7222\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7066 - accuracy: 0.7360 - val_loss: 0.7774 - val_accuracy: 0.6944\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7127 - accuracy: 0.7380 - val_loss: 0.6420 - val_accuracy: 0.7639\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7562 - accuracy: 0.7340 - val_loss: 0.6959 - val_accuracy: 0.7361\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6972 - accuracy: 0.7400 - val_loss: 0.7266 - val_accuracy: 0.6806\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7091 - accuracy: 0.7460 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6572 - accuracy: 0.7580 - val_loss: 0.8344 - val_accuracy: 0.7361\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7402 - accuracy: 0.7300 - val_loss: 0.6851 - val_accuracy: 0.7361\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6009 - accuracy: 0.7500 - val_loss: 0.9615 - val_accuracy: 0.6944\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6972 - accuracy: 0.7380 - val_loss: 0.6392 - val_accuracy: 0.7917\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7685 - accuracy: 0.7280 - val_loss: 0.6178 - val_accuracy: 0.7778\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.7739 - accuracy: 0.7260 - val_loss: 0.8698 - val_accuracy: 0.7639\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6452 - accuracy: 0.7580 - val_loss: 0.6401 - val_accuracy: 0.7639\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6525 - accuracy: 0.7540 - val_loss: 0.6264 - val_accuracy: 0.7500\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 76s 1s/step - loss: 0.6673 - accuracy: 0.7580 - val_loss: 0.5303 - val_accuracy: 0.8056\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6866 - accuracy: 0.7480 - val_loss: 0.5447 - val_accuracy: 0.7639\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.8382 - accuracy: 0.7100 - val_loss: 0.8197 - val_accuracy: 0.7361\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7421 - accuracy: 0.7400 - val_loss: 0.7385 - val_accuracy: 0.6667\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7113 - accuracy: 0.7320 - val_loss: 0.8474 - val_accuracy: 0.6806\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.5983 - accuracy: 0.7740 - val_loss: 0.7188 - val_accuracy: 0.7639\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.7873 - accuracy: 0.7180 - val_loss: 0.7414 - val_accuracy: 0.7222\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.5869 - accuracy: 0.7780 - val_loss: 0.5389 - val_accuracy: 0.7778\n",
            "Epoch 58/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6477 - accuracy: 0.7800 - val_loss: 0.8433 - val_accuracy: 0.7083\n",
            "Epoch 59/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7040 - accuracy: 0.7540 - val_loss: 0.6649 - val_accuracy: 0.7500\n",
            "Epoch 60/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6858 - accuracy: 0.7660 - val_loss: 0.7526 - val_accuracy: 0.7500\n",
            "Epoch 61/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6341 - accuracy: 0.7880 - val_loss: 0.5398 - val_accuracy: 0.8056\n",
            "Found 508 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 104s 1s/step - loss: 1.7780 - accuracy: 0.3300 - val_loss: 1.2552 - val_accuracy: 0.4167\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.3153 - accuracy: 0.4820 - val_loss: 1.2214 - val_accuracy: 0.4861\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.2001 - accuracy: 0.5160 - val_loss: 1.1499 - val_accuracy: 0.5417\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 1.1394 - accuracy: 0.5480 - val_loss: 0.9763 - val_accuracy: 0.6528\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 1.0308 - accuracy: 0.6180 - val_loss: 0.9713 - val_accuracy: 0.6250\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.9691 - accuracy: 0.6220 - val_loss: 1.0027 - val_accuracy: 0.5972\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.9892 - accuracy: 0.6220 - val_loss: 1.0696 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.9746 - accuracy: 0.6320 - val_loss: 0.9707 - val_accuracy: 0.7083\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8989 - accuracy: 0.6620 - val_loss: 1.0609 - val_accuracy: 0.5833\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.9086 - accuracy: 0.6440 - val_loss: 0.9410 - val_accuracy: 0.6528\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.9635 - accuracy: 0.6500 - val_loss: 1.1348 - val_accuracy: 0.6111\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.9324 - accuracy: 0.6520 - val_loss: 0.8995 - val_accuracy: 0.6806\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8672 - accuracy: 0.6500 - val_loss: 0.9782 - val_accuracy: 0.6389\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8434 - accuracy: 0.6800 - val_loss: 0.9822 - val_accuracy: 0.6806\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.8335 - accuracy: 0.6720 - val_loss: 0.8816 - val_accuracy: 0.7083\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8002 - accuracy: 0.6800 - val_loss: 0.8979 - val_accuracy: 0.7222\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7669 - accuracy: 0.7063 - val_loss: 1.1826 - val_accuracy: 0.6944\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.7937 - accuracy: 0.7180 - val_loss: 1.0279 - val_accuracy: 0.6806\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7984 - accuracy: 0.7000 - val_loss: 0.8526 - val_accuracy: 0.7222\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 76s 1s/step - loss: 0.6208 - accuracy: 0.7260 - val_loss: 0.8423 - val_accuracy: 0.7361\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7485 - accuracy: 0.7160 - val_loss: 1.0183 - val_accuracy: 0.6806\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6884 - accuracy: 0.7220 - val_loss: 0.8362 - val_accuracy: 0.7222\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8274 - accuracy: 0.6820 - val_loss: 0.8396 - val_accuracy: 0.7361\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7583 - accuracy: 0.7300 - val_loss: 0.9892 - val_accuracy: 0.6806\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7844 - accuracy: 0.7060 - val_loss: 0.8061 - val_accuracy: 0.7361\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6996 - accuracy: 0.7580 - val_loss: 0.8166 - val_accuracy: 0.7083\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7027 - accuracy: 0.7260 - val_loss: 0.8873 - val_accuracy: 0.6806\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7913 - accuracy: 0.7020 - val_loss: 0.7819 - val_accuracy: 0.7361\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7200 - accuracy: 0.7380 - val_loss: 0.7090 - val_accuracy: 0.7639\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7368 - accuracy: 0.7180 - val_loss: 0.6519 - val_accuracy: 0.7639\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7218 - accuracy: 0.7200 - val_loss: 0.8839 - val_accuracy: 0.7222\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6967 - accuracy: 0.7440 - val_loss: 1.0465 - val_accuracy: 0.6667\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7592 - accuracy: 0.7300 - val_loss: 0.8781 - val_accuracy: 0.6806\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7595 - accuracy: 0.7140 - val_loss: 0.7731 - val_accuracy: 0.6806\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6966 - accuracy: 0.7619 - val_loss: 0.8423 - val_accuracy: 0.6806\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6917 - accuracy: 0.7380 - val_loss: 0.9059 - val_accuracy: 0.7361\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7104 - accuracy: 0.7340 - val_loss: 0.9448 - val_accuracy: 0.6667\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 75s 1s/step - loss: 0.6957 - accuracy: 0.7300 - val_loss: 0.9666 - val_accuracy: 0.6806\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7841 - accuracy: 0.7220 - val_loss: 0.9171 - val_accuracy: 0.6667\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7013 - accuracy: 0.7520 - val_loss: 0.7187 - val_accuracy: 0.7083\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7628 - accuracy: 0.7220 - val_loss: 0.8603 - val_accuracy: 0.6806\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7528 - accuracy: 0.7240 - val_loss: 1.0048 - val_accuracy: 0.6667\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7434 - accuracy: 0.7280 - val_loss: 1.0684 - val_accuracy: 0.6389\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6865 - accuracy: 0.7580 - val_loss: 0.7179 - val_accuracy: 0.7639\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7261 - accuracy: 0.7300 - val_loss: 0.7822 - val_accuracy: 0.6667\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7099 - accuracy: 0.7260 - val_loss: 0.6919 - val_accuracy: 0.7083\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7183 - accuracy: 0.7360 - val_loss: 0.7388 - val_accuracy: 0.7500\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6892 - accuracy: 0.7480 - val_loss: 0.7596 - val_accuracy: 0.6806\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6406 - accuracy: 0.7560 - val_loss: 0.7850 - val_accuracy: 0.6944\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6935 - accuracy: 0.7680 - val_loss: 0.7897 - val_accuracy: 0.6528\n",
            "Found 508 validated image filenames belonging to 4 classes.\n",
            "Found 72 validated image filenames belonging to 4 classes.\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 97s 1s/step - loss: 1.5791 - accuracy: 0.3400 - val_loss: 1.1813 - val_accuracy: 0.4722\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 1.2899 - accuracy: 0.5080 - val_loss: 1.1370 - val_accuracy: 0.4722\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 1.1727 - accuracy: 0.5480 - val_loss: 1.0558 - val_accuracy: 0.4861\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 1.0698 - accuracy: 0.5800 - val_loss: 0.9840 - val_accuracy: 0.5556\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 76s 1s/step - loss: 1.0429 - accuracy: 0.6000 - val_loss: 0.9792 - val_accuracy: 0.5556\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.9355 - accuracy: 0.6340 - val_loss: 0.9773 - val_accuracy: 0.5833\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8597 - accuracy: 0.6580 - val_loss: 1.0541 - val_accuracy: 0.6389\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7919 - accuracy: 0.6944 - val_loss: 0.9816 - val_accuracy: 0.6250\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.9589 - accuracy: 0.6560 - val_loss: 0.9452 - val_accuracy: 0.6667\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8565 - accuracy: 0.6520 - val_loss: 1.0927 - val_accuracy: 0.6667\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8111 - accuracy: 0.7120 - val_loss: 0.9189 - val_accuracy: 0.6806\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8411 - accuracy: 0.6740 - val_loss: 0.9878 - val_accuracy: 0.6111\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8096 - accuracy: 0.6940 - val_loss: 1.0603 - val_accuracy: 0.6806\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8760 - accuracy: 0.6740 - val_loss: 1.1007 - val_accuracy: 0.6944\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8465 - accuracy: 0.6780 - val_loss: 1.1275 - val_accuracy: 0.6528\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7957 - accuracy: 0.7080 - val_loss: 1.2011 - val_accuracy: 0.6944\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7565 - accuracy: 0.7480 - val_loss: 1.4799 - val_accuracy: 0.6250\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.8053 - accuracy: 0.7000 - val_loss: 0.8563 - val_accuracy: 0.6667\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8272 - accuracy: 0.6720 - val_loss: 0.9461 - val_accuracy: 0.6944\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8016 - accuracy: 0.7040 - val_loss: 1.0951 - val_accuracy: 0.6250\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6955 - accuracy: 0.7260 - val_loss: 1.0336 - val_accuracy: 0.6944\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7444 - accuracy: 0.7160 - val_loss: 0.9573 - val_accuracy: 0.7083\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7583 - accuracy: 0.7200 - val_loss: 1.1254 - val_accuracy: 0.6111\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7894 - accuracy: 0.6980 - val_loss: 1.1283 - val_accuracy: 0.6528\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6921 - accuracy: 0.7260 - val_loss: 0.9582 - val_accuracy: 0.7083\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 81s 1s/step - loss: 0.7979 - accuracy: 0.6980 - val_loss: 1.0142 - val_accuracy: 0.7083\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 88s 1s/step - loss: 0.6399 - accuracy: 0.7660 - val_loss: 0.8400 - val_accuracy: 0.7222\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7179 - accuracy: 0.7360 - val_loss: 0.9775 - val_accuracy: 0.6806\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.8156 - accuracy: 0.7200 - val_loss: 0.9646 - val_accuracy: 0.7222\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.6656 - accuracy: 0.7600 - val_loss: 1.1958 - val_accuracy: 0.5972\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.7350 - accuracy: 0.7440 - val_loss: 0.9383 - val_accuracy: 0.6806\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6897 - accuracy: 0.7520 - val_loss: 0.9635 - val_accuracy: 0.7361\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7044 - accuracy: 0.7300 - val_loss: 1.0051 - val_accuracy: 0.7083\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 71s 1s/step - loss: 0.7060 - accuracy: 0.7500 - val_loss: 1.0653 - val_accuracy: 0.6806\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7812 - accuracy: 0.7200 - val_loss: 0.8242 - val_accuracy: 0.7361\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7322 - accuracy: 0.7280 - val_loss: 0.9295 - val_accuracy: 0.7083\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6197 - accuracy: 0.7720 - val_loss: 0.7559 - val_accuracy: 0.7639\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 74s 1s/step - loss: 0.6448 - accuracy: 0.7620 - val_loss: 1.0022 - val_accuracy: 0.7222\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7073 - accuracy: 0.7500 - val_loss: 1.0896 - val_accuracy: 0.6806\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7722 - accuracy: 0.7420 - val_loss: 0.9389 - val_accuracy: 0.6944\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7640 - accuracy: 0.7180 - val_loss: 0.9100 - val_accuracy: 0.7083\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7400 - accuracy: 0.7380 - val_loss: 1.2376 - val_accuracy: 0.6667\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7301 - accuracy: 0.7240 - val_loss: 1.0454 - val_accuracy: 0.7500\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.7143 - accuracy: 0.7440 - val_loss: 0.9677 - val_accuracy: 0.7222\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6438 - accuracy: 0.7660 - val_loss: 0.9094 - val_accuracy: 0.7222\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.7449 - accuracy: 0.7240 - val_loss: 0.9525 - val_accuracy: 0.7222\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.6842 - accuracy: 0.7460 - val_loss: 0.8386 - val_accuracy: 0.7222\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.6763 - accuracy: 0.7520 - val_loss: 1.0319 - val_accuracy: 0.6806\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6468 - accuracy: 0.7520 - val_loss: 1.0792 - val_accuracy: 0.7083\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 68s 1s/step - loss: 0.6509 - accuracy: 0.7940 - val_loss: 1.1624 - val_accuracy: 0.6667\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.5706 - accuracy: 0.8120 - val_loss: 1.1347 - val_accuracy: 0.7083\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6985 - accuracy: 0.7400 - val_loss: 1.1882 - val_accuracy: 0.6528\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6452 - accuracy: 0.7660 - val_loss: 1.0376 - val_accuracy: 0.6111\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 69s 1s/step - loss: 0.6495 - accuracy: 0.7480 - val_loss: 0.8810 - val_accuracy: 0.7222\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 72s 1s/step - loss: 0.6839 - accuracy: 0.7320 - val_loss: 1.0507 - val_accuracy: 0.7500\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 70s 1s/step - loss: 0.7067 - accuracy: 0.7620 - val_loss: 1.1300 - val_accuracy: 0.7083\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 73s 1s/step - loss: 0.8162 - accuracy: 0.7160 - val_loss: 0.9806 - val_accuracy: 0.7361\n"
          ]
        }
      ],
      "source": [
        "# モデルを学習させるための設定を行い、学習を開始する\n",
        "skf = StratifiedKFold(n_splits=8, shuffle=True, random_state=1)\n",
        "\n",
        "models=[]\n",
        "for ix, (train_index, val_index) in enumerate(skf.split(train_df, train_df['y'])):\n",
        "  train_df_ = train_df.iloc[train_index]\n",
        "  val_df_ = train_df.iloc[val_index]\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "  train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,height_shift_range=0.1,width_shift_range=0.1) # 前処理を（）内に追加可能\n",
        "  valid_datagen = ImageDataGenerator() # 前処理を（）内に追加可能\n",
        "\n",
        "  train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df_,\n",
        "    x_col='x',\n",
        "    y_col='y',\n",
        "    class_mode = 'categorical',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  validation_generator = valid_datagen.flow_from_dataframe(\n",
        "    val_df_,\n",
        "    x_col='x',\n",
        "    y_col='y',\n",
        "    class_mode = 'categorical',\n",
        "    target_size=TARGET_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  nb_train_samples = train_generator.samples\n",
        "  nb_validation_samples = validation_generator.samples\n",
        "  model = gen_model()\n",
        "  model.fit(\n",
        "      # 学習データのバッチを生成するジェネレータ（train_generator）を使用する\n",
        "      train_generator,\n",
        "\n",
        "      # 1エポック（学習の1サイクル）で何ステップ（何回のバッチ処理）行うかを指定\n",
        "      # 学習データの総数をバッチサイズで割った数だけステップを実行する\n",
        "      steps_per_epoch=int(nb_train_samples/BATCH_SIZE),\n",
        "\n",
        "      # モデルを何回学習させるか（エポック数）を指定\n",
        "      epochs=EPOCHS,\n",
        "\n",
        "      # 検証データを使ってモデルの性能を確認するためのデータを指定\n",
        "      validation_data=validation_generator,\n",
        "\n",
        "      # 1エポックで何ステップ検証を行うかを指定\n",
        "      # 検証データの総数をバッチサイズで割った数だけステップを実行する\n",
        "      validation_steps=int(nb_validation_samples/BATCH_SIZE),\n",
        "\n",
        "      callbacks=[callback]\n",
        "  )\n",
        "  models.append(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードの「model.save_weights(save_weights_path)」は、機械学習モデルが学習して得た「重み」というデータを保存するためのものです。\n",
        "\n",
        "＜重みとは？＞\n",
        "モデルは、たくさんのデータを使って「これが正解かどうか」を学習します。そのときに、データに基づいて内部の計算を行うための\n",
        "「数字（重み）」を少しずつ調整していきます。この「重み」は、モデルがどのようにデータを理解するかを決定する非常に重要な情報です。\n",
        "```"
      ],
      "metadata": {
        "id": "Ggf2RoG9xcdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XMtrwkl2zhIW"
      },
      "outputs": [],
      "source": [
        "# 今回学習した重みを保存する\n",
        "for ix, model in enumerate(models):\n",
        "  save_weights_path = os.path.join(weight_dir, f'weights.weights_{ix}_effb6_mix_v2.h5') # 'weights.h5'のファイル名は変更可\n",
        "  model.save_weights(save_weights_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####モデルを学習させるための設定を行い、学習を開始しました。<br>データを順番に取り込んで学習を進め、1サイクルあたりの処理回数や学習の繰り返し回数を指定しました。<br>さらに、確認用のデータを使ってモデルの性能もチェックしています。<br>最後に、学習した結果を保存しました。\n",
        "---"
      ],
      "metadata": {
        "id": "5OqhFF__VBKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け次のコード解説\n",
        "```\n",
        "このコードは、モデルが「どれだけ間違えたか（損失）」を示すグラフを描くためのものです。\n",
        "\n",
        "Training loss（訓練損失）は、コンピュータが勉強しているときの間違いの量です。コンピュータが勉強している間にどれだけ間違えているかを教えてくれます。\n",
        "Validation loss（検証損失）は、勉強しているときに使っていないデータでテストしたときの間違いの量です。勉強に使っていない新しいデータを使って、\n",
        "どれだけ正しく判断できるかを測ります。\n",
        "\n",
        "これらは、モデルが「どれだけうまく学習できているか」を評価するための間違いの度合い（誤差）を表すものです。\n",
        "\n",
        "もしTraining lossが小さくなっているのにValidation lossが大きいままだと、コンピュータは勉強した内容にだけ特化しすぎて、\n",
        "新しい問題に対応できないことがあります（これを過学習と言います）。\n",
        "\n",
        "過学習をもう少し説明すると、コンピュータに大量のデータを使って学習させると、最初はうまく学べていないことが多いです。\n",
        "でも、学習を続けると、そのデータに対してはどんどん正確に答えられるようになります。しかし、学習を続けすぎると、そのデータに特化しすぎて、\n",
        "新しいデータに対しては正しく判断できなくなることがあります。これが過学習です。\n",
        "\n",
        "今回の結果のように一般的には、training lossとvalidation lossが一緒に下がっていくのが適切で、理想的な学習状況です。\n",
        "```"
      ],
      "metadata": {
        "id": "P4z6_81_xvNF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iEgxv7E2Ubtk",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "a84be1f4-d8c9-44c0-8764-d6bd6ec97a27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAALFCAYAAADELKIPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd5wU9fkH8M9sv96444474OggShEFCyAIYo0ViSVGsTeCP42o0Wg0MbHEGjUaFRRjAVFjxQbSLSAgTYrAAQd33HG9bp3fH+N3dw+ubJndmd39vF8vXlzZ8r2d3Zl55nm+z1eSZVkGERERERERBc2g9QCIiIiIiIhiFQMqIiIiIiKiEDGgIiIiIiIiChEDKiIiIiIiohAxoCIiIiIiIgoRAyoiIiIiIqIQMaAiIiIiIiIKEQMqIiIiIiKiEDGgIiIiIiIiChEDKiIiaqO4uBiSJOG1117TeigR99VXX2H69OkYOHAg0tPTYbVaUVBQgNNOOw1PPfUUKisrtR4iERHpnEnrARAREUXboUOHcOmll+Lrr78GoASREydOREpKCsrLy7Fq1Sp8/fXXuP/++/H1119jzJgxGo+YiIj0igEVEREllLq6OowdOxbbtm3D4MGD8Z///Afjxo1rcxu73Y7XX38dDzzwAMrKyjQaKRERxQIGVERElFBmzJiBbdu2obi4GCtXrkR2dvYRt7Farbj++utx3nnnoba2NvqDJCKimME5VEREFLbS0lLMmDEDAwYMgM1mQ0ZGBk4++WS89NJLcLvd7d7n3XffxeTJk5GTkwOz2YycnBwcddRRuO6667Bhw4Y2t62rq8N9992HY445BikpKbBarejRowdOPvlk3H///XA6nQGNc9euXXjrrbcAAE8++WS7wZS/7t27Y9CgQd7vr7rqqk7nl7322muQJAlXXXVVhz+vrq7Gbbfdhn79+sFqtWLChAn44osvIEkShgwZ0uFYXC4X8vPzIUkSfvrppza/a2lpwRNPPIETTjgBmZmZsNlsGDRoEGbNmoWqqqp2Hy+Y15+IiDrGDBUREYVl9erVOOOMM1BdXY1evXrh/PPPR11dHZYsWYJVq1bhgw8+wEcffQSLxeK9z0MPPYQHHngAJpMJJ510EgoLC1FXV4e9e/fi1VdfxdChQzFs2DAAQHNzM8aOHYtNmzYhNzcXkyZN8s512rp1K1atWoXbb78dmZmZXY71k08+gdvtRmZmJs4999xIvSQdOnToEI477jjU1tZi3LhxGDVqFCwWC0477TQUFRVh69at+O6773DCCScccd+FCxfi4MGDOPbYYzF8+HDvzw8cOIAzzjgDGzduRHZ2No4//nikpaVh7dq1ePzxx/Huu+9iyZIl6N27t/c+wbz+RETUOQZUREQUMrvdjosvvhjV1dW48cYb8eyzz8JsNgNQskGTJk3CF198gQcffBAPP/yw9z6PPPIIUlNTsWbNmjYZIADYs2cPWlpavN8vWLAAmzZtwplnnokPP/zQ+/gA4PF4sHz5ciQnJwc03jVr1gAAjj32WBiNxrD+9lB8+umnmDRpEt5//32kp6e3+d2VV16Jhx9+GK+99lq7AdWcOXMAANOnT/f+TJZlTJs2DRs3bsQ111yDp556CmlpaQCUjNbdd9+NJ554AtOnT8fixYsBBP/6ExFR51jyR0REIXv33XexZ88e9OjRA08//XSbYKdv37745z//CQD417/+hdbWVgBAfX09Wlpa0Ldv3yNO5gGgd+/eGDx4sPf7gwcPAgBOO+20No8PAAaDAaecckqb7FdnRBv0vLy8IP5K9ZjNZvznP/85IpgCfIHSO++8432thMrKSnzyySewWq247LLLvD//4osvsHLlSowYMQIvvviiN5gCAJPJhMceewxHH300vvnmG2zatAlA8K8/ERF1jgEVERGFbMmSJQCASy65BFar9YjfX3jhhcjKykJDQwN+/PFHAEBubi6Ki4uxYcMG3HHHHdiyZUunz3H88ccDAB577DHMnTsX1dXV6v4RUTRy5Ej07du33d/169cP48ePR11dHT744IM2v3vzzTfhdDpx3nnntZn39emnnwIALrroIphMRxadGAwGjB8/HgCwatUqAMG//kRE1DkGVEREFLL9+/cDAPr06dPu7yVJ8v5O3BYA5s6di7y8PDz55JMYOnQocnJycNZZZ+Gpp57CoUOH2jzGhAkTcNddd6GiogJXXnklunXrhkGDBuHqq6/Ghx9+CI/HE/B4c3NzAQAVFRVB/Z1qKS4u7vT3V199NQBfeZ/QXrkfoJRVAsCf//xnSJLU7r8XXngBANosUhzM609ERJ3jHCoiIoq6cePGoaSkBJ9++imWLl2KVatW4YsvvsDChQvxwAMP4IMPPsCkSZO8t3/kkUdw44034uOPP8aKFSuwcuVKzJkzB3PmzMHxxx+Pb775BikpKV0+76hRo/DGG29g7dq1cLvdqs+j6iq4S0pK6vT3F198MWbMmIFFixahtLQURUVFWLt2LTZs2IDCwkJMmTKl3ecbO3Ys+vXr1+ljDx061Pt1sK8/ERF1jAEVERGFrLCwEIAvU9Ke3bt3t7mtkJSUhKlTp2Lq1KkAlAzKfffdh//85z+4+uqrsWfPnja3Ly4uxowZMzBjxgwASnfB3/3ud1i9ejUee+wxPPjgg12O95xzzsHtt9+O2tpafPTRR7jgggsC/2MB71ythoaGdn9/+JiDlZycjGnTpuHVV1/F66+/jnvvvdfbov3KK6+EwdC2sKRnz54AgPPOOw9//OMfg3quYF9/IiJqH0v+iIgoZBMmTAAAzJs374hGCgDwwQcfoKamBmlpaRg1alSnj5Wbm4vHHnsMALB3717U1NR0evvjjz8eN998MwBg/fr1AY23X79+uPTSSwEAd9xxR5fzsSoqKrBt2zbv9yIo/Pnnn4+4rSzLWLhwYUDj6Iwo+3v99ddht9u962YdvrYVAJx55pkAlOYgsiyH9bzBvv5ERKRgQEVERCG7+OKL0atXLxw4cAC33347XC6X93e7d+/GHXfcAQCYMWMGbDYbACWL88orr6C+vv6Ix/v4448BAFlZWd5OeB988AGWLVt2RDmd0+nE559/DgBt1ljqyr/+9S/0798fu3fvxtixY7FixYojbuNwODB79myMHDmyTfA0efJkAMAbb7zRppmD0+nEXXfdhdWrVwc8jo6cdNJJGDRoEHbs2IG77roLVVVVGDt2LAYMGHDEbc877zwcf/zx+OGHHzB9+vQ286SEmpoavPjii95tE+zrT0REnZPkcC9pERFRXCkuLsaePXvQt29fbxOH9rzwwgs49thj2yzs27t3b5xwwgloaGjA4sWL0draitNPP73Nwr7r16/HyJEjYTabMWLECG/Tih07dmDdunWQJAkvv/wyrrnmGgDAbbfdhmeeeQbdunXDyJEjkZeXh4aGBnz33XeoqKhAYWEhvvvuOxQVFQX8N1ZUVOC3v/2tt0thnz59MGzYMCQnJ+PgwYP44Ycf0NjYiPT0dHz11VcYPXq0977nn38+PvzwQyQlJWHs2LFISkrC2rVrUV9fj+nTp+OZZ57BlVde6S3VA4DXXnsN06dPP+LnHXn00Udx9913e7+fPXv2EQ0phAMHDuDss8/G+vXrkZKSguHDh6NXr15wOBzYtWsXNm7cCLfbjZaWFthstqBffyIi6hwDKiIiakMEVF355ptvvCV/+/btw6OPPoqFCxeitLQUVqsVRx99NH7/+9/j2muvbdPSu6GhAbNnz8bSpUuxadMmlJWVQZZlFBYW4oQTTsAf/vCHNuWB69evx7x587BixQrs3r0blZWVyMjIQK9evXDRRRfh+uuvR05OTkh/6+eff463334bq1atQnl5Oex2O3JycnDMMcfg7LPPxhVXXNGmTTmgLIz7t7/9DW+99Rb27duHrKwsTJo0CX/961+xfPnydgOnYAOqsrIy9OzZE263GykpKSgvL0dqamqHt7fb7Xjttdcwb948bNiwAXV1dcjOzkaPHj1w8skn49xzz/U2tAj29Scios4xoCIiIiIiIgoR51ARERERERGFiAEVERERERFRiBhQERERERERhYgBFRERERERUYgYUBEREREREYWIARUREREREVGIGFARERERERGFiAEVERERERFRiExd3ySx1NTUwOVyaT0MAEBubi4qKyu1HgZFEbd5YuJ2T0zc7omJ2z0xcbvHHpPJhKysrMBuG+GxxByXywWn06n1MCBJEgBlPLIsazwaigZu88TE7Z6YuN0TE7d7YuJ2j38s+SMiIiIiIgoRAyoiIiIiIqIQMaAiIiIiIiIKEQMqIiIiIiKiELEpBRERERHplt1uh91u13oYYWlpaYHD4dB6GHQYSZKQmprqbRwSKgZURERERKRLTU1NkCQJaWlpYZ/0aslsNuuiizS15XA40NjYiLS0tLAehyV/RERERKRLLpcLycnJMR1MkX5ZLBZVWtkzoCIiIiIiXWIgRbGAARUREREREVGIdDmHasuWLfjoo4+we/du1NTU4I9//CNGjx7d6X2cTicWLFiA5cuXo7a2FllZWbjoootw6qmnRmnURERERESUaHSZobLb7SguLsY111wT8H2eeuopbNq0CTfeeCOefvppzJw5Ez169IjgKImIiIiIIm/MmDF4+eWXA779qlWrUFhYiLq6ugiOCpg3bx6GDBkS0eeIBbrMUI0cORIjR44M+Pbr16/Hli1b8NxzzyE1NRUAkJeXF6nhEREREREdobCwsNPf33777bjjjjuCftzPPvsMycnJAd/+uOOOw7p165Cenh70c1HwdBlQBWvNmjXo168fPvzwQyxbtgw2mw2jRo3CJZdcAovF0u59nE5nm/aVkiQhKSnJ+7XWxBj0MBaKDm7zxMTtnpi43RMTt3v8W7dunffrjz76CP/85z+xbNkymEwmuFwupKSkeH8vyzLcbjdMpq5Px3NycoIah8ViYXIhCFyHCsDBgwexdetWmM1m3Hnnnaivr8err76KxsZG3Hzzze3e54MPPsCCBQu83/fp0wePPvoocnNzozXsgOTn52s9BIoybvPExO2emLjdExO3e+BaWlpgNpt9P5BloLk5+gNJTgYCOOn2z1BlZWVBkiTvz1auXIkLLrgAb7/9Nv7xj3/g559/xvz589GjRw888MADWLNmDZqbmzFw4EDce++9OOWUU7yPNWrUKFx//fW44YYbACiVWE8++SS++uorLFmyBPn5+XjwwQdxxhlntHmuHTt2ICMjA++88w7uu+8+/Oc//8Gf//xn7N+/H2PGjMGzzz6L7t27A1Ba1N9///2YP38+jEYjLr/8clRUVKC+vh5z585t9+8VwaD/NpozZw5eeOEFHDhwAL169cL//d//Ydq0aQCUIPLxxx/H22+/jcrKSmRlZeE3v/kN/v73vwMAZs+ejZdeegkHDhxAWloaTjjhBMyePTuwbRQii8WCgoKCsB4jLgIq0T/+D3/4gzcd6nQ68eSTT+Laa69tN0t1wQUX4JxzzvF+LyLTyspKuFyuKIy6c5IkIT8/H+Xl5ar0xyf94zZPTNzuiYnbPTFxuwfP4XC0rShqbkbBgAFRH0fZjh2Qgyi5A+A9n3Q6nTCbzd7vH3roIdx///3o1asXMjIycODAAUyYMAF33nknLBYLFixYgCuuuALLli3zBmMim+X/Wjz++OO47777cO+992LOnDm46aab8P333yMrK6vNczudTrhcLrS0tOD555/HM888A4PBgBkzZuD+++/Hc889BwB45plnsGDBAjz55JMYMGAAXnnlFSxcuBAnnXRSh4sS+z8PACxcuBD33Xcf/vKXv2DcuHH4+uuvMXPmTOTl5eHkk0/GJ598gpdeegkvvPACBg0ahIqKCmzZsgVOpxM//fQT7r33Xjz77LM47rjjUFtbi++//z7iCyI7HA6UlZUd8XOTyRRwoiUuAqrMzExkZ2e3qS0tLCyELMuoqqpqN+o0m81tr3j40dNOTpZlXY2HIo/bPDFxuycmbvfExO2e2O68806MHz/e+31WVhaGDh3q/X7WrFn4/PPP8eWXX2L69OkdPs60adNw/vnnAwDuvvtuvPrqq1i/fj0mTpzY7u2dTiceeeQRFBcXAwCuuuoqPP30097fz5kzBzNmzMCZZ54JAHj44YexePHioP62F198EdOmTcNVV10FAOjXrx/Wrl2LF198ESeffDL279+P3NxcjBs3DmazGYWFhd6+Cfv370dycjImT56M1NRUFBUV4eijjw7q+UMV7ucxLgKqwYMH47vvvkNraytsNhsAoKysDJIkBV1zSkRERET6JCcloWzHDk2eVy3Dhg1r831TUxOeeOIJLFq0CBUVFXC5XGhtbcX+/fs7fRz/7nrJyclIS0vDoUOHOrx9UlKSN5gCgO7du3tvX19fj8rKSowYMcL7e6PRiGHDhsHj8QT8t/3yyy+4/PLL2/zs+OOPx6uvvgoAOOecc/DKK6/gxBNPxMSJE3HqqafitNNOg8lkwvjx41FUVIQTTzwREyZMwMSJE3HmmWd6exzomS7bpre2tqKkpAQlJSUAgIqKCpSUlHg3+ltvveVNTwLA2LFjkZaWhhdeeAGlpaXYsmUL/vvf/2LixIkdNqUgIiIiohgjSZCTk6P+L5D5U4E6vFvfQw89hM8//xx333033n//fXz55ZcYPHgwHA5Hp49zeKWVJEmdBj/t3T7amdLCwkIsW7YMf//732Gz2fCnP/0JF154IZxOJ1JTU/H555/j+eefR/fu3fHPf/4TkydPjnjrdzXoMqDauXMnZs2ahVmzZgEA5s6di1mzZmHevHkAgJqamjYRuM1mw3333Yempibcfffd+Ne//oVRo0bh6quv1mT8RERERESBWLNmDS6++GKceeaZGDJkCPLy8lBaWhrVMaSnpyM3Nxfr16/3/sztdmPjxo1BPU7//v2xZs2aNj9bvXo1BvjNe0tKSsKUKVPw17/+Fe+++y5+/PFHbN26FQC8mar77rsPX3/9NUpLS7Fy5crQ/7Ao0WXJ39ChQzF//vwOf3/LLbcc8bPCwkL8+c9/juSwiIiIiIhU1adPHyxcuBCnnXYaJEnC448/HlSZnVqmT5+O5557Dn369EG/fv0wZ84c1NXVBdVS/KabbsKNN96IoUOHYty4cfjqq6+wcOFCvPPOOwCUhYA9Hg9GjhyJpKQkvP/++7DZbCgsLMRXX32FvXv3YsyYMcjMzMSiRYvg8XjQr1+/SP3JqtFlQEVERERElAgeeOAB3H777TjvvPOQnZ2NW265BY2NjVEfxy233ILKykrMnDnT2zb9lFNOgdFoDPgxzjjjDDz44IN46aWX8MADD6Bnz5548skncdJJJwEAMjIy8Nxzz+HBBx+E2+3G4MGD8dprryE7OxsZGRlYuHAhnnzySbS2tqJPnz54/vnnMWjQoEj9yaqRZLaZaaOysjLi7RkDIUkSCgoKUFZWxk5ACYLbPDFxuycmbvfExO0evPr6eqSnp2s9jLCZzWZdnF8Gw+Px4JRTTsFvfvMb7zSceNTRe8xsNidW23QiIiIiIgpdaWkpli5dihNOOAEOhwNz5szBvn37cMEFF2g9NN1jQKVDxn37YN68GRg8GOjTR+vhEBEREVGckyQJ8+fPx1//+lfIsoxBgwbhnXfeadNQgtrHgEqHbF98gYwHHgB++1vgqae0Hg4RERERxbnCwkJ8+OGHWg8jJumybXqi82RnK190sjgbERERERFpjwGVDjGgIiIiIiKKDQyodIgBFRERERFRbGBApUNtAiq2VSUiIiIi0i0GVDrkDajsdkjNzdoOhoiIiIiIOsSASofk5GTINhsAwFBdrfFoiIiIiIioIwyodEpkqRhQERERESWWqVOn4v777/d+P2bMGLz88sud3qewsBCff/552M+t1uMkEgZUOsWAioiIiCi2XHnllbj88svb/d3333+PwsJCbNmyJejH/eyzz/C73/0u3OG18cQTT+C000474ufr1q3DxIkTVX2uw82bNw9DhgyJ6HNEEwMqnWJARURERBRbLr30UixbtgwHDhw44nfz5s3D8OHDcdRRRwX9uDk5OUhKSlJjiF3Ky8uD1WqNynPFCwZUOiUCKokBFREREREApflxc7MU9X+BNl2ePHkycnJyMH/+/DY/b2xsxCeffIJLLrkE1dXVuPnmmzFq1Cj069cPkyZNwv/+979OH/fwkr9du3bhwgsvRN++fTFhwgQsW7bsiPs8/PDDGDt2LPr164cTTzwRjz32GJxOJwAluHvyySexZcsWFBYWorCwEPPmzQNwZMnfzz//jIsvvhj9+vXD0KFDMWvWLDQ1NXl/f9ttt+Hqq6/Giy++iJEjR2Lo0KH405/+5H2uUOzfvx/Tp0/HgAEDMGjQINxwww2orKz0/n7z5s2YOnUqBg4ciEGDBuGMM87ATz/9BAAoLS3FlVdeiaOOOgr9+/fHxIkTsWjRopDHEghTRB+dQsYMFREREVFbLS0SBgwoiPrz7thRhuTkrqMqk8mEqVOn4t1338XMmTMhSRIA4OOPP4bb7cb555+PpqYmDBs2DDfffDPS0tKwaNEi/OEPf0Dv3r0xcuTILp/D4/HguuuuQ7du3fDxxx+joaEBDzzwwBG3S0lJwVNPPYX8/Hz8/PPPmDVrFlJTU3HzzTfj3HPPxbZt27BkyRK88847AIC0tLQjHqO5uRmXX345Ro0ahU8//RSHDh3CnXfeiXvvvRdPP/2093arVq1CXl4e3n33XezevRs33XQThg4d2mH5Y1d/3/Tp05GSkoL33nsPLpcL9957L2666SYsWLAAADBjxgwMHToUjzzyCAwGAzZv3gyTSQlrRDD33nvvITk5Gdu3b0dKSkrQ4wgGAyqdYkBFREREFHsuueQS/Pvf/8a3336Lk046CQDw9ttv46yzzkJ6ejrS09Nx4403em9/9dVXY8mSJfj4448DCqiWL1+OX375BW+++Sby8/MBAHffffcRc6xuu+0279c9e/bErl278OGHH+Lmm29GUlISUlJSYDQakZeX1+FzffDBB7Db7XjmmWeQnJwMAPjb3/6Gq666Cvfeey9yc3MBABkZGXj44YdhNBrRv39/TJo0CStWrAgpoFqxYgW2bt2Kb7/9FoWFhQCAZ555BhMnTsT69esxYsQI7N+/HzfeeCP69+8PAOjbt6/3/gcOHMBZZ53lnaPVu3fvoMcQLAZUOsWAioiIiKitpCQZO3aUafK8gerfvz+OO+44vPPOOzjppJOwe/dufPfdd3j33XcBAG63G88++yw++eQTlJeXw+FwwOFwBDxHaseOHejRo4c3mAKAUaNGHXG7Dz/8ELNnz8aePXvQ1NQEt9uN1NTUgP8O8VxDhgzxBlMAcPzxx8Pj8WDnzp3egGrgwIEwGo3e23Tv3h0///xzUM/l/5w9evTwBlPi8TMyMrBjxw6MGDEC119/Pe6880689957GDduHM455xwUFxcDUALUe+65B0uXLsW4ceNw1llnhTRvLRicQ6VTDKiIiIiI2pIkIDlZjvq/Xyv3AnbppZfis88+Q2NjI+bNm4fi4mKceOKJAIB///vfePXVV3HzzTdj/vz5+PLLL3HKKaeENefocGvWrMGMGTNw6qmn4vXXX8cXX3yBGTNmqPoc/sxm8xE/kwOdeBaCO+64A4sXL8akSZOwcuVKTJw4EQsXLgQAXHbZZVi1ahUuuugibN26FWeddRZmz54dsbEADKh0iwEVERERUWz6zW9+A4PBgA8++AALFizAZZdd5p1PtXr1apx++um46KKLMHToUPTu3Ru7du0K+LEHDBiAAwcO4ODBg96frV27ts1t1qxZg6KiIsycORPDhw9H3759sX///ja3MZvN8Hg8XT7Xzz//jObmZu/PVq9eDYPBgH79+gU85mCIv89/vNu3b0ddXR0GDhzo/Vm/fv1w/fXX4+2338aZZ57pbaoBKI01fv/73+OVV17BDTfcgLfeeisiYxUYUOmUN6CqqtJ4JEREREQUjJSUFJx77rl45JFHUFFRgUsuucT7uz59+mDZsmVYvXo1duzYgbvuuguHDh0K+LHHjRuHvn374rbbbsPmzZvx/fff49FHH21zGxFAffjhhygpKcGrr77qzeAIPXv2xN69e7Fp0yZUV1fDbrcf8VwXXnghrFYrZs6cia1bt2LlypX485//jIsuushb7hcqt9uNTZs2tfm3Y8cOjBs3DoMHD8aMGTOwceNGrFu3DjNnzsSJJ56I4cOHo6WlBffeey9WrVqF0tJSrF69Gj/99BMGDBgAALj//vuxZMkS7N27Fxs3bsTKlSu9c60ihQGVTnkDqpoaoIurB0RERESkL5dccglqa2txyimntJnvNHPmTBxzzDG4/PLLMXXqVOTm5uL0008P+HENBgNeeeUVtLa24pxzzsEf//hH3HXXXW1uM2XKFFx33XW49957MWXKFKxZs6ZNkwoAOOusszBhwgRMmzYNxxxzTLut25OSkvDmm2+itrYWZ599Nq6//nqMHTsWDz/8cFCvRXuamppw+umnt/l31VVXQZIkzJkzBxkZGbjwwgtxySWXoFevXvj3v/8NADAajaipqcHMmTMxbtw43HjjjZg4cSLuuOMOAEqXwHvvvRcTJkzA5Zdfjr59++Lvf/972OPtjCRHssAxBlVWVkasvjQYksOBgj59AABlmzdDzszUdkAUcZIkoaCgAGVlZRGtOyZ94XZPTNzuiYnbPXj19fVIT0/XehhhM5vNuji/pCN19B4zm80BZ+GYodIrqxX4dT0AzqMiIiIiItInBlR61q0bAAZURERERER6xYBKzxhQERERERHpGgMqPRMBVU2NxgMhIiIiIqL2MKDSM2aoiIiIiIh0jQGVnv3aWYQBFRERESWqrhafJQqVWt02GVDpGTNURERElMCSk5PR0NDAoIoiorm5GVarNezHMakwFooUBlRERESUwEwmE1JSUtDY2Kj1UMJisVjgcDi0Hgb5kWUZJpOJAVXc+zWgMjKgIiIiogRlMplienFfLugc/1jyp2fMUBERERER6RoDKj1jQEVEREREpGsMqPTs14BKqqsDXC6NB0NERERERIdjQKVnWVmQJQmSLMNQV6f1aIiIiIiI6DAMqPTMZIKcmQkAMFRVaTsWIiIiIiI6AgMqnfNkZQHgPCoiIiIiIj1iQKVznuxsAAyoiIiIiIj0iAGVzjGgIiIiIiLSLwZUOseAioiIiIhIvxhQ6RwDKiIiIiIi/WJApXMMqIiIiIiI9IsBlc55A6qaGo1HQkREREREh2NApXPMUBERERER6RcDKp1jQEVEREREpF8MqHTOk5MDgAEVEREREZEeMaDSOW+GqrERsNs1Hg0REREREfljQKVzcno6ZKMRABtTEBERERHpDQMqvZMkzqMiIiIiItIpBlQxgAEVEREREZE+MaCKAQyoiIiIiIj0iQFVDPBkZQFgQEVEREREpDcMqGIAM1RERERERPrEgCoGMKAiIiIiItInBlQxgAEVEREREZE+MaCKASKgMjKgIiIiIiLSFQZUMYAZKiIiIiIifWJAFQMYUBEdqbTUiKoq7sKIiIhIWzwbiQHegKqmBpBljUdDpL2GBgkTJ+bi3HO7aT0UIiIiSnAMqGKACKik1lZILS0aj4ZIe/v2GdHcbEBJiYnXGIiIiEhTDKhigJycDNlqBcCyPyIAbUr97HYNB0JEREQJjwFVLJAkeLKyADCgIgKA6mrfrqulRdJwJERERJToGFDFCDamIPLxD6haWxlQERERkXYYUMUIT04OAAZURABQVWX0fs2AioiIiLTEgCpGuJmhIvLyn0PFkj8iIiLSEgOqGMGSPyIf/4CKGSoiIiLSEgOqGMGAisiHc6iIiIhILxhQxQhvQFVVpfFIiLTHgIqIiIj0ggFVjPC2Ta+p0XgkRNrjHCoiIiLSCwZUMYIlf0QKjweoqWGGioiIiPSBAVWMYEBFpKitleB2+4IoBlRERESkJQZUMaJNQCXLGo+GSDvV1cY237Pkj4iIiLTEgCpGiDlUktsNqb5e49EQace/IQXADBURERFpiwFVrLDZ4ElJAcCyP0ps/g0pAAZUREREpC0GVDGE86iIjgyoWPJHREREWmJAFUMYUBExQ0VERET6woAqhjCgIvIFVAaD0pyltVXL0RAREVGiY0AVQ7i4L5FvDaru3T0AmKEiIiIibTGgiiHMUBH5MlSFhW4AnENFRERE2mJAFUMYUBH5AqqiIhcAZqiIiIhIWwyoYggDKiKgqkpZ2FdkqBhQERERkZYYUMUQBlSU6GTZt7Bvjx4s+SMiIiLtMaCKIZ6cHAAMqChxNTdLsNuVAIoZKiIiItIDBlQxRGSojFVVGo+ESBti/pTNJiM7m13+iIiISHsMqGKICKikujrA5dJ4NETRJwKq7Gw3bDZlHSqW/BEREZGWGFDFEE9mJgBAkmUY6uq0HQyRBkRAlZPjQVKSWNiXARURERFphwFVLDGZvEEV51FRIvIPqESGigEVERERaYkBVYzxZGUBYEBFiammRpT8+QIqp1NiBSwRERFphgFVjGHrdEpkvjlUvpI/gFkqIiIi0g4DqhjDgIoSmVjUVyn58/2cARURERFphQFVjGFARYnMfw6VJIHzqIiIiEhzDKhiDAMqSmT+ARUAtk4nIiIizTGgijEMqCiRiaYUhwdUzFARERGRVhhQxRg3AypKYCJDlZXlBsCAioiIiLTHgCrGeDNUNTUaj4Qouux2oKGhbYZKdPpjyR8RERFphQFVjOE6VJSoqquV3ZXRKCMjQwmkfBkqzYZFRERECY4BVYzhHCpKVP5rUBl+3XOxKQURERFpjQFVjPEGVA0NgMOh8WiIokdkqES5H+Ar+eMcKiIiItIKA6oYI2dkQP718jznUVEiqa5WFvXNyvIFVMxQERERkdZ0GVBt2bIFjzzyCG644QZMmzYNP/zwQ8D33bp1Ky655BLceeedERyhhgwG3zyqqiqNB0MUPYevQQWwyx8RERFpT5cBld1uR3FxMa655pqg7tfU1ITnn38exxxzTIRGpg+enBwAnEdFiaW9gIolf0RERKQ1k9YDaM/IkSMxcuTIoO/38ssv4+STT4bBYMDq1asjMDJ9YGMKSkSdZahY8kdERERa0WVAFYpvvvkGBw8exIwZM/Dee+91eXun0wmn0+n9XpIkJCUleb/WmhhDe2MRAZWxpkYXYyV1dLbNCaip8QVU4jX69SMLu12K2deN2z0xcbsnJm73xMTtHv/iIqAqKyvDW2+9hQcffBBGozGg+3zwwQdYsGCB9/s+ffrg0UcfRW5ubqSGGZL8/Pwjf1hUBADIcDqRUVAQ5RFRpLW7zQkNDcr//fploKAgAwAgPq4GQyoKClI1Gpk6uN0TE7d7YuJ2T0zc7vEr5gMqj8eDZ599FhdffDF69OgR8P0uuOACnHPOOd7vxVWDyspKuFwu1ccZLEmSkJ+fj/Lycsiy3OZ3aTYbUgE07dmD+rIybQZIqutsmxNQVtYNgBkGQxXKypQlA5zOFADpqKpqRllZnabjCxW3e2Lidk9M3O6Jids9NplMpoATLTEfULW0tGDnzp3YvXs3Zs+eDQCQZRmyLOOSSy7Bfffdh6OPPvqI+5nNZpjN5nYfU09vdvG3+HP/2uVPqq7W1VhJHe1tc/Jf2NftfX2SkpT5VC0tUsy/ZtzuiYnbPTFxuycmbvf4FfMBVVJSEv75z3+2+dmXX36JTZs24fbbb0deXp5GI4scNqWgRON2A7W1bJtORERE+qPLgKq1tRXl5eXe7ysqKlBSUoLU1FR069YNb731Fqqrq3HrrbfCYDCgV69ebe6fnp4Os9l8xM/jBQMqSjR1dQZ4PErQ1HZhX+V/BlRERESkFV0GVDt37sSDDz7o/X7u3LkAgFNOOQW33HILampqcOjQIa2GpzkGVJRoRLlfRoYH/pW6Yh0qtk0nIiIiregyoBo6dCjmz5/f4e9vueWWTu8/bdo0TJs2Te1h6QYDKko0vvlTnjY/Z8kfERERac2g9QAoeN6AqrUVUkuLxqMhirz2FvUFGFARERGR9hhQxSA5JQWyxQKAWSpKDNXVIqByt/m5CKhY8kdERERaYUAViySJZX+UUDrKUIk5VK2tUR8SEREREQAGVDHL8+taVAyoKBGIDBXnUBEREZHeMKCKUcxQUSLpqilFS4sBXCuRiIiItMCAKkZ5A6qqKo1HQhR5VVVGAB2X/AGA3R7VIREREREBYEAVs5ihokTia0rRfoYKYNkfERERaYMBVYxiQEWJpKOSP7MZMBo5j4qIiIi0w4AqRrlzcgAwoKL4J8sdZ6gAX9kfW6cTERGRFhhQxShmqChRNDZKcDiUYKm9gIqd/oiIiEhLDKhilLdtek2NxiMhiixR7peU5GnThEJgQEVERERaYkAVo5ihokTRWbkf4N86nQEVERERRR8DqhjVJqDiAjwUxzpqSCGIrBUzVERERKQFBlQxSpT8SS4XpIYGjUdDFDmBZqgYUBEREZEWGFDFqqQkeJKTAbDsj+KbWNS3owyVzab8z5I/IiIi0gIDqhjGeVSUCETJX0cZqqQk5efMUBEREZEWGFDFMAZUlAi6LvlT/mdARURERFpgQBXDGFBRIuiqKQXnUBEREZGWGFDFMAZUlAi6ylCJLn+cQ0VERERaYEAVw7i4LyUCX4bK3e7vmaEiIiIiLTGgimHMUFEi6KophS+gitqQiIiIiLwYUMUwb0BVVaXxSIgio7UVaGoKLKBiyR8RERFpgQFVDGOGiuKdmD9lMslIT5fbvY2YQ8WSPyIiItICA6oYxoCK4p0IqLKzPZA6iJc4h4qIiIi0xIAqhjGgonhXVWUE0HG5H8CSPyIiItIWA6oY5g2oamsBd/sd0IhiWVdrUAEs+SMiIiJtMaCKYaJtuiTLMNTVaTwaIvV1tQYVwJI/IiIi0hYDqlhmNsOTkQGAZX8UnwLJUDGgIiIiIi0xoIpx3sV9GVBRHPKtQdVxSaso+eMcKiIiItICA6oYx8YUFM/8u/x1hBkqIiIi0hIDqhjHgIrimS9DxYCKiIiI9IkBVYxjQEXxLJimFCz5IyIiIi0woIpxDKgongXTNt3plLh6ABEREUUdA6oYx4CK4pXbDdTWdp2hSkryfc2yPyIiIoo2BlQxjgEVxauaGgNkWQmQsrI6DqisVtn7Ncv+iIiIKNoYUMU4BlQUr0S5X2amByZTx7czGNiYgoiIiLTDgCrGeQOqmhqNR0KkLl9Diq4nRjGgIiIiIq0woIpxbrGwb1WVxiMhUlcgDSkEX0AV0SERERERHYEBVYzzZqgaGgCHQ+PREKknkDWoBF/rdO7SiIiIKLp49hHj5IwMyAZlM7Lsj+JJIGtQCaJ1ektLRIdEREREdAQGVLHOaIQnMxMAG1NQfAmt5I9zqIiIiCi6GFDFAXb6o3gUTIbKV/LHgIqIiIiiiwFVHGBARfGoqsoIILAMlSj5Y4aKiIiIoo0BVRxgQEXxKJSmFAyoiIiIKNoYUMUBT04OAAZUFF9Y8kdERESxgAFVHPCItajY5Y/ihCz7Aqrs7K4X9mXJHxEREWmFAVUcYMkfxZuGBglOpxIcscsfERER6RkDqjjAgIrijZg/lZzsQVJS17dnQEVERERaYUAVBxhQUbwJpiEF4L+wLwMqIiIiii4GVHGAARXFm2AaUgDMUBEREZF2GFDFAQZUFG+CWYMKYEBFRERE2mFAFQe8AVVLC6SWFo1HQxS+4DNUyv8s+SMiIqJoY0AVB+TUVMhmMwBAYpaK4oCYQxVohopt04mIiEgrDKjigSR5s1RGBlQUB4JtSsGSPyIiItIKA6o44c7LAwAYS0s1HglR+Hwlf10v6gv4AiqW/BEREVG0MaCKE64hQwAA5k2bNB4JUfhY8kdERESxggFVnHAecwwABlQUH0Jvmx6xIRERERG1iwFVnHAefTQABlQUH4LNUHEOFREREWmFAVWccB51FGRJgrG8HIbKSq2HQxSylhaguTm4DJUo+eMcKiIiIoo2BlRxQk5NhbtPHwDMUlFsq65WFvU1m2WkpckB3cc/QyUHdhciIiIiVTCgiiMOzqOiOOA/f0oKMOEkAipZluBwRGpkREREREdiQBVHXJxHRXEg2PlTgC+gAlj2R0RERNHFgCqOOBhQURwIJaAymwGjkY0piIiIKPoYUMUR0enPVFICqb5e49EQhUYEVIEu6gsAksROf0RERKQNBlRxRM7OhquwEABg3rxZ49EQhcYXUAWeoQJ8ARVL/oiIiCiaGFDFGa5HRbGupib4kj/A1zqdGSoiIiKKJgZUccYpOv1t3KjxSIhCE26GigEVERERRRMDqjjjHDoUAEv+KHaF0pQCYEBFRERE2mBAFWdEhsq0YwfQ0qLxaIiCV1WlLOwbbIZKlPxxDhURERFFEwOqOOPJz4c7JweS2w3z1q1aD4coaP4L+wbDZlP+Z4aKiIiIookBVbyRJM6jopjlcgG1tZxDRURERLGDAVUcYqc/ilWiw58kycjMZNt0IiIi0j8GVHGIARXFKtGQIjPTA6MxuPuybToRERFpgQFVHPIGVFu3Ak6nxqMhClyoLdMBlvwRERGRNhhQxSF3797wpKVBstuVbn9EMUKNgIolf0RERBRNDKjikcHgW4+KZX8UQ0Lt8Af4l/ypOiQiIiKiTjGgilOcR0WxSARUwS7qC7Dkj4iIiLTBgCpOMaCiWCQW9WVARURERLGCAVWc8gZUmzcDnuBPTom0EM4cKlHyxzlUREREFE0MqOKUa8AAyDYbDI2NMJaUaD0cooCwyx8RERHFGgZU8cpkgnPwYAAs+6PYIRb2ZUBFREREsYIBVRzjPCqKNSJDlZ3tDvq+bJtOREREWmBAFccYUFEskeXwuvz52qYzoCKi+LB1qwm33ZaJvXuNWg+FiDrBgCqOOY85BgBg3rhROVsl0rG6OgkulxIMseSPiAh47bUUvPtuMt56K1nroRBRJxhQxTHn4MGQjUYYq6thKCvTejhEnRLlfqmpHlitwd+fJX9EFG/EfrG0lBkqIj1jQBXPbDa4Bg4EwLI/0j9R7hdKdgpgyR8RxZ+6OmW/uH8/AyoiPWNAFeecQ4cCYEBF+lddHfqivgBL/ogo/tTWMqAiigUMqOJcm3lURDrm6/AXaoZK+d/hkOAOvkkgEZHu1NYqF4jKy41wuTQeDBF1iAFVnGOnP4oV4SzqC/hK/gBmqYgoPogMldst4eBBZqmI9IoBVZwTJX+mAwdgqK7WeDREHQs3oLJaGVARUfxwOoGmJt9pGsv+iPSLAVWck9PS4CouBsAsFembrylFaPV6BoMvqGJARUSxTjSkEBhQEekXA6oEwHlUFAvCWdRXYOt0IooXotxPYEBFpF8MqBIA51FRLAi3KQXg3zpdlSEREWlGNKQQGFAR6RcDqgTADBXFgnDnUAHMUBFR/GCGiih2MKBKACJDZdq9G1Jjo8ajIWofAyoiIh8RUJlMyn6NARWRfjGgSgCenBy4CwoAAOYtWzQeDdGRWloktLaGH1D5Sv4YUBFRbBNNKQYMUBagYkBFpF8MqBKEdx4Vy/5Ih0R2ymqVkZIid3HrjokMFQMqIop1IkN11FFOAEBDgwH19dy3EekRA6oE4Z1HxcYUpEMioMrK8kAK43yBARURxQvRlKJHDzcyM5XMPbNURPrEgCpBMENFeqbG/CnAV/LHOVREFOtEhioz04OiIpb9EekZA6oE4RCNKXbsYE9p0h1fQBXaor4CM1REFC9EQJWV5UFhobJvZEBFpE8mrQfQni1btuCjjz7C7t27UVNTgz/+8Y8YPXp0h7f//vvv8eWXX6KkpAQulwtFRUW4+OKLMWLEiOgNWuc8PXrAnZUFY00NzNu2wTl8uNZDIvISi/qGm6FiQEVE8UIEVBkZMgMqIp3TZYbKbrejuLgY11xzTUC3//nnnzFs2DDcc889eOSRRzB06FA8+uij2L17d4RHGkMkifOoSLdEQBXOor4A26YTUfzwL/ljQEWkb7rMUI0cORIjR44M+PZXXXVVm+8vu+wyrFmzBj/++CP69Omj8uhil/Poo2FbtozzqEh3RMlfuAEV26YTUbyoq1P2Y5mZHvTowYCKSM90GVCFy+PxoKWlBampqR3exul0wul0er+XJAlJSUner7UmxqDmWFwiQ7V5sy7+RmorEts8VpSWKrui3FxPWH+/zab8b7dLMfM6JvJ2T2Tc7okp0O0uy/4ZKhk9e4oufya+Z2IQP+/xLy4Dqo8//hitra048cQTO7zNBx98gAULFni/79OnDx599FHk5uZGY4gBy8/PV+/BTj0VAGDZsgUFubmAKS43f8xTdZvHgIYG4Pvvla/PPjsTBQWZIT9WXp74KgUFBSnhDi2qEm27k4LbPTF1td3r6wH3rz16hgzpjoIC5evyciNycwt4+I5R/LzHr7j7SK5YsQILFizAnXfeiYyMjA5vd8EFF+Ccc87xfi+uGlRWVsLlckV8nF2RJAn5+fkoLy+HLIe+0GkbKSnonpICQ1MTKlesgGvQIHUel1QRkW0eAz75xAaHIwt9+riQmVmJsrLQH8vpTAaQgZqaFpSV1ao1xIhK1O0eT2pqJHz2mQ2/+U0r0tMD24bc7okp0O1eWmoEkAebTUZtbTk8HsBszofTKWHdugoUFYXXEZWii5/32GQymQJOtMRVQLVy5Uq8+OKLuP322zFs2LBOb2s2m2E2m9v9nZ7e7LIsqzceSYJz6FBYf/gBpg0b4Bw4UJ3HJVWpus1jwBdfWAEAU6a0ApARzp/u35Qi1l7DRNvu8eTFF1Pxr3+loaKiHrfd1hjUfbndE1NX272mRvk/I8MDWZYhScoCv3v2mFBaakBhofYXfil4/LzHL112+QvFihUr8MILL2DmzJk49thjtR6ObrHTH+mJywUsWqRMfDr99PDXR2PbdNJCSYlybXLfPjYMIHXU1Pg6/AlsTEGkX7rMULW2tqK8vNz7fUVFBUpKSpCamopu3brhrbfeQnV1NW699VYASjD1/PPP46qrrsKAAQNQW1sLALBYLEhOTtbiT9At59ChABhQkT788IMFtbUGZGW5MWqUI+zHE13+2DadoqmiQjn5razkiS6pw79lusDW6UT6pcuAaufOnXjwwQe938+dOxcAcMopp+CWW25BTU0NDh065P39119/DbfbjVdffRWvvvqq9+fi9uTTJkPl8QCGuElSUgz64gslOzV5sl2VSdbMUJEWDh5UTnBF+3+icNXVHRlQiXlTDKjiX3OzhAMHDOjfn3PlYoUuA6qhQ4di/vz5Hf7+8CDpL3/5S4RHFD9cAwZAtlphaGiAce9euIuLtR4SJShZBr78Ur1yP8A/oFLl4Yi6JMvAwYMiQ8WAitQhMlQZGb75NsxQJY4bbsjC4sU2fPZZJYYPd3Z9B9Ic9/6JxmyGc/Bg5UuW/ZGGtm0zYe9eE6xWGaecYlflMf2bUhBFQ2OjhJYW5VBaVWUMq6kKkcCSv8S1ZYsJixcrFxtXr7ZoPBoKFAOqBOQ8+mgAgHnjRo1HQolMlPuNHWtHcrI6Z6FiDhVL/ihaRHYKUN53jY1871H46uqU91F7AVVpKQP3ePbaa741FHfu1GUhGbWDAZUOVVdL+Mc/0rBsWWQe39uYYvPmyDwBUQDULvcDOIeKoq+iom224NAhHlYpfL6SvyO7/DU1GVBfz31cPKqtlfDee0ne73ftYkAVK7jn16Gnn07Dv/6VivvuQ0SuQnkbU2zcGJknIOpCebkB69dbIEkyTjtN/YBKWYdKtYcl6tCRARXLsSh8om16VpYvoEpOlpGdzbK/ePbOO8lobTUgJUXZ7sxQxQ4GVDp0002NsFplLF8OLFumfv2sa8gQyAYDjIcOwXDwoOqPT9SVr75SslMjRzqRl+fp4taBEyV/sizBEX4XdqIu+Zf8AcxQkTp8Xf7aXhniPKr45XYDc+cq5X4zZyoLhJeVGdHczGxkLOCeX4cKCjy44opmAMDjj6epfqVdTkqCa8AAAGxMQdqIRLkf4MtQASz7o+g4PEPFTn+khtpaZf/lX/IHMKCKZ998Y8WePSZkZHhw9dVNyMpStvWuXdzWsYB7fp269dZGJCUBa9dasGiRVfXH986jYmMKirLGRgkrVijv6SlT1A2ozGbAYOA8KooesaivwLWoSA3tdfkDGFDFszlzlOzUJZc0IylJRt++IqBi2V8s4J5fp/LyPLj1VuXrf/5T/SyVdx4VG1NQlC1ZYoXDIaG42IUBA1yqPrYk+cr+2DqdokEs6tuzp/JerqzkiS6Fx+EAmpvbD6hEYwoGVPFl504jliyxQZJkXHllEwCgXz/Xr79jQBULGFDp2J13AsnJHmzcaPG2mFaLCKgs69er+rhEXRHv5dNPb4UUgZiHnf4omkSGauhQZfFNzqGicIn5U5IkIz29ozlUPMmOJ6+/rmSnJk2yo3dvZRv37asEVMxQxQbu+XUsNxe49lplLtU//5kGj3pz9+EcNkxpTFFWBkNZmXoPTNQJlwveBQvVnj8lMKCiaBJzqBhQkVp8LdNlGA57OxUVMUMVb5qaJMyfnwwAmD69yftzkaFiQBUbuOfXuRtuaERamgc//2zGp5+ql6WSU1LgGjIEAGBZu1a1xyXqzA8/WFBba0BWlhujRkWmDZ9/63SiSGpp8WUTjjqKJX+kjo7mTwG+DNXBgwY4nVEdFkXIggVJaGgwoE8fF8aPt3t/7p+h4jIg+seASueysmRcd51yxeKJJ9Lgdqv32I5jjwXAgIqiR5T7TZ5shylCF93EHCpmqCjSRHbKapW9V5PZlILCJTr8tRdQdevmgcUiw+ORUF7O4D3WyTLw2mtKud/06U1tMpLFxS5Ikoz6egMz3zGAWygGXHddIzIzPdixw4wPP0zq+g4BEgGVmQEVRYEsR65duj/br4lcBlQUaSKgystzo1s35WpXXZ0Bdntn9yLqnK/k78iAymBgY4p4snKlBdu3m5Gc7MHFFze3+Z3N5ivxZNmf/jGgigHp6TJuuEFZ5O3JJ9PgUqkxmmPUKACAZcMGcBVUirRt20zYu9cEq1XGKadE7oyTJX8ULWJR37w8DzIyZJhMynuPWSoKR2clfwADKq3dfXcGzj8/R5WskchOTZ3ackQDEoCd/mIJ9/oxQizytnu3Ce+9p06Wyt23LzyZmZBaW2H++WdVHpOoI6Lcb+xYO5KTI1cQzpI/ihaRoere3Q2DQSnHAoBDh3iiS6ET8/IyM9vfT7IxhXYqKw14440UrF5txfXXZ4V1LXr/fqP3uOjfjMIfO/3FDgZUMSI1VcYttyhZqqefTlNnMqok+eZR/fijCg9I1LFolPsB7PJH0eOfoQKAnBwRUPHQSqETc6jaK/kDuLivlpYvt3q//v57K+67LyPkhhFz5ybD45Fw8sl2DBzYfumRL0PFba133OvHkKuuakZurht795q8LTbDxXlUFA3l5QasX2+BJMk47TQGVBQf/OdQAUBurvJ/ZSUPrRS6rkr+REB14ABPsqNt6VIloDr+eDskScabb6bg9deDPx9rbQXefPPIVumH69uXc6hiBff6MSQpyT9LlarKxGenmEfFgIoiSGSnRo50eq/mR4oo+eMcKoo0sahv9+7KSY/IUFVV8USXQhdoQFVayvdZNMmyL0N1xx0NuOeeBgDAAw9kYOVKS1CP9dFHSaipMaKw0NXpRUaRodqzx6Ta/HmKDAZUMeaKK5qQn+/GgQMmvP12+Fkqx4gRkCUJpj17YDh0SIUREh3pq6+iU+4H+GeoIv5UlOAOHhRzqJQT39xc5X9mqCgcIqDKyuqoKYVyZr1/v5HrE0XRtm0mHDxohM3mwfHHO3DzzY244IJmuFwSbrghC3v3BhbgyjIwZ47SjOL3v2/udAmRggI3bDYPnE4J+/YxgNYz7vVjjM0GzJihXBV59tk0tLSE93hyejpcAwcCYNkfRUZjo4QVK5SrelOmRDOgYoaKIktkqETJn2idzjlUFA5f2/T2o6XCQiXQamoyoK6O+7loEeV+J5zggM0GSBLw+OO1GD7cgZoaI66+OhtNTV1vj7VrzdiwwQKrVcZllzV3eluDAejTR9mvsNOfvnGvH4MuvbQZPXq4cPCgEf/9b0rYj8fGFBRJS5ZY4XBIKC52YcCAyNcssG06RYPT6SvtExkqX5c/HlopdJ0t7AsoZc05OWxMEW3LlikB1fjxvvkWSUnAK69UIzfXjZ9/NmPmzEx4uqhqF63SzzuvBdnZXZfAs9NfbOBePwZZrcBttylzqZ57LhXNzeGdOHrnUTGgoggQbWFPP70VUhRiHLZNp2gQZX0mk+w9KWLbdAqXx+PfNr3jk212+ouu1lbgu++UeVKHr6PYo4cHr7xSDYtFxsKFSXjyybQOH6eiwoCPP1aWvumsGYU/rkUVGxhQxahp05rRq5cLhw4ZvVc7QuXt9PfTT+CsR1KT0wksXhy9+VMAS/4oOkSHv27dPDD8eiQVXf6YoaJQNTZK8Hg6b5sOsNNftK1ebUFrqwHdu7sxaNCR50nHHefEI4/UAgCeeioNn35qa/dx3nwzGU6nhGOPdWDYsMDWv2GGKjZwrx+jzGbgttuUuVQvvJCCxsbQTx5dAwbAk5YGQ3MzTFu3qjVEIqxebUFtrQFZWW6MGhXGCohBYMkfRYOvIYXb+zNflz9Dl2U/RO0R86dsNg9s7Z+TAwB69BCd/niSHQ2i3G/cOHuHlRa//W0Lrr1WqR6aOTMTmze33TZOJ/DGG0ozsauvDiw7BfgyVAyo9I0BVQy76KIW9OnjQk2NEa++GkaWymCAY+RIAGyfTuoS5X6TJ9s77WSkJpb8UTQcvqgv4Auo3G7Je2JMFAxfuV/n7ftY8hddIqA6vNzvcH/+cz3Gj29FS4sBV1+djaoq337ggw+A8nIjcnPdOPvswDuKiQxVebkxoKYXpA3u8WOYyQTcfruSpXrppdSwuv04RWMKBlSkEln2rT8VrXI/gCV/FB2HL+oLABaLb94Ly/4oFDU1nTekEIqKGFBFy6FDBmzapMyfGjeu84DKZAL+/e8aFBe7UFpqwvXXZ8Hxa3HGc88p/19+eTMsQSxblZnpa0LCLJV+cY8f4847rwUDBzpRV2fAK6+khvw47PRHatu61YS9e02wWuUur+qpiQEVRYNvUd+2J76idTrXoqJQdLWor8AMVfSIxXyPOsrpXWuuM5mZMl57rRqpqR58950V99+fgc2bTVi+XGlic8UVgZf7CSJLxcYU+sU9fowzGn1ZqpdfTvG2Ww2WKPkz7doFqbpatfFR4hLZqbFj7UhOjt7qk6Lkj3OoKJLEHCr/DBXA1ukUnmADqoMHDXAG1tuAQhRouZ+/AQNceO65GkiSjDfeSMENN2QBAM48sxX5+cFPsPTNo2IArVfc48eBs89uxYABTjQ0GPDVV53MYu2EnJ0NV9++AADLunVqDo8SlBblfgAzVBQdvgxVRwEVT3woeIG0TAeU+XpWqwxZllBWxvdapMiy//pTwR3LTjvNjrvvVi54i1K9YJpR+Ovbl4v76h0DqjhgMABnnKF80JcssYb8OA7OoyKVlJcbsH69BZIk47TTGFBR/BFzqA4v+ROt01nyR6EQGaqMjM6z+gYDUFDAsr9I277dhPJyI2w2GaNHB9+p9pZbGnH++c0AgOHDgdGjQ0snstOf/nGPHycmTlRS0UuXWuF2d3HjDjh+XeDXzICKwiSyUyNHOtt0QYuGJGXNRJb8UcS43b6A6fCSP//W6UTBEmX7XWWoAM6jioalS5WL1GPG2DttY98RSQKeeKIWf/tbHebNQ8iL2/vPoZKjV0FPQeAeP04ce6wDqake1NQYsXGjOaTH8Gao1q0DF1GhcGhV7gf45lA5HFLIFxeIOlNdbYDbLUGS5CMmqYvvKyt5kkvBC7TkD2Cnv2gQDSnGjw+9sZLNBlx9dTMGDQp9HL17u2AwyGhqMnjLjWPBli0mTJiQi88+C206Sixh7jBOmM3K5P/PP0/CkiVWjBgRfFrZNXgwPMnJMDQ0wLRjB1zhfPopYTU2Sli5UjkITZkS/YBKlPwBgN0uRbUhRqxpbJSwd68RpaVG7N1rwr59xl//mVBaasSoUQ688UZ1yFdV45VYgyonx3PE+mpsSkHh8JX8MUOlNbsdWLVK6W8ezU617bFagZ493dizx4SdO03o3j348kMtzJ6dgh07zHj77WScdVb0zweiiQFVHJkwwRdQ3XZbY/APYDLBOXw4rN9+C8vatQyoKGiyDDz4YDocDgl9+rgwYIAr6mPwD6haWhhQAUB9vYQPP0xCSYmpTQDV1eKz33xjQ1mZAT16MGPtz7cG1ZGvi2ibzoCKQiE+k1lZXe+3CguV/euBAwyoImH1agtaWw3Iy3Nj8ODoH8sO16+fC3v2mLBrlwknnaT/gEqWlWMIkBjNNOL/L0wgEyYoV1DWrrWgvl5CenrwJ5KOUaNg/fZbmH/8Ebj0UrWHSHHupZdS8NZbKTAYZPzlL3WaZDYMBsBqlWG3S2xM8avHH0/D7Nntr1OXleVGz57+/1zo2dONu+/OwIEDylpiPXro/+AdTR11+AOYoaLwBNo2HQB69FDef6WlDKgiQZT7jRtn10WWvk+f2FqL6ueflYYeALBvnxF2u5Jpi1exsVUoID17utGvnxM7d5qxYoU1pPSqaEzBTn8UrC++sOFvf0sHANx/fz0mT9auRMJmUwKqlhbNhqArW7Yo8yrPOKMFJ53k8AZNRUVupKW1f+GlXz83DhwwYc8eI044IZqj1T9xktBehkrMoWppMaCpSUJKCjOkFDjRlCLYkj9ZDr3hAbVPNKTQutxPiLVOfyI7BQAej4Q9e0wYOFD7TF+k8BJanBFZqlDbpzvFAr/bt0Oqr1dtXBTfNm0y4ZZbMiHLEq64ognXXhvaWhtqYev0tvbsUQ7At9zSiGuuacKUKXYMGeLqMJgCgF69lAPf3r2xcfCOJl/J35EZquRkGTYbs1QUvNZWJRAHgstQNTcbvIEYqaOqyoCNG5X5U+PG6SOg8u/0FwsWL257Hhor4w4V9/ZxRlxJWbLEGlJrTU9uLly9ekGSZVjWr1d3cBSXysoMuPLKHLS0GDB+fCv++ldtSv38iU5/bJ2unKSVlyu7+uLiwNse9u6t3HbvXpYTHa6zkj9J8u/0x0MsBU50+DMY5E4vdghJSb45e2xMoa4VK5RgasiQ6C/90RGRodq71whnaMtZRU19vYTVq5XXcNQopWScARXFlBNPdMBqlbF/vwm//BLam9e7HtWPP6o5NIpDzc0Spk/PRnm5EQMGOPHiizUwh9a1X1XMUPmUlpogyxJSUz3Iygr8xKB3b+XgLbJb5HPwYMclf4BvHlVVFU9yKXAioMrI8MAQ4NmZKPtjYwp1LV2qlKvppdwPAAoKPEhK8sDtlrBnj7639/LlVrjdEvr1c2LiRGX6CQMqiinJyb7VvEMu+xPrUXEeFXXC4wFmzszExo0WZGW58frr1cjI0Md8EQZUPiUlyoG3d293UJlDZqg6JjJU7ZX8Ab6AihkqCoavZXrg+1G2TlefLOtv/hSgZL/79lW2t97nUX3zjfL6TZxoj7lSxVBxbx+HJkxQrgaEGlC1aUzBJbmpA488kobPPkuCxSJj9uwa7wm4HoiAiiV/vjlQIuMUKDGHqrLSiOZmvo6CLPvmUHXv3lGGiq3TKXhiHlQwmWRfp7/4PlmNpl9+UbrTWa0yjj9ePwEVEBuNKfzbpZ96qt07ZgZUFHNEY4rvvrOG1OXMOWQIZJsNhtpaGHftUnl0FA/mzUvC88+nAQD++c9ab1ZUL8QcKmaofBmqXr2CC3gzMmTvxHhmqXxqayU4HMr7qqsMFQMqCkYwLdMFZqjUJ7JTY8bYkZSk8WAOI7I9eg6oRLv0pCQPxoyxe7NqtbUGVFfH7zGZe/s4NGiQC/n5brS2SvjhhxCyVBYLHMcco3zJeVR0mFWrLJg1KxMAMHNmAy66SH+9yVny5xNqhgrw7/THkzVBZKcyMz2w2dq/jS+g4utGgfOV/AUeUBUVMaBSmx7L/YRYyPYsXqzsGE86yQGbTZmK0qOH/scdLgZUcUiSfGV/oo41WE6uR0Xt2LXLiOuuy4bLJeE3v2nBH//YoPWQ2sWSPx8xeTmUkkyR1WJjCp+DBzufPwUAubks+aPg+TJUwc+hYlMKddjtwLff6qtdur9YyFCJ885TT/WthRorc7/CEdbe3uPxoLm5GW532wOLw+HAu+++i8cffxyvvfYaqqurwxokBU9cWRFXWoLlEI0pmKGiX9XUSPj973NQW2vAyJEOPPVUTcCdqKKNJX8KWQ4vQyXuwwyVj28Nqo6zCDk5LPmj4IVT8nfwoAEOfVVex6Qff7SgpcWA3Fw3hgzR3yK0IqCqqDCioUF/xzf/dukTJ/oC0ljIrIUrrL39ggULMH36dGzfvt37M1mW8Ze//AULFizAmjVrsHDhQtx3331obGwMe7AUuHHj7DAYZGzfbsb+/cFvZhFQmbZuhdSk7SKtpD2HA7juumzs3m1CYaELs2dX66623B9L/hQHDxrQ2irBaJS9J17BEBmqkpL4PQgGq7NFfQXfOlQMRClwdXXK/iqYkr+cHA+sVhmyLKGsjO+3cImL0Mo5lMaDaUd6uuzNgOsx2+PfLt2/KoIBVRc2btyIzMxMDBkyxPuzH3/8ETt37kRBQQGuvPJKDB8+HFVVVVi0aFHYg6XAZWXJGDFCWflNrKcQDE9BAVw9ekDyeGD+6Se1h0cxRJaBe+7JwLffWpGS4sFrr1XrZqHDjjCgUojsVGGhO6T1wTiH6kii5K+jDn+Abw5Vba1B9wtwkn6EkqGSJF+nP86jCt+yZUpANX68/sr9BD0HJ/7t0v3pecxqCSugqqioQGFhYZufrV69GgDwhz/8AWeddRbuuusupKen47vvvgvnqSgEYjG1sNejYtlfQvvPf1LwzjspMBhkvPBCDY46Sn9lEIcTJX+JPocq1A5/grjCuG+fCR59x9BR41vUt+PXNCvLA4NBeQ9WVenwMjfpUigBFcDGFGqprjZg40blypOeAyq9zqM6vF26PxFQlZSY4NbPCiuqCmtP39jYiMzMzDY/27ZtG7Kzs9G3b18AgNFoxIABA3Do0KFwnopCIOZRLV9uhSuEc2BR9mdmY4qEtW+fEY8+mg4AeOCBekyerN+DjD/RfY0ZqtDnTwFKZstolGG3S97MTKITi/p2797xWYHBwHlUFDwRUGVlBbf+Y2Gh8vlmQBWe5cstkGUJQ4Y4O81Aa02v2Z4tW9q2S/dXWOiG1SrD6ZSwb198vk/D2tMbDAa0tvq6eDQ2NqKsrAyDBg1qc7ukpCQ0NzeH81QUghEjnMjM9KC+3oB164Kv9+ECv/SPf6TBbpdw0kl2XHNN7MylY8mfIpwOfwBgMvmufovgLNH5MlSdn3CxdToFK5S26QA7/aklFsr9AP8Mlb62t8hOiXbp/gwGoE8ffQaCagkroOrevTt27NgBz6+1IGt/zWQMHjy4ze3q6+uRnp4ezlNRCIxGX9vPJUuCn0flPPpoyGYzjIcOwbh3r9rDI51bu9aMDz9MhiTJeOCBOkgxFJto1Tbd6QReeCEVO3fq40An2p2HmqEC/Fun6+Nv0prIUHVW8gf4WqdXVjJDRV3zeHxNKYIt+ePivuGT5VgMqEy6utbdXrt0f2LcDKjacdxxx6G+vh6PPfYYPvvsM7z55pswGAw47rjjvLeRZRm7d+9GXl5e2IOl4In1qEJqn26zwXn00QC4HlUoKisNaNHfmrcBkWXgwQczAAAXX9yCo4/W/7wpf1q1Tf/f/5Lw8MPpmDEjK6rP25FwM1SAf2OK+DwIBqOxUUJzc9dNKQBfhopzqCgQDQ0SZDn4Ln+ArylFaSkDqlDt3GnCgQMmWK0yxozRd//5Xr2UUuzmZgPKy/Wxf/Fvl374/ClBr6WKaglrS5x77rkoKirCunXr8Prrr6O2tha/+c1v0K1bN+9ttm7dioaGhiOyVhQdYh7V+vVmVFeH3j7dzMYUQamsNOCEE/JwySXdur6xDn3yiQ1r1liQlOTBrFn1Wg8naFqV/G3dqpTW/vSTBdu3a3vQaGqSvOVm4WSoRDDGDJWvw19KigepqZ1fGhYBFVunUyBEuV9SkgfWIK9/+meo9JSxiCXiovPo0Q7vBTm9slh8lQN6CU7826V31ASJAVUnkpOT8Y9//AO33HILLr/8cjzwwAO47LLL2tymoaEBZ555Jk466aSwBkqhKSjwYPBgJ2RZwvLllqDv32YeFQVs/XozWluVuWuhNATRkt0O/P3vSonuTTc1oaBAv5NzO6JVyZ//gWLBAm0X6hIBUGamB+npoZ8gMEPlE8iivoJvDpU+riBT52QZ+PBDm2YT5n0d/oL/rIoMVUuLATU1MVSbrSOxUu4n6K3T3+LF7bdL9ycCqt279TFmtYW9p7dYLBg/fjzOPfdcHHXUUUf8fvTo0bjqqqvQu3fvcJ+KQjRhQhjzqH4NqMybNyNm69c0IE6s3W4p5iYKz5mTgr17Teje3Y2bborNBbl9JX/RfV7/gOq995I1bQ8rAqDi4vAiepGh4lpUgXX4E7p1U27DgCo2fPaZDTffnI27787Q5PlDbZkOKF1NxZy9WDve6IHDAaxapVxwHj8+ygeNEOkp2yPLvvPLjsr9AF8QWF5uRGNj/AX+Ed3TNzc3Q2b+WXOnnOKbRxXs5nAXFsKdlwfJ5YJl48YIjC4++e/kYulEtLragGeeSQMA3HVXPZKTY/Pzq0XJn9Pp29Y2m4zyciNWrgw+K6yWcNegEkSGqqLCmPDregXa4Q9ghirWiAn1mzaFsAK2CmprQ2tIIfjK/rQ/wY41P/5oQXOzAd26uWNinUVAXxmqztql+8vMlJGTo7xP9TButYW1p9+7dy8+++wzHDhwoM3PN23ahFtuuQXTp0/HtddeiyVLloTzNBSm0aMdsNk8OHjQiJ9/DvJNLElcjyoEbQOq2NlxPPVUKurrDTjqKCemTo3djKQWAdWePUa4XBKSkjy4+GJlmYh3302O2vMfLtw1qITMTNk7ST7R51H5Sv66DlJzc9k2PZasXKkEVIcOGb3d9qIpnAwV4Cv7Y6e/4In5U+PH22GIkesfIkOlh8BEtEs/+eQj26UfTk+ZNbWF9dZZuHAh5s6dC4vFdxW2oaEBjz/+uHch38bGRrz44ovYvXt3eCOlkNlsyroAQHhlfxY2pgjYL7/EXobql1+MmDs3BQBw//11MMbGsNslSv6imVERB7a+fd2YNk0JqBYutGlW2qBGhz/BN48qht8UKhBNKQJZ9FNciT10yMBGATq3d6+xzYUvLU5Sww2oRIaKnf6Ct3y5ElCJZWZigchQ7d1rhEPjpoQiuztxYtflkgyoOrBt2zb07NmzTVe/ZcuWobW1FZMnT8acOXNwyy23QJZlLFy4MOzBUuh886iCb58uMlRc4DcwtbUSqqp8B7VYOQl9+OF0uFwSJk9uxbhx+m4b2xX/DFW03rLiANGvnwsjRzrRt68LLS0GfPZZ8Bcx1KDGGlSCby2q+DsIBiOYDJUo+XO5JG85F+mTyE4JWpzs1dWF3pQC8C3AzQxVcKqrJfz0k1LmGSsNKQDlok5Kigcej6TpfjmQdun+GFB1oK6uDjk5OW1+tmHDBhgMBlxyySVITk7G+PHjUVxcjB07doQ1UAqPWI/qhx8saGoK7uDuHDYMstEIY3k5DIeVd9KRDt9RxELJ38qVFnz5ZRKMRhl//nPstUk/nAioPB4JTmd0ntM/oJIkaFr253b7rlSrkaESjS1i5eJApIgMVSABldUKpKeLtagS+3XTOzHX0WBQ9htaZqiCXYNK4OK+oVmxwgpZljB4sBP5+bHT0VaS9DGPatmyrtul+/OVKsbf+zSsgKq5uRnJyW1PFn755RcUFxcjLS3N+7OCggJUV1eH81QUpr593ejZ0wWnU/J2swmUnJwM568dHFn21zVR7peVpexctGrDGyiPB3joIaVN+hVXNKN//9iYlNsZEVAB0Sv78w+oAOCii5Q5aKtWWaNehlNWZoTTKcFikZGfr0bJHzNUgC9DFUjJH+C/FlWMTMxIQLLsy1BNmqRcYdfi6rlaTSnY5S8477yjnMOKKp5Yoodsj6/cL7DXzz8IjLeCp7DXoaqpqfF+X1paisbGRgwcODDsgZG6JMm3wxATMIPh9C/7o06Jq0Xi9T50yBh0VjCaFixIwqZNFqSleXD77Q1aD0cVFovvanO0GlMcHlAVFrpx0knKe+D996O7JpXo8FdU5FZlLhznUCmrRoiyrEAyVABbp8eCHTtMqKgwwmbzNZPR4oq/r+QvvIDq4EEj7LEXG2hi/Xozli61wWiUceWVTVoPJ2h9+4qOedrsl/3bpYuLEV3p1csNo1FGc7MBZWXxtV8M668pLi7Gtm3bUF5eDgBYvHgxAByxHlVFRQWysrLCeSpSgTjBFx1ZgsEFfgMnTqxHjnR6D456zVI1N0t49FElOzVzZgNycmKn5KEzkhTdTn/+8+bEFTgAmDrVV/YXzatxaq1BJYiywX37TPDEx1skaJWVyva1WuWA57mwdbr+rVihXGAcPdqBwYOV+uBdu4xRf5+HW/KXne3x7vPKyvR5vNGb555LBQCcf35L2MtLaEHrDFWg7dL9WSy+iod4m0cV1l5+8uTJcLvduOuuuzBr1ix8+umnyMjIwLG/ZjMAoKWlBSUlJejZs2fYg6XwnHyyHSaTjJISk/cKdqC8rdM3bgQvf3VOlPz16+dCz576vrL/0kspKC83omdPF6ZPj70rdJ0RJxfRKPkTV7Tz891ITfWdbJ99diuSkjzYtcuEdeuit76N6PCn1klCjx7KVcXWVsm7uG2i8Z8/JQX4lvIFVPr8/JNv/tTJJzvQq5cbJpOM1tboXz0XAVVWVmhXXiSJrdODsW2bCQsXJkGSZMyYEZsL2Gs9h8q/Xbo1iMInrQPBSAlrj3HiiSfi4osvhsfjwZ49e5Cbm4vbb78dZrPvxOHbb7+F2+0+ImtF0ZeWJuO440T79ODK/tzFxXBnZ0NyOGDevDkSw4sLLhdQUqLsJPr3d6FnT+UAp8fGFOXlBjz/vHKF7p576rtcPyLWiNbp0chQiQODf3YKAFJTZZx5ptIQZsGC6DWnULPDHwCYzb6SIj2+l6PB1+Ev8AxCbq7ymnEOlT653cC33yrHwrFj7TCbtbt6Hm7bdAAoKlI+7wyouiayU2ee2YoBA2Jz3rA43mi1dtrixYG3S/enpzW01BT2Xn7q1KmYM2cOXn75ZTz33HMYPHhwm98PGzYMjz76KCZOnBjuU5EKTjklxHlUkgTHcccBANKeekqJHOgI+/YpzQBsNg969HB7S6X0mKF6/PE0tLQYcOyxDpx7bnA7xFgQzZK/w+dP+bv4YqU5xYcfJkUtuavmGlSCrzGF/t7L0SAyc927B/6aihLaqioGVHq0aZMZdXUGpKd7cPTRSrmfFid7LS2+/VSoJX8AO/0Fas8eIz78UJnXGqvZKUC5YCf2R9EOTurqJKxZE3i7dH8MqDphMpmQnp7e7u+6deuG4uJi2OLt8neMEp1YVq60Br0YXOP//R88Nhtsixcj/aGHIjC62CfK/fr0ccNggF/Jn752HJs3mzBvnpIxeeCBuoBLmGKJ2OVoHVCdfLId+flu1NYasGhRdPaD4v2mVobK/7H09l6OloMHQ8lQiS5/PMHVI9Hd74QT7DD9+rbWooxKNKQwGmWkpYU+2ZKd/gLz/POpcLslTJzYimHDorSuRoSI92u0M6rLlwfXLt2fVmOONNUum7lcLmzfvh3fffcdvvvuO2zfvh0uZjF0Z+hQJ3Jy3GhqMnivLgTKOWwYap95BgCQ+uqrSH7jjUgMMaaJHYRoPe6bzK+fA5wsAw89lAFZlnDuuS047rjYPqB0RJT8RXMO1eElfwBgNAIXXaQ0p1iwIPLd/mprJW/5kJoTrZmhCnxRXyHWmlJUVhoweXIu/v73tK5vHAdWrFCOgWPH+q4uanH13L8hRTgXtziHqmtlZQbv2oCxnJ0StJpHJdqlB5udAnyfsX37jGiNo+KYsLeA2+3Gu+++i88//xwtLS1tfpeUlIQzzzwTU6dOhVGN3r0UNoNBKft7//1kLF1qxUknBZemaj3nHNTfeSfSH38cGffeC1dxMRzjxkVotLFH7NTEDsO/KYUsQxeZoEWLrFixwgqLRcY998T+Ir4diVbJn9sN7N7dcYYKAKZObcHzz6dh0SIbqqoMEe2mKDJIeXluJCer11pQtE5P1LWoQin5i7W26W+9lYyffzajutqAP/0pPpZQ6IjDAXz/vWhI4Tsp1OLqua9lenifV5Ghiva6d7HkpZdS4XBIGDPGjjFjgizT0SEtGjz4t0sPJaDKzfUgLc2DhgYDSkpMGDw4PpIvYe3lPR4PHnvsMXzwwQdoaWlBSkoK+vTpgz59+iAlJQUtLS14//338dhjj8GTqL12dSic9ukA0DhzJpovvBCS243sG26A8Zdf1BxeTPPv8Aco6wBJkrLmgh7mUTidwF//qpTnXnNNU0y2ig1UtAKq/fuNsNuVRXRFE5LDDRzowvDhDrhckrd2P1JEB0+1t62e5wNGQyglfyJD1dRkiNoC06GSZWD+fOXK/aFDBrjjd9cAAFi3zoLWVgO6dXNj0CDfCZ3/1fNozXkMt2W6UFTky1DF26KpaqiuNuC//1Xe43/4Q+xnpwBtLgCE0i7dnyTFZ6e/sM7wFi9ejPXr13u7+82ePRuPPPIIHnnkEcyePRt33HEHcnNzsX79eu8aVaQ90Zhi82ZzaC2QJQm1jz8Ox3HHwVBXh5wrr4RUXa3yKGPT4SV/ViuQn68cJPVwIvq//yXhl1/MyM52Y8aM+L4CHa226WKbFxe7Ol1Ed+pUJYMf6bK/SMyf8n+8igqj7oODSBD7ymBK/tLSZFityvtQ71mq1ast3g6lbreEmhp9jzdcYv2pk0+2t6kcyM31IDXVA1mWvK9HpNXWKgPIygovoCooUN6bra2GuN9+oXjllRS0tBgwbJjDex4U60Rgsnt39NZOW7w4tHbp/uJxHlVYn7ilS5fCYrHg/vvvx5gxY474/ejRo3H//ffDbDZj6dKl4TwVqahbNw+OOUZJdQfd7U+w2VD96qtwFRXBVFKC7OuvR9BdLuJMba3kXW/Gfy6NKJXSw2T+jz9WTuavvroJGRnxfQkzWm3TO2tI4e+881pgMsn46ScLtm+P3HshEh3+AKUcSVxB18PFgWhyOn1rSXXvHvhZiyT5yv703jp9/vy2gX68rzfmv/6UP/+r59Gal6JGy3RAuYAnAn7Oo2qrvl7CnDkpAJS5U3oov1dDz57+a6dFZ5uL+VPBtkv3F4+d/sLaY+7btw9HHXUU8vLyOrxNXl4ejj76aOzbty+cpyKVhdw+3Y+nWzdUv/46PKmpsH77LTL+9Cckcp2BOLE+fHFXUXql9UloY6PkvSp71llxNBO0A76Sv8g+T6ABVU6OB5MmiTWpIpelUnsNKn++eVSJdbImgiGjUQ56/lssNKZobpbw0UfKe1Jk1OK5M2Fzs4S1a0VDiiMzFdG+eq5WyR/A1ukdef31FNTXGzBggBNnnBE/xz+z2bev37kz8ts8nHbp/pihOozT6URycteLVdpsNjid8dlJLFaJ9unffGMLa0kp1+DBqHnhBcgGA1LefhspL72k0ggD98orKbjnngzNl8bq6MRanIRq3elvyRIr7HYJxcUuDBwYH5NAOxOtkr/OOvwdTpT9vfdecsTmqEQqQwX4XxyIn4NgIESHv9xcDwxBHjV9AZV+T3A/+8yGpiYDevd24fjjlYxNPGeofvjBAqdTQlGRq925htplqMK/IMlOf0dqaZHw8stKdurWWxuD/gzrXd++0VuLSrRL798/+Hbp/vw/Y/FyHT6st1W3bt2wffv2ThtOeDwe7NixAzk5OeE8FansuOMcyMpS1sb57rvg2qcfzj5pEurvvx8AkP63v8H65ZdqDDEgtbUSHnooHXPnpmDZstCzbWroKKASjQq07o72xRdK3fMZZ7TGTblDZ/RW8gcAkya1IjPTg/Jyo7fkSE0Oh28NmkhkqHxrUSXWyVoo86eEWMhQiTXpLr642dvFMJ4zVP7lfu3tC7XKUIVb8gew01973norGVVVRvTs6cL557d0fYcYE80LAL5yv/DmoIkgsLbWgOpq/e4bgxHWXzF8+HAcOnQIc+bMaXfNKZfLhdmzZ+PQoUMYMWJEOE9FKjOZgClTlA/E55+Hv9ho07XXoul3v4Mky8i69VaYtmwJ+zEDsXSpcrUEUOfvCEdHJ9Z6WIvK6QS+/toXUCWCaHT5a26WvHXrgQRUVqsylwqAdy0UNZWWGuHxSEhK8ngXlVWTby2qxMpQiQ5/wcyfEnJz9d06fd8+I1atUk6SLr64xdvFMJ4zVKL0ub1yP8D/BDU6++y6OmUfpUbJn3+nP1IuMv3736kAgJtvbvQu4BxPonUBINx26f6SkmQUFsZX2V9Ye8zzzz8fKSkp+PLLLzFjxgy88cYb+OKLL/DFF19g7ty5mDFjBr766iukpqbi/PPPV2nIpJYzzlBO7D7/PCn8lKskoe5vf4N97FgYmpqQfdVVMFRUhD/ILoggAQC+/NIWtS437Tm8w58g1qLav9+oWVnit99aUF+vtAg+9tjEaB4SjYBKnHBlZ7uRlRXYh2jqVGWR34ULbWhsVHdsvg5/7ohkIRO1dXooi/oKYs6VXgOqd99V5k6dfLIdRUVu79+o9yYaoaqtlbBxoxkAcNJJ7Z8U9umjvAbV1UbU1EQ+nR+JDJXIVCe6995LRlmZEd27uzFtWrPWw4mIaGWoKisNKC83wmCQMXp0+F0S4611elh7zOzsbPzpT39Ct27dUF1djU8++QSzZ8/G7Nmz8emnn6K6uhrdunXDvffei+zsbLXGTCoZN86O5GQPysqM2LDBHP4Dms2ofukluPr2hWn/fmRffTXQErn0utvtSz9LkozKSiPWrlXh7wiBywVvi93DMxXdu3tgtcpwuyXNDnJffKGcNE2Z0tppa+94Ikr+IjmHKphyP2HkSCf69nWhpcWAzz5TN6vqW4MqMpG7f8fKeKl7D8TBg2JR31AyVMp99FhC5/H4MqW//a1ysunLUOlvvGr47jsrZFmZAyKWtDhcSoqM/PzozUuJREDFDJVyXH7uOSU7dcMNjbBpW8QSMSJDtW+fMaJNmMT83B493Kq8ltHOBEda2Jeg+vfvj2eeeQa33norJk6ciBEjRmDEiBGYOHEibr31VjzzzDMwGAzYEqUSMApcUpJvkd+FC9XZ08iZmah6/XV4MjNhWbcOmX/8Y8Q6/61da0ZNjREZGR6cfbayFxHzhKJt3z4jHA4JNpvsPaAJBgNQVKTd3BNZ9pVDnn56YpT7AdHJUIUSUEmSMlcFUL/szz9DFQmFhW4YDDJaW6W4Lgk7XHgZKuU+eljY+3Dff2/B3r0mpKZ6vJ0/RYlivGaoVqwQ3f06z9RHcx5VXZ3yWgea5e6MOP5UVET25DoWfPJJEkpKTMjM9OB3v4vP7BSgXLRJS1PWTotkObY4vqi1aLyYR8UMlR+TyYRx48bhxhtvxD333IN77rkHN954I8aNGweTyYSXX34ZDz30kBpPRSo780xlj6vm/CN3376ofvllyCYTkv/3P6Q+/bRqj+1PlPtNmNCKs89WMmELF6pQvhgCsUPo08fVbgchLbujbdhgRnm5EcnJng7nDMSjaAZU4sAQqIsuUt6vq1ZZVZ087uvwF5kMldnsO2FLpHlUIngUDRuC4ctQ6S9AEc0ozj23xZvRFRkqPWbU1LBypW9B385Eq4zK7VZ3DlVWlse79tmPP6rf+CZWeDzAv/6lZKeuvbYRKSnxm1KXpOhcABAXhNU6vrDkL0RyItWHxJBJk1phMsnYscOMX35R7wDqOOkk1P3jHwCAtGeegRSB0r9Fi5SAavJkOyZOtMNikbF7twm//BL9D2dXmQot16ISwfLEifa4LXloTzTapoeSoQKUoETM33j/ffU2im8Nqgj1ZPd77ERai0o0pRDBRjBEl7+aGoPmSzv4a2qS8Omnyntv2jTf/llkqGprDbDH2fWXgwcN2L7dDEmSceKJnf9x0cpQ1ddLkGX1AipJ8nVgE8fIRPT111Zs3WpGaqoH06c3aT2ciIvGBQBxfFErQyXGvGePSVf7xlDp75IZRVVGhuy9Uifm2ail+dJL4e7eHZLTCfOmTao+9v79Rvz8sxkGg4wJE1qRliZ7sy9adPvrOqDSbi0q/3bpiSTSbdNl2XfwCjagAnzNKebPT1YlqyrLviAnUnOoAP/W6fFxVbErHo+voUQoJX/Z2R5IkgxZlnTVHviTT2xobjagTx8XjjvOV/6WkSHDYonPxX1FN8Ojj3Z2WV4nPtO7d0f2fS7K/VJSPLColFA69VRlX794sbZLiWhFloFnn00DAFx5ZZMq63vpXTQuAKhdAaHMxfLA6ZTiotGRfvbupBkxr0ateVRekgTHr+3yzevWqfrQixYpB4pRoxzIzlZ2luLv0GIeVUcd/gSt1qLatcuIbdvMMJlk70E2UUS65K+83ICmJgOMRjmkA8zZZ7ciKcmDXbtM+OGH8MdTVWVAc7MBkiR732+R4GudHvsHwEBUVxvgckmQJDmkVvRGoxJUAfrq9Dd/vlLuN21ac5uOkJLky1LF2zw5//WnuiJOUHfvNkW0e6xoSKFGdko45RQ7jEal8iQeTlSDtWKFBevWWWCzybjuuvjPTgG+92skM1Rqz9E1GHwdNeOh7C++9pYUEhGIrFtnQVmZum8Jpwio1q9X9XHF/KlJk3xlG1OmtEKS5Ij8HV3pKkMlTrijnaH68kvldTrxREdCXKXzF+kuf2Kb9+zpDunKcmqq7J3DOHdu+OMRHf4KCtywRvDCtK/TX2KcqIkOf9nZHphDbCIqArFDh/TxmpWUGPHdd1ZIkuzNlPqL13lUXa0/5a9nTzfMZqUBSyS7s/o6/Km3f87IkDF6tBI0JmKWSmSnLr20KSLr8emRbz5SZN6rLS1Aebn6FRDRXJQ40hhQEfLzPd61idTO7ogMlUXFgKqlRfJOLJ482Zd1ycvz4NhjnQB8gUQ01NVJ3hMPcZXocCJjcOiQEc3NkV/XRBDlj2LNsUQS6QxVOOV+wsUXK9vl7bcR9nyVSHf4E3xrUcX+ATAQ4cyfEsRaVHppTCG6S44fb0ePHkf+XfGYodq714h9+0wwmXzBRmdMJt+FsEhePVezZbo/sfBqos2jWrPGjFWrrDCZZNx0U2JkpwCguFj5zNbUGFFbq/4xr7RU+QykpXlU6UYpRLObZqTFz96SwiKulKsdUDmHDwcAmPbsgaG6WpXHXLnSgtZWCT16uDB4cNuTWTFPKJplf2JHkJ/vRlpa+zuajAzZe8CM1pX9ykoD1qxRUiennZZY5X6AsiwAELmAKtSGFP5OPtmOggI3amqAJUvCu5Ic6Q5/grg6efCgMaINP/QinA5/gghQ9FDyp6w9pXw4xNpTh9NzZ8JQiezUyJGOgDu+RWOdHHHyq3ZANWmSss9ftcqaEJ9T4V//UrJTU6c2H7GESTxLTZW9czwjMe/PNz9X3UXj4ylDFdRfsHTp0pCepL6+PqT7UfSccUYLHn44HatWWVFbK6lWfiBnZMDZvz/Mv/wC8/r1sJ96atiP6d/d7/AP9umnK3/HypVW1NVJyMiIfJmbr3V25yeyPXu6UFtrwd69xiMCwUj46isbZFnC8OEOFBYmRtmDP5GhstsleDxot519ONTIUBmNysWM2bNT8PXXNkyZEnrgq3YHpo5kZspIT/egvt6AffuMGDgwDtozdUJkqEJZ1FcQGSo9BFQrV1qwf78J6emeDt9v8bi4r5g/1dX6U/6isU5OpDJUAwe6UFjowv79JqxcacHkyXHWsrEdVVUGfP21DZIk4+abG7UeTtT16eNCRYURu3ebMHKkU9XH9lVAqLu/j6fW6UH9BS+88EKkxkEa69vXjYEDndi+3YxFi2zedXLU4BwxQrWASpaVdqhA23I/oV8/NwYMcGLHDjO++caG88+PfKlboJmKnj3d2LhR7Jgif3BLxMV8/Yk5VICSpUpOVje4ViNDBSjvYyWgskKWEfLVP3EFsbg4sgGOJClZqk2bLNizJ/4DqnAW9RX0NIdKNKM477wWbxb3cPG2uK8sB77+lL9oXD2PVEAlScoc47lzTVi0yJYQAZXYB+bne9CvX+Jkp4Q+fVz4/ntrRDJUYo6u2hfsxGesosKIhgapwyqfWBDU3rJbt25h/SN9E+Vyarcdd4wcCQCwqNDpb+tWEw4cMMFm83jX8TmcCCCi1T490BNr39yTyJ9UNTZK3hKXRGuXLogMFaB+2Z/d7mswEm5AdeKJDqSkKJmQTZtC7HoA9Vex74yWC1VHmxolf2ItKq0zVPX1Ej77TKw91X65HxB/Gart202orDTCZvPNFw5ENOZ3iLbpkWgaJDq7Llpk1WTB+2jbv195vxYVxfdFno6Ijnm7d6v/uY1Uhio9XfZewIn1LFVQo3/++ecjNQ7SgTPPbMWzz6bhm2+saGlBh1cvg9Wm0184l+Dh6+43dqyjw/GdcUYrnnsuDYsXW2G3I6Idz4CuW6YLPXtGr9PfkiVW2O0SiotdcZ9B6IjBAFgsMhwOCWqvK11SYoLHIyEtzRN2FymrFZgyBfjgAyX7eswxwZdq+HdgivQcKuU5Eqd1uhpNKbp108ccqk8+SUJrqwEDBjg7LQmKtwyVyE6NHu0I6nggLpbs329U9ZjoT8yhUrNtujB2rAM2m4z9+03Yvt2EQYPi+1ggAqpEmjvlr0+fyK2dJi4ER6LpUb9+LlRWGrFrlwkjRqhbqhhN8bG3JFUcc4wThYUutLQYsHy5elGIc8gQyBYLjNXVMO7bF9Zj+dqld5x1GT7cifx8N5qaDN4DaaS43b6dV1eZimhe1fdfzFfNCaSxRmSp1J6U7Z+VVOP1Pecc5X/x/g7Wvn2R6cDUEV/r9Ni+ohgIkaEKp+RPZKi0bkM+b55Ye6ql0/etf9v0eMhsrFgR+PpT/nJyPEhP90CWJZSUROa9HqmSP0ApexaVHInQ7U+0t2dAZVL1cxvpRePjpdMfAyrykiRfedjChSpeirNa4Rw6FEB4C/xWVxuwdq1SEtVZQGUwwDvZOtJlf/v2GeFwSLBa5S534v7r90TyJMXp9J2YJ2q5nyDmUald8hdoI5JAnXWW8v/69ZaQsgKivr13b3UCvK6IFr3xnqGSZV/ZWzhNKUQWs6rKoFmAsnOnEWvWWGAwyLjwwo7L/QDfeFtbJTQ0xPYVGbcb+Pbb4OdPAcoxMdLzqHwlf5FpHCTK/hJhPSqRoerRI1EDKuXvrqszoKZGvdP7ykoDWlsNMBi6Ps8JRbw0pmBARW2I+UdffWWFS8ULEWqsR/XNN1Z4PBKGDHF22bVOBBJffmmL6Cr3/ifWxi7OLYuK3JAkGc3NBlRXR+6j9+23FtTXG9Ctmzuo+QLxKFJrUakdUOXnAyNGhL4QZzTnTynP48tQxUMGoyN1dRLsduW9E06GKidHua/DIaG+XpsARTSjmDDBjvz8zneKSUky0tLEPKrYPk3YtMmM+noD0tM9IZXTiqv+kTrZi2SGCvCtR/XDDxbU1cV2cNyVRC/5S0qSUVCg/O1qtvoXF8569AhtEfuuMENFcWnMGAeystyoqTHi++/V++S0mUcVokWLOu7ud7gTT7QjLc2DykqjN6sVCcGcWFut8J7IRPLK/hdfKNnFKVNauwzy4l00Sv7UMmmScuITStlftDr8CYWFbhgMMlpbpZg/4e6MyE5lZHhgCyPZnZQEpKZq15jC7QYWLBDlfp1npwTfWlSxvRMRzXlOOMEOUwjna5HMUMmyf0AVmSsTvXu70b+/E263hKVL4ztLlegBFRCZeVSRXpLDf723SF4Aj7T4PRJSSEwm4LTTlBM7NcvlRIbKvGEDQkl9uVzAkiVdz58SLBbf7SK5yO8vvwR3Yi2u7EeqMYUss126v0iU/MmyOmtQHU4svrx0qdJMJRjRWoNKMJt9Jy3xPI/q4MHw508Jvk5/0Q9Qli+3orzciMzMjteeOpzoahjrAXMo60/5i+TV89ZWXwY0UhkqwHexZvHi+J1H1dIiobqaAVUkAipfQ4rIXLDr1csNk0lGa6sBZWWxewEntveUFBFnnqm0RPv8c5tq5Tzuvn3hSU+HobUVpq1bg77/mjUW1NUZkJXlxrHHBla2IQKKhQuTIlaWJE6su+rwJ/TsKeaeROYkdMMGM8rLjUhO9mDs2Phfd6QrkSj5q6kxeK8qi4U/1XD00S507640U/n+++CuJIsMVTQ6/AkieAsn27psmQWzZ6fotmzQtwZV+Ce7WrZOnz9fyVqff35LwF3u4iFD5XDAW2kR7PwpIZIZKtHhz2iUkZISuQ+BuLiolM1H7Gk0tX+/8rlKTfUgPV2nO5QoEBcAIpGhikSHP0C5QCeOXTt3xu7+hgEVHWHcODuSkjw4cMCEjRtVKpczGOAcPhxAaPOoRBnUxIn2gMvYJk60w2KRsXu3yZtJUluwpV9ipxGpDJXITk2caA+rRCleRCKgEtu8sNDVZvHgcBkMvhMfsXh1IDweX5e/SB3w2iPey6Guq9bYKOHaa7Px5z9nqLefUZlomR7OGlSCVq3Ia2slfP65ElD99reBlfsB8dE6fe1aC1pblfmkobYMFxdNamvVn/vqP38qks1kjj/egdRUDw4dMmLDBn1+1sJ14IDYL7sTurNtJNaiEvv4SHT4E8TnLJKLaEda7O4pKWKSkpQTcgBYuDACZX8hBFTBzJ8S0tJkb5YmEt3+6usl7xXsQAMqkaGKVJmUf7t08pX8qTmHSlxBU7PcT5g8WXm/fvVV4Nnh8nID7HYJRmNkOjB1xJehCu29/L//JaGpSTkE6fUgKkr+wunwJ+TkiE5/0b0C+9FHSbDbJQwe7AyqKUM8LO4rls04+WR7yCfZSUkyevSIzNXzSDekECwWYPz4+G6fzvlTiki0Tvct6hu51zYeOv0xoKJ2iRNyNQMR58iRAILPUO3da8T27WYYjTImTAiubEOU/UViHpX44Hfv7kZaWmB7Lt9aVOqfpOzaZcS2bWaYTLK3VW6ii2SGKhIB1dixdlitMvbuDTyrKg52RUXukCbdh8p/GYBgyTLwxhvJ3u8j8XlQg6/kT40MlSihi+5hV3T3mzatOaigQmSoYnkOVajrTx2uX7/IXD33tUyPfImayH6Li5PxJtFbpgu9erkgSTIaGw2qlBf7LxofyQwVAyqKW5MmtcJkkrF9u1m1q3IiQ2Xatg1SU1PA9xMHgNGjHcjICO7AM2VKKyRJxrp1FpSVqft2D6V1ttgh7d9vVLUtPaC0iAeAE090ROUAHQtiLaBKSfEtxBlo2Z8W86eU5ws927p+vRmbNvm6iOo3oBIZKjWaUiiPUVUVvcPu9u0mrFtngdEo48ILW4K6b6xnqJqbJaxdG978KUHs49UOqMQcqoyMyE9sEu3Tf/optLXu9I4ZKoXN5nsN1JhHFa1F4xlQRciWLVvwyCOP4IYbbsC0adPwww8/dHmfzZs346677sJll12GGTNmYMmSJZEfaBzLzPSd2Ik23OHydO8Od0EBJI8H5o0bA76fmD8VSHe/w+XlebxNLETAoZZgO/wBSumQ1SrD7Za8q7qrRWQTzzgjuBOneBaJtum+gCoyB25R1hpo+/Rod/gTxMWB8nIjWoJ8y/33v0rWRJxI6rVToJhDpWZTimiezL77rrLvnjSp1ZshC1Ssz6H64QcLXC4JRUWusEuVInWyF62SP0B5Dw8bFvpad3rHgMpHzXlU4oJdr16RnZsmPmP79wd/PNELXe4p7XY7iouLcc011wR0+4qKCjzyyCMYOnQoHnvsMZx99tl48cUXsT6MNY/IV/an6jyqX8v+Ap1H1dQkYdUqMX8qtKuM4u9Qu+xPHFwD7fAHKI0HiorCm8zfnspKA9asUa7GivbbpH7bdJfLF8BEIkMF+Focr15tQU1N1+OO9hpUQlaWjPR05USwtDTwE826Ogn/+59yon/rrY0AItekJVwiQxWLbdNraiS8+WYKAGDatODPUEQQWVVlgDsGz1HF+lMnn+wI+0Qwchkq5f2VlRWd1nsiSxWP7dMZUPmIeVRqvF9986cie3zJyfEgI8MDWZZQUqLPC2xd0WVANXLkSFxyySUYPXp0QLf/8ssvkZeXh9///vcoKirCGWecgRNOOAGffvpphEca38R6JWvXWlBers5bRSzwa1m3LqDbr1hhhcMhoVcvV1CBi7/TT1dOJlautKq6UnyoaxGJTIJIpatBaWIgYfhwBwoL47QvbghEp0O1Aqq9e41wOiXYbB7vivRq69nTjcGDxUKcXZ/4aJWhkiRflqqkJPAg4f33k9DaasDgwU5ccIHSdS4SJbDhamqSvE0z1GhKIUr+otU2/bnn0lBXZ8CQIc6A157yl5PjgcEgw+ORolqmqBbf+lPhLx8h9vElJSZVg0sRUAVbyh4qUeWxdKkVzsD7k+iexwPv+kUMqNRdi8pXUh7Z11WSIrvmWzTE5qgPs2PHDhxzzDFtfjZ8+HC89tprHd7H6XTC6bdHkSQJSUlJ3q+1Jsag5Vh69JBx7LEOrF1rwZdfJuHKKwNvudsRp1+GKpC/TXQkmjzZDoMhtNeif38PBgxwYscOM775xoYLLgg/g+N2+3ZW/fu7g9pOvsYUpjb3C2eb+7r72XXx/tUL/zlUarwuu3YpLYf79nXDaFTndW5vu0+ebMfWrWZ8/XXX71dfhiq496Eaevd2Y9Mm8V7ueuK/0oxCyZpccUUz8vNlWK0y7HYJZWWmqAeFnRFzh5KTPUhLA4DwXtvcXOW92NCgdGVMSorcPr601IA5c5TX+d57G2AyBf8cJpMSVFVWGlFZaUT37rE1L1OUZI8Y4Qz7NS4q8njfpwcOhPc+9f+8t22bHvnP7ogRLmRnu1FdbcSaNVacdFJ4zTr0orpa+UxJkoyCgui8lsGK5jmdaEG+e7cp7Ofz7/AX6bH36+fCunUW7NplhiTF3jqacRFQ1dbWIiMjo83PMjIy0NLSAofDAYvFcsR9PvjgAyxYsMD7fZ8+ffDoo48iNzc34uMNRn5+vqbPP20asHYt8M03Gbj77oyu79CVKVMASYKptBQFBgPQvXuHN5Vl4JtvlK9/+9sUFBSkhPy0U6cC//gHsHRpFm6+OeSH8dq1C7DbAasVOP74vIDXxgKAo49W/q+sTEVBQeoRvw92mzc0AMuXK19fcUUaCgrSgrp/PPO9lMkoKEju7KYBqaxU/h861IyCgoKwH8+f/3a/5BLgueeAJUuSkJub1GH3vvp6oLpa+XrMmFykp6s6pC4ddRTw6adAVVUGCgq63j+sWAFs2wYkJwO33JKBjIwMFBcrP2tqyoPKL2lYduxQ/u/Rw6DKts7PVxawdDoBo7HA+96MxD7+7ruV/dPEicBll2WHXPLWo4fynne7c3W1bbrS2Ag0/3r9b8SIPKQeuZsNWv/+wObNQE1NHsaMCf/x8vPzvXNF+vQJ7POjhrPPBt54A/j++xxcdFFUnjLiSkuV/3v0kNCrl77fqNE4pxPvzz17zMjPLwir5PXAAeX/kSMj/x4dMQJYsAA4cCA2z2PiIqAKxQUXXIBzzjnH+72IvCsrK+HSQe2JJEnIz89HeXk5ZLUWEwjByScbAeRh8WIZW7ceVKU0oduAATBv347qL76A/bTTOrzdxo0mHDiQi+RkDwYOPIiystCfc+xYM4Bu+PRTD0pKDsIa5pzcb7+1AshGnz5OVFQcCuq+mZk2AFnYvt2BsrIq789D3eaffGKD3Z6FPn1cyMqqDOt1ijd2exKATNTUtKKsrCbsx1u3LgNAMgoLG1BW1hj24wHtb/fevYGsrO6oqTHgk08OYcyY9utzNm0yAchFdrYbTU0VCKJ5pipycpIBZGDLlsBe36efVl6/885rRnNzHZqbgR49srBtmw1r19ZiyBD9zEbeskX5nObk2FFWVq3KY3brloeyMiM2bz4Ei8UVkX385s0mvPFGNwASZs06hPLy0Gu7srKyANiwdWsthg/Xz7bpilKCmoekJA8aGg6ioSH8x+zVKwubN9uwenUdhg8PvVrD//NeUZENwAJZrkZZWXSuyJ90kg1vvJGFDz904v/+L7hjl1799JPyWc3Pb3tM1ZNontPZbIDBkI+mJgnr1x9Efn5oJcuyDOzcmQ9AQmpqBcrKIltBkJenbMdNm/SzHU0mU8CJlrgIqDIzM1FXV9fmZ3V1dUhKSmo3OwUAZrMZZnP7K4ZrGcAcTpZlTcfTt68LAwc6sX27GV9/bQ269W57nCNGwLx9O8zr1qF18uQOb/fVV0rUM368HRaLHNYidcOGOZCf70Z5uRErVli8k3NDtWOHkpLq29cV9Pbp1Us5wdmzx9jufYPd5p9/rrxOyppb4b1O8ca/5E+Nz9GuXaFv9674b3eDAZg4sRXvv5+Mr76yYvTo9ktz/OvbtdhP+K9F1dXzV1dL+OQTpaz6d79r8t7et9h1148RTWJR37w8j2rj6tbNjbIyIyorfe9HtffxDz+cBlmWcO65LRg2zBHW/kB0BqyoMOhq23TF10xEvW3Xr58TgA07d5pUeUxZlv3mUEXv8zt+fCuMRmVJlL17Dd7PXywrLVVex8JCbfaDwYjGOZ3ZrOxX9+wxYdcuY8jLPhw8aEBrqwSDQVncOtIvbd++yrnRzp0meDxyRLsKRkLszTRtx4ABA7DxsDbcGzZswMCBAzUaUXwRi+Oq1e1PrEfVVac/MX9KdD0Lh8Hga7KhxmLFoXT4E8QB7NAhI5qbw9tjOJ2+9tqimyH5iC5/arVNj+QaVIcT7dPF56A9Wq1BJYiASrk40Plt3303GXa7hGOOcWD4cF/WRDyG3jr9qdnhT/B1+ovMoXf5cguWLLHBbJZx1131YT+e+NtjbXFf0epdvN5qiESnv2i2TRcyM2Ucd5xygSZeFvllh78jqdGYQsyfKix0o4PchKqKi5VFievrDTHZCEeXI25tbUVJSQlKSkoAKG3RS0pKcOiQkp5+66238Nxzz3lvP2XKFFRUVOC///0v9u/fjy+++ALffvstzj77bC2GH3fOPFM5sVuyxKrK+gCiMYVl/Xp0dBZWWWnA+vVKBvHUU9UJFETA8eWXNnjCPH6Fc2KdkSH7rb8T3knkt99aUF9vQLdubhx7bHxMMFaTL0MV/mM1NEjeRgXRCKgmTLDDaJSxbZu5w/eJVh3+hMJCNwwGGa2thk7XKzq8GYX/lUf/Ji16Ul6uvOZqdPgTItk63eMBHn5YmUT3+983obg4/PeEyFBVVuor2O1KJIJhXwcydV4Ltxuorxdt06ObVREVGp1drIklYk3HwkLtp2vohS+gCv396r8GVTQkJfmC4ljs9KfLgGrnzp2YNWsWZs2aBQCYO3cuZs2ahXnz5gEAampqvMEVAOTl5eHuu+/Ghg0bcOedd+KTTz7BjTfeiBG/ZkIoPMOGOdGjhwvNzQYsXx7+FS3n4MGQrVYYamth/DVoPtzixVbIsnI1O9T638OdeKIdaWlK16q1a9sv9wxUuJkK/1KpcIhFl6dMaQ2qMUai8C/5C5fY5nl5bqSlRf4EKCND9pb6dXQlWas1qASLBejRw91mLO1ZudKC3btNSE314Pzz216V8QVU+noDi+A51HKZ9kRycd8PP0zCxo0WpKZ6MHOmOvP7REASa4v7ioBVzQyVWMj7wAGTKhlv/yU8xHpu0SLap69apc5FUq0xQ3Uk3+K+4WSool8BEalFtKNBlyMeOnQo5s+f3+Hvb7nllnbv89hjj0VyWAlLkpTszuzZqfj88yRMmRJmCZ7FAufQobCsXQvL+vVo6dPniJv4t0tXi8WiHEj+979kfPGFDccdF9pkbTUyFT17urFxo1iLKrS/UZZ97dJFWSa1JQIqNU6AolnuJ0ye3Ipvv7Xi669tmD79yInwIqujZbvxXr3cKC01Ye9eE44/vv3P1H//q2SnLrywBSkpbYPRnj2V11OUwCYn62MORGRK/pTHUrucxW4HHn1U6Yp1882NyMlR5wTdfw5VLInEtsvO9iAz04PaWgN27TJi6NDw9gOi3C811YMOpnNHzODBLhQUKPP5Vq2yqlJWryURUImLO6ROyZ8WFRD9+rmwdGlsBlSxtZckzfjK5ayqLMDpEOtRtbPAr8OhLDwI+K6kqcU3Hywp5AmW/pmK9PTQHkTsoDq7qt+VdevMKCszIiXFo8rilfFIzKFSM0MlSn+iQVxQWLXKiqamtn+DywWUlmo7h8r/uTvKMFVWGrzzL3/3uyPbEGZm+kpg9TSPypehUr/kT+0SurlzU7Bvnwndu7tx3XXqtXr0Zaj0s10CIeaoiYBQLWrOo6qri/78KUGSfMfWWC/7a2nxZSSZofIRAVVJiSnkKQ6+kj9mqALBgIoCMmaMA5mZHtTUGHHjjVl45ZUUrFljDrlcwPlrOaalncYUP/xgQWOjMi/If/K6GiZOVDoG7t5t8i78GCxxv3AyFWpMxBcd0047rRW22D4mRkwkSv6imaHq18+F4mIXHA7piHLbAweMcLkkWK2yamWxoejdW1wcaP/zNG9eMlwuCcce6+jwqr7IUoVzgUFNra2+DIKaWQ5xgq9mhqquTsIzzygLLd1xR4OqGb68PGW89fWGmCoNE8Gw2gGVmid7vg5/2mRkRUCllNdrMgRVlJX5FuDOzIzhP0RlPXu6YTLJaG2VUFYW2v7Gf1HfaPHNVWRARXHKZALOO085oi5cmIQHHsjAeeflYvDgApxxRjfcfXcG5s1LwrZtJrgD+Ox5O/1t2qS0qvMjutadeqodBpXfoWlpsjebE2q3PzVOrEWGSin5C54sA59+qoz/7LNZ7tcR/5K/cE8atAio/K8kf/1124BKWWtHCUbU/pwEo7P5gB4P8N//Kgsqt5ed8j1GeJ8HtYmMjNUqq3qSJkr+1JyT9MILqaipMWLAACd++9vQ10dqT1qa7P0MRaKRRqSI1zc3V90TQTUzVDU1ykUeLTJUADB2rANWq4x9+0zYsUMfn7tQ+M+firU225FkMvk6CodS9tfSIuHgQe3mUO3dazz81FD3GFBRwB56qA5vvlmFP/6xHpMnt6JbNzdcLgkbN1rwxhspuP32LJx6ah6GDMnH1Kk5+Nvf0vHJJzZs22bCoUOGNoGWu08feDIyINntMG/d2uZ5fPOnIhMoiLK/N95IDqltuToBVeDtptuzYYMZpaUmJCV5MHEiy/06Ikr+PB4prJ2zx+PrlhTNkj+gbft0/9INPcyfAjrPUC1dasW+fSZkZHhw7rkdf5711phCrEGVm6vuSZoo+auuNgR04akrBw4Y8MorSnbqT3+qh0nl82JJ8gUlsTKPSpZ9wV+kMlRqBFRatEz3l5ws48QTlWPH4sWx2z7d1+GP5X6HC2celaieSU+PbuavoMADm80Dl0vSzfEgULF7WYKizmRSWjlPmKDshGVZuTq0fr0Z69dbsH69GT/9ZEZTkwHffmvFt9+23UlLkoysLA9ycjzo1s2DfPP/UIDNSHs8BemnJiMnxwNZVg5WZrOM8eMjEyhceGEL/vWvVJSWmvDkk2m4777g1mtRI6AqKnJDkmQ0NxtQXW0IehK5yE5Nnmz3Bg10JHF1HVDK/iyW0F6rAweMaG01wGyWox7AnHCCAykpHlRUGLFxo9lbBqt1hz9BXBwoLzeipUVpfSuI7NTUqc2dvk9FyV8kDqAOhxLs9e/vCjg4EiVjouRNLeJz7vFIqKkxoKgovMd74ok0tLZKGD3ajtNOi8z+MjfXg337xGui/0vGDQ2St8Q3knOoZBlhBdtazqESTj3VjiVLbPj6axtuvFG9uXfRxA5/HQsnoPKfPxXNzJ/BAPTt68aWLQbs22fydteMBQyoKGSSpAQGRUVunHOOcvXZ7QZ27DBh/Xoz1q1TgqzSUhNqaw2QZQnV1UZUVxuxYwcATFD+LYLyz8+YMY6ItaZOTpbx8MN1uPLKHPznPym44ILmgDs2ud2+nVMoi/oKVqsy2b283Ig9e4xBBVSy7Js/dfbZMTSxQQMWixLIy7JykhVqExFxRbp3b5fqWYCuWCzAKafY8dlnSfj6a5tfQKWPDFVWloy0NA8aGgwoLTVhwADlc3HggAFffaUE/ldc0XkpWiRL/u6+OxPz5iVj7Fg7HnigDkcd1fXnVmRj1GyZDigXpbKy3KipMYa9uO/WrSbMn68ErPfeWx+xk55YW9xXlPulpnpUv9gkFh6tq1MWHg2nLXttrbYlf4BSTnz//RlYvdqC+vrQ949aYoe/jokLAKGsRaVlBcScOdXIzvbopuNroGJjD0kxw2hUWrJeckkLHn20Dl98cQibN5ejpOQA1q0rx9dfV+Cddw7hhReq8Y/Lv8Of8RCuy3gHZ53VgjFj7OjXz4miIheuu06ddVQ6MnmyHWed1QK3W8Ldd2cG3AVn/34j7HalEUBRUXg7GlGXHGxjis2bTdizxwSbzeNdoJHaJ0m+sr9wWqeLxTyjOX/Knyj7859HJa4gatnhD1Be4/a6Vr7zTjLcbgknnGD3Blkd8S/5U3uC/A8/WAAAK1ZYcfrpuZg1K6PLOUxi7oDaGSrAf7Hc8A6/f/97OjweCWed1RLyEhCBiLXFfcU41c5OAW0XHg237M9X8qfdSWNxsRv9+jnhcklYtiw2y/7271e2AzNURwpnLSrf8SX6r2tRkTvmgimAARVFidmsnJwMGeLCuHEOnHdeK676ow0P4QG8VH8ZXnlqH95/vwrLllXi++8rVF1/qiMPPVSH1FQP1q61eEuTuiI6/BUXu8JeSFdMGBVXggIlslOnnmo/Yk0fOpIanf60aEjh79RT7ZAkGRs2WFBeboAs+zJUWhzwDudrna6MyeUC3npLWXvqd7/rulFCUZFy/6YmA2pq1Dsstbb6TgwmTWqFxyPhzTdTMHZsHp57LhWtHUzrisQ6RoLIRoeTofr2WwsWLbLBaJRx993BlSwHK1YzVGo3pBDU6vSn9RwqQVyUi9X26Sz565go+duzJ7BmYf58FRDaXrCLJbGxh6S45MnLg6uwEJIsw7xhQ9Sfv6DAg1mzGgAA//hHekAnDGqeWHe1fk97/Mv9zjmH5X6BiIeAKjfXgxEjlCzE4sU21NRIaGhQ3q9al/z5j0EEL4sXW1FWZkR2thtnndX1+9RmA/Lzw1+b7XA7d5rg8UjIzPTg9der8cEHhzB8uAONjQb84x/pmDAhDx99ZDsiKxaJNagEkTkJNaCSZeDhh9MBAJdf3hzxOQZqZdSiJZIZKsB/HlV471Nf23RtAyrRRfSbb6whr1ekFVlmU4rOFBa6YbHIcDgk7+sUKHFeUlzM1zVQsbGHpLjV2XpU0XDVVU0YNsyB+noDHnwwvcvbq3liHUqG6uefTdi92wSrVY751e2jRazRFV7Jn9ju2h1c/Mv+xHume3e3LpqSHN46/Y03lOzUtGktsAZYSRSJxhQ7dpgBAAMGOCFJwOjRDnzyySE880wN8vPd2LfPhJtuysYFF+Rg/Xqz937l5SKgUn97i9bpobYh/+QTG9atsyA52YPbb29Qc2jtEmWPsVPyF7nsIqBmhkr7OVSAMl85JcWDykql6U0sqa42oLVVgiTJ3gsy5GM0+vbNwZT9ybL/HCpmqALFgIo05Rg5EgBgXrdOk+c3GoHHHquDwSDjf/9LxtKlnZ/9qbGorxBKq+hPP1WyUxMmtCI1VfsT6VggAo5QM1QtLZK3Tl+rDBXgC6iWLbNi2zZfkww9EGWHe/easG+fEd98o3yOLr888M5hkWhMsX278lgDB/peJ4MBmDq1BcuXV+COO+qRlOTB6tVWnH12LmbMyMSBA4aIlvyJRgahZHwcDuCRR5QLPzfe2BSxLIy/WGubLl7XcBpGdKZvX3XmUOmhyx+gNL0RHXUXLYqteVSi3C8vzxPwhZtEI+ZRBZNRrahQAlWDQWbmLwixsYekuCUyVGaNMlQAcMwxTkyfrpz4/elPGWjppEJJHETVCaiUx9i/3whXgA/HxXyDF27JnzgQZWZ6kJ2t3cnP0KEu5Oe70dJiwLx5ypw/PZT7Ab7Abs8eI/7732TIsoRx4+zek89ARGItKrFgqX9AJSQny7j99kYsX16BqVOVeV7vv5+McePyvNmjSJT8iRP9UEr+3nwzGSUlJnTr5sYNN0S2cY/gn6FSu2FIJESq5b0g9v0lJaaA99uHk2V9NKUQTjtNOZ78739JMbGNBXb465qv01/gFwBEdqqw0A1zbCUtNcWAijTlHDYMssEA04EDMBw8qNk4Zs1qQH6+GyUlJvzrX2nt3qahwbdyuBoBVffuHlitMtxuCWVlXZ9Ebt9uwo4dZlgssvcASF0TAVWoJX9az58SJMmXpfr+e+VyrNZrUAmFhW4YDDJaWgx4/XXRjCK4dW18JX+RzVAdrqDAg2eeqcVnn1Vi9Gg7WluVw6LRKAe9PlwgRMYn2ICqoUHCU08p+6bbb2+IWoZalCg6HBLq6qK4IE2IxOsqxq22Hj3csNlkOJ0SSktDC/6bm5XXE9A+QwUoF+iSkz3YudOM1astWg8nYGxI0bVQ1qLyrUHF1zUYDKhIU3JKClwDBwIAzD/9pNk4UlNl/PWvdQCAF15I9V7Z9idOrHNz3cjICP9kxmDwHQgCmYgvslPjx9tjcr0QrYRb8qeXgArwBVSCXg54FovvKnFDgwF5eW6cfnpwQb8oGwx2GYGO2O2+k4gBA7puKz58uBPvv1+Fl16qxuDBTpx/fgsMEThCiiAtmJI/lwv4wx8yUVVlRN++Llx2WdedE9Vis/kaJ8TCPKpIZ6gMBt9JaqjzqKqrlf/NZlkX7aFTU2X85jfK5/XttwPreKsHDKi6Jt6rwZSo+jrIan/MiyUMqEhzDtGYQqN5VMKZZ7Zi8uRWOJ0S7r4744jSh0icWPvWoup6Z8fFfEPjK/kL7f5qlnmGa+xYh/fvAfR1wPMP7n772+agS0VEhqq01Bh0i9/27N5tgtstIS3Ng/z8wE6uJQk455xWLFpUiWefrQ1/EO0Q856qqgIroZNl4J57MvDll0mwWmU88URt1MtwYmUelSz7MlSRnF8Wykmqv5oa5f+MDE/EFmQO1qWXKkH6xx/b0NCgk0F1gQFV18R7dd++wKcWaLkGVSzT996REoIe5lEBysnUww/XISnJg+++s2L+/CTv75LnzkXZwwsAqHti7ev01/mV319+MWHrVjNMJhlTprDcLxjhzqESgbSoRddSUpKMk0/2dXfU0wFPBHeSJOPyy4PPoOTne2A2y3C5AiuB7Yoo9xswwKWbk1bAN4eqtVVCQwBN+p54Ig1vvZUCg0HG88/XYPRoR4RHeKRYWdy3tlaC06ls7EiV/AHhd/oTGSo9lPsJxx3nQP/+TrS0GPDhh0ld30EH2DK9awUFHthsyn410Oy/OB9hh7/gMKAizYlOf5affoLWC2EUFblxxx3KWc5f/5qO6mrlI5Ly2mvYcTATQGQyVF0FVKLcb9w4uy4mMccSUfIXyhwqWdZXhgrwrRuTnOyJWCezUPTvr7w+EyfavRcKgmE0+k6M1GhMIVqmDxzYdblfNCUny0hOVrZbRUXnt507N9k7b+rhh+tw5pnaXEyJlcV9RTORjIzIdn3zrUUVbkCln325JPmyVLFS9scMVdcMBt9c20DnUYl5rHq6YBcL9L13pITgGjQIss0GQ10djLt3az0cXHttE4YMcaKmxoi//jUdkGUY9+zBNgwCEKkMVec7OtEunYv5Bi+cDFVlpQENDQYYDLJuGkCcc04revVy4Te/adVV5uWKK5px3311eOKJ2pAfI5TFrjsSSEMKrYhAuLM+PJ99ZsOf/pQBAPi//2vA738fvXlTh/N1+tP3KYMI+ESJYqSEm6ESJX96ylABynICJpOM9est2LJFveYwkWC3++bLMaDqXDCNKVpafM23mKEKjr73jpQYzGY4jz4agHYL/Pozm4FHH62FJMmYPz8Z333WBLnVgR0YAMB3JV4NgbSK3r3biM2bzTAaWe4XinACKnHC1LOnWzfrnOTkePDttxV48slarYfSRkqKjJtuagqrGUAoi113pLOW6VoTAVVHGarvvrPg1luzIMsSLr+8yZs114rYpuIEVq+iMX8K8GWoysuNaGoKfr8iMlSi2YdedOvm8R5j3nlH/SzV+vVm1YJyURZss3mQlaWv11FvfAFV159fURaYnu7RVQY1FjCgIl1w6GQelTBqlBO/+51yRfjuBwvwC/qjFUmwwI7elgOqPY+4AnTokBHNze0fmEV26uST7cjO5g4uWOG0TddTh79E4FvcN7wTd6fTV46lz4BK+Tvby1D9/LMJ06dnw26XcPrpLfj73+s0z0SKjI/+M1TK+ybSAVVWlozsbOU1CeQk9XB6nEMliLK/995Lht3exY2D8PXXyuLZN96Ypcrj+Zf7af350DuxuG8gGaqSEl92iq9rcPS9d6SE4RTzqDTu9OfvnnvqkZvrxo79abgBLwEA+uMXJK3/UbXnyMiQvVcpOzqJ5GK+4QmnbbqeGlIkAnGBIdwMVUmJCU6nhJQUjy4X/RQn/IdnqPbvN+J3v8tBfb0Bxx9vx/PP18Ckg8qrWMlQiYAv0iV/ALyLVodS9idK/vSYWTnlFDsKCtyorTXg889tqjymxwM88kg6AGDNGkvIHVf9cf5U4IIp+eP8qdAxoCJd8GaoNm8GHNHvYtWejAwZf/lLPQBgKSYAAAZjKyxr16r6POIksr21qPbuNWLDBgsMBlmzCemxTo2SP2aooiOQEthA6LXDnyDWovLPUFVXS7jssmyUlxsxcKATc+ZUI0knzdZiJUMluhBGOkMF+PYJoTSm8JX86a/iwGhUlj0AgLffTlHlMf/3vyT8/LPSJMblkrB1a/h9/xlQBc6/dXpXp1di36unJTlihb73jpQw3L17w5OZCcnhgPnnn7Uejtd557Xg1Lz13u8HYRvMP6qXoQI6b50uslMnnujwnoRRcFjyFzvEWlQVFUa0hNF/xT+g0qPDM1QtLRKuvDIHv/xiRkGBG//9bxWysvRzsi0yVFVVhoDXstGCCPhEV8JICqfTn55L/gBfQLV8uTXsixtOJ/DPfyqdKo1G5T29YUP4ARVbpgeue3cPkpM98HikLrenWNRXL4vGxxIGVKQPkuRtn27WUdmfJAH/6vYArFCyQ4OwDZYNG1TNonU2b0TMn+JivqELteSvtlbyZg31OA8nHmVlyUhNVU4yS0tDr3UTDSkGDdJXy3TBfw6VywXceGMW1q61IDPTg7feqkJhob5OtLOyPDAaZciy5G38oEcioIrGcgLhdPrTe0DVq5cb48YpE6jmzQuvOcXbbydjzx4TunVz46qrmgAAGzeql6HSY0mv3kgSUFwc2DwqX4aKr2uw9LtnpIQjFvjVQ6c/f4MOrsRc/B6/GVuO8zMWQ2ptVTWL5iv5a7ujKy01Yt06CySJ5X7hCLXk7/vvrZBlCf36OaNSQkTKgV9cYGivBDZQ27crJ2x6zVD5t02fNSsDX39tg80m47XXqnUZvBuNvjHreXFfMbZwOk0Gyj9DJQeZTBRzqPTW5c/fpZcqwc+8eclwh3hu3dICPP20kp2aObMRY8YoFyLVyFCx5C84gcyjkmXfHCq2TA8eAyrSDb11+gMAqbERxqoqTMO7eOnlWlhHDQQAWFQs++soQ/XZZ0q53wknOKJyghCvQg2oVq2yAABOOkkfc/oShTiQh9rpz+XyZQ30GJwAvpK/7duV9tQGg4x//7saxx+v3/eamEel18V9PR5f23SRAYyk4mIXJElGQ4Mh6Llles9QAcDpp7ciM9ODsjIjli4Nbc2I115LwcGDRhQVuXD55U0YNkzJGG/bZg6rg6AsM6AKViAB1cGDBrS2SjAaZb6uIdDnnpESkshQmX75BVJ9vbaD+ZWxpAQA4M7KgpyeDsexxwKAqvOoxLyRPXuMba50stxPHaLkL9g5VKtWKScRJ56oYu9g6lK4a1Ht2WOEwyHBZvOgqEifJwU5OW3H9cgjdZgyRd/vM70v7ltTY4DbrXzGo1HyZ7X63qvbtgX+XnW5AHF409M8ucPZbMBFF4nmFMGX/dXXS3juOSU7dfvtDbBagaIiNzIzPXA6w2tMUVMjoaVFeR8WFOjzM643IqPaWUAl9rmFhW6Yw08iJhx97hkpIXm6dYOrZ09Isgzzhg1aDwcAYNq7F8D/t3ffYVKV1wPHv/dO396ApRepShWsIIJi7zWWWGLviSZRE2OisSSan8YYSzQaS2IJtkSxBEVABRsISkea1IVdtrG70+/9/TFz7+7ClpnZ6Xs+z5MnMuXOu3t3du+Zc95zIDhoEAC+iRMB4trpr1+/IIqi09SkUlUVum37dpVFi0IZEin365pY9lBVVyusXBn6iyIZquQyukvFuhn++++by/3UNP0LV1Skk5sbuuj/xS/2cOGFTSleUeeaG2mkZ8mfEegVFyfvYvDAA0O/G+6+uzDiD2zq6pofV1CQvhkqgPPOC/1czp7tjHrv3FNP5VFbqzJsmJ+zzw59KKgoMHZs18v+jIYUPXoEccans3vWa55F1f771yizloYUsUnTPzeiuzL3UaVJYwrLDz8AEBg4EAjNy9IVBevmzaiVlXF5Dacz1IUHYOPG0G3vvx/KTh10kJfy8vT+o5vujD+40QRUX34Zyk4NHy77p5KtqxmqdO/wB6Cq8NRTtTz3HNx8c0OqlxORdG+dbpQiJrM8+s47Q7MKV62yceuthRHtpaqtDa0zP19LixljHdl//wDjx/sIBBRefz3yHv5VVSpPPx1quf7LX+7B0uIa3ij760pjim3bmjMpIjJGyd+2bZZ254A1z6BK39+d6Sw9fzOKbss3aRIAjk8/TfFKQqxGyd+AAQDo+fkERowA4ruPyvgFtmFD6N9Gu/STT5bsVFfF0jbd2D912GGSnUq2lnsKo93sDy07/KX3RcFRR3m59FLSck5WW9J9uK/RkCIZ5X6G8nKNJ5+swWLRefPNHF54ofPSOCOgSuf9Uy2df34oS/XqqzkRvx8ffTSPpiaVsWN9nHhi679hY8bEI6CSDn/RKivTyMvT0HWl3Q+rJEPVNRJQibTiOfpoAOxffpkW+6gs4ZK/QLjkD2jeRxXHsj/jU/mNG0MbQ7/6yij3k/1TXWWU/Hm9ClqE1zCffx7KUB1+eHrva8lGxnthzx6V2troow0jQzV8eHq2TM9U6Z6hSuYMqpYOO8zHHXeE/lb97neFfP11x4FCXZ0RUKXv/qmWTjvNjcul8f33NhYt6jwI2rbNwj//GcpO3X77nn0+MDAyVKtX22KePiINKaKnKJ03pjDKrKXDX2zS8zej6LaCgwfjHzoUJRDAMW9eqpeDNVzyFwyX/EGLfVQJ6PS3cWOou5+uKxx4oC/t5tFkIiNDBaGgqjO7d6usWhW6cJAMVfK5XLp5URxt2V8wCOvWpXfL9EwVzwzVm2+6zCx8vBgZqlSU6F51VSMnn+wmEFC45pqSDoNO40OCdG6Z3lJ+vs4pp4SyTK++2nkG7uGH8/D5FA47zMvUqft+INW/f6gxhc+nsGZNbFkqCahi09k+KmN0i8ygio0EVCLteGfMAMD50UepXYjfj2XrVgAC4ZI/AH84oLItXRoaAx8HxidCGzY0l/tJd7/4aBlQRVL29/nnoezgyJF+Sksz46In2zTvo4ru4n3LFgsej4LDoUvZSpzFK0O1bZvKjTcWc/31xVF33uyIsa5UBFSKAg89VMuwYX4qKixce20xgXbi+Zoao3lG5vxuMcr+3n7bRUND++ds3ToLM2eGgq7bb69vs5xVUZrL/mJtTCEBVWyMDNWGDft+UOV2K+aHJZKhio0EVCLteI45BgDHxx8T80TBOLBs24YSDKI7HGjl5ebtgf32QyssRPV4sK1eHZfXMi7+li6FL74IXdDL/qn4sFjAbjf2UXX+eCn3S73mWVTRZaiMcr/99gu02ggvus7IUDU0qDQ1xR4IffNN6Peb36/EPGusLc0BVWr+ZuTl6TzzTA25uRqff+7gD38oaPNxmbaHCuCgg3zst5+fpiaVt99uvznFn/5UgKYpHHOMh0mT2v+wsaud/owufxJQRaejkj/jw6vCQi2t2/mnMwmoRNrxTZqEVlSEpaYmru3Jo2W0TA8MGECr/suqim/CBCB+86iMWVS7d4OmKYwf70vbGTqZKJrhvtKQIvWMDxiMTdKRMlqmy/6p+MvL03E6uz6LaskSu/nfsbbGb0sqS/4MQ4cG+POfawH429/ymDVr37JGYw9VYWHmXLQqSnOW6uWX2y77W7bMxqxZLhRF57bbOt7/3JXGFD5faJ8xSEAVrY4CquaGFJKdipUEVCL9WK14pk8HwPHhhylbhjnUt8X+KUO891GVl2tmFgXgpJMkOxVPkQZUVVUqa9eG/sgfeqhkqFKlOUMV3QV3c0MKuSiIN0VpHu9gtCiPxZIlzRfR2ZShMpx0kofrrtsDwC23FJldJw3GHqpMylABnH22G6tVZ8kSO6tX73tB/sADoSG+Z5zhZtSojt9/RmOKVauib0xRUWFB10NlvVKSHZ0hQ0LvjR07LPuU2xr7VaVUOnYSUIm0lA77qKx7zaBqyR/u9BevDJqq0iojJfun4svo9NfZng0jOzVqlJ+Sksz5BDnbxDqLyrh4lYAqMYzsj5ENipbf37rMy9gE31XBIFRXp24P1d5uu20Phx/upbFR5YorilvtO8rEkj8IfV+POSb0Qd8rr7TOUn3xhZ25c51YrTo///meTo81YECQwsJQYwrjQ5BItWyZnikjB9JFcbFmNkPZtKn1e9jIFssMqthJQCXSkmfaNHSLBduaNWbr8mQzXrfNDFW45M+6aRNqVVVcXs/4RTZmjF+67MRZpBmqhQtl/1Q6MH7+t261RLyNUtNaDvWVkr9EMLovxpqhWrPGisfT/Nx4Zah271bRNAVVTY+shdUKTz5ZQ3l5kHXrbNxyS5E5w8kIqDKpKYXBKPt74w0X3vCvSF2HP/4x37x/0KDO37CKAqNHG40p7J08ujVpSBG7jlqnb9okGaqukoBKpCW9qAjfwQcDqctSGUN928pQ6YWF+IcPB+I3j2r8+NAfmHPOaYrL8USzSAMqo8Pf5MmyfyqVevcOYrXq+P0KFRWR/Znats2C261is+kRXdSJ6HU1Q2U0pDDej9FmINtjBHglJVraNCMpK9N4+ulqbDadd9918dRTodlMRkCVSXuoDNOmeSkvD1JTY2H27ND+sDlzHHz9tQOnU+dnP+s8O2Uwyv6ibUwhAVXXtBdQNWeo5PsaKwmoRNryhMv+UrKPStextDGDqiVjwG+89lHdcEMDn3wCl18uAVW8GRdwHZX87dypsm6dDUXROeQQyVClksXSfMEUaae/lh3+rPG5Thd7MfYnxZqhMhpSHH10qHRs82aLmbnpiqqq1DekaMvEiX7uvrsOgPvvL2DhQnvG7qGC0PvyRz8K/X165ZUcNA0eeCDUzfAnP2mkvDzyr2nMmNCHVtE2ppCAqmvamkWlac2/Z6XkL3YSUIm0ZbZP//xzlIaGpL62uns3amMjuqIQ6N+/zcf449yYwuWCI45A6sITwNhD1VGGymhXf8ABfoqKMu/T42wT7Swq2T+VeF0d7ms0pDj11NAe0YYGlZqarv/CMwI8oyQxnVx8cRNnn91EMKhw7bXFGbuHymAEVJ984uDJJ/NYudJGfr5mNuKIVMvGFNGMc2wOqOR9Hou2MlS7dql4PAoWi06fPun3HsoUElCJtBXcbz8Cgwej+P045s9P6msb2SmtvByc+7a+heZOf7Zvv6XdKY4iLURS8rdgQWj/lLRLTw/GJ6WRloUZ3RmlZXridGW4b329wrp1oXN52GE+evWKrfFIW4wMVVlZ+gUpigJ//GMd++/vp6rKQiBgZKgy80ObgQODTJ7sRdcV7r8/lJ26+uqGqJv4DBoUpKBAw+tVWLMm8p+Blk0pRPTaCqiM92DfvkFssY0GE0hAJdKckaVyJrnsz+zwN2hQu48JDBuGlp+P2tSENU4DfkViRFLyJw0p0ku0GarmhhTy4UaidCVDtXSpDV1XGDAgQGmpZrbGj8csquYMVfoFVBDKkP/979VmhzW7vTlrnokuuKC5LL20NMiVVzZGfYyWjSmWLYusMYWuS8lfVxkB1c6dFhobQ38Pm2dQyfe0KySgEmnN3Ef18cdE3O4rDsz9UwMGtP+gFgN+41X2JxKjs5K/HTtUNm60oqo6hxwiGap0EM0sKl2Xkr9kMDJUVVUqWpSxi9GQYsKE0PvLCJgj3SPXkaqq0KVMWVn6XhAOGhTk0UdrUBSdkSMzu7T7+OPdZsniTTc1kJcXW3AYbWOK2lqFpqbQuZYMVWyKinRKSlrvozLGF8j+qa6RgEqkNd/BB6MVFGDZvRvbkiVJe92OZlC1ZO6jilOnP5EYnZX8ff55KDs1erQ/I7tvZSPj09JISsK2b1dpaFCxWnUGDZKLgkQxSur8fsVsrhApoyHFhAmhi2jj/BqfjneFkTFL1wyVYcYMLx9/XMUHH6R6JV3jdMLjj9fwi1/Uc/HF0WenDGPHRteYwshOlZYGcbliftlur7kxReh3q2So4kMCKpHebDa806YByW2fbomg5A/i3+lPJIaxDa79gCp0sXf44ZKdShfGH/eKCgseT8eP/f770AXZ4MEB7NGNtRFRcDiamylE0zpd15sbUhx4YOg9Fk0GsjOZkKEyjBgRoHfvVK+i66ZN83LzzQ1der+NGRMKrleujKwxxfbtUu4XD3vvozI+tJIMVddIQCXSnrmPKokBlbWTlukGc8Dvxo2o1dUJX5eIjVHy194eKmP/1GGHyf6pdFFSopGTE7p437q144tuY/+UlPslXizDfbdssbB7twWbTeeAA1pnqOLRlCLd91CJtg0aFCQ/P9SYwngPd0T2T8XHvgGVzKCKBwmoRNrzTJuGrqrYVq3CsnVrwl9Pcbux7NwJQKCjPVSAXlyMf7/9gPgN+BXx11HJ37ZtKps2WbFYZP9UOlGU5j/wnV10y/6p5IlluK+RnTrgAL+ZLTYyVNu2Wbq0Pdbvh5qa9JxDJTqmqi0bU3Re9rdtW3M3OhG75oDKgtutmCWzxntSxEYCKpH29JISfAcdBIAjCVkqy+bNAGgFBejFxZ0+Pt7zqET8dRRQGfunxo71k58v+6fSSf/+kXWCM1qmDxsmLdMTLZYM1d4NKQDKyzVsNh2/X6GiIvayP6Pcz2LRKS6WgCrTNDem6Lx2UDJU8TFkSPMeKuN3a2GhlrGt/NOFBFQiIySz7M/SsiFFBK2YfBJQpb2O2qZLuV/6iqQTnK5LyV8yxZahat2QAsBiab4w7kpjCmMdZWUaqlzRZBwjoIosQyUBVTwYGaqqKgvLl4e+75Kd6jr59SMygtdon75gAUpj7F2FImHdtAnopGV6C0ZjCtvSpUlt7S4i11HbdGlIkb6a99m0f8G9c6dKfb2KquoMGSIXBYkWbYbK58O8aGuZoYLmTfBdaUxhDBk2WrqLzDJmTOhnYuVKK4FO3r4SUMVHXp5uvl/mzQt9oCgd/rpOAiqREQJDhxIYNAjF58Px6acJfS2j5K+zDn+GwIgRaHl5qI2NWNesSeDKRKyaS/5a3751q4XNm0P7pw46SAKqdBPJ8FcjOzVoUBCHIynL6taizVCtWmXD61UoKtLMds0GIwNpzMGJhRFQSUOKzDR4cJC8PA2PRzX3QrbF7w99eAISUMWDkaX65JPQL00ZN9F1ElCJzKAoeI4+GgDHhx8m9KUi7fBnsljwjx8PSNlfumqv5G/BglB2atw4f8zDKUXiGJ+adlTyZ7RMHzFC9k8lg5GhMgKZzhgNKSZM8O1TQW00Helahqq55E9kHlVtbp/e0YDfigoLuq7gcOiUlsq57irjw42qKplBFS8SUImMYe6jmjMHtMT9QjVK/job6tuSOY9KOv2lpfZK/oyGFIcfLvun0pGRwairU9sdJGtkqIYNk09Yk8HIBEVa8tfckGLfgLe56Ug8MlRyQZipjICqo31URrlf795B2SsXB0aGyiB7qLpOfixFxvAdcghafj6Wykps336bmBcJBrFs2RL6z2gCqnBjCptkqNJSW13+dB0WLpT9U+ksN1c3h7W2l6WSlunJZQRU1dWWiIaxttXhzxDJHrnOSIYq80XS6U/2T8XX3gGVzKDqOgmoROaw2/EeeSQAzgSV/VkqKlD8fnSbjWCfPhE/z2xMsX49Sk1NQtYmYtdWQLVli4Vt26xYrbJ/Kp0ZWaq2Lrp1HdaskZbpyVRUpGG1ht5PRsvy9tTUKObw0PHj2wqoQhd1u3ZZ2h263RnJUGU+ozHFihXtN6aQgCq+WgZUFotOnz7yfe0qCahERvGEu/0lqn26xejw169fqK9vhPSSEgKDBwNgX7IkEUsTXWCU/LW8aDOyU+PH+8nJkf1T6cq46G5rn01VlUptrYqi6Oy3n2SokkFVm7NBxkDQ9ixdGnqPDRoUoKRk3/dYUZFOfn7oWLHuozJKDyVDlbmGDGluTLFuXduZaAmo4qtlg5i+fYPYOu9aLzohAZXIKN6jj0ZXFGwrVqBu2xb34xsNKSLt8NeSzKNKX21lqBYskP1TmcAoC2urE5yxf2rgwCAuV1KX1a1F2jrdaEhx4IFtZ4AVpetlf8ameunyl7lUFUaP7rgxxfbtElDFU06OTnl56Hsp5X7xIQGVyChaSQn+cODinDMn7sc3hvpGOoOqJQmo0pcRUAWDCn5/qFTMaEghA33TW3Onv30vuJv3T0m5XzJF2jrdGOjbXkAFHWcgO+PxhBqWAOZeO5GZOmtMIRmq+DPK/qQhRXxIQCUyjtntLwH7qMwMVRQNKQzmPqolS2TAb5oxAioIlf1t2mRhxw4LNpvOQQfJxXg6a+4Et+8F99q1oYsvaUiRXJFkqHS9Zcv09t9jXZlFtXt36GfCZtMpKpKy3UzWUWMKXQ/NDATo00fe6/FywAGh7/moUfI3MB4koBIZxwioHAsWoDQ1xfXYZoYqhpK/wMiRaDk5qA0NWL//Pq7rEl3jcICiNJf9GdmpAw/0mfurRHoyMlRbt1r3mZYgLdNTI5IM1aZNFmpqLDgcOvvv3/4F28CBsWeojICuR4/gPjOuRGYxMlQrVlj3+Tyyvl6hsdEY6iulnfFyyy17ePrpas4/P77XUd2VBFQi4wSGDyfQvz+K14v9s8/iemwzQxVDyR9Wa1YO+M1/8EHKTjsNdceOVC8lZorSeh+V0ZDisMOku1+669MniMWi4/Uq7NzZ+k+WEVBJhiq5IslQGeV+Bxzgx95+N+wuZaiMDn9GgCcy15AhAXJyNNzufRtTGOV+JSVB+QAsjgoLdU46yYPTmeqVZAcJqETmUZTmsr84dvtTamtR6+qA6GZQtWSW/WXJgF+lpoa8xx/HvmgRxddeS0SDZ9KUEVC53QoLF0pDikxhs2G29G05i2r3btUs+Ro6VAKqZGrOUHUUUBnlfh1/aGFsiN+yxYIe5bWykSGTgCrzWSztN6aQ/VMiE0hAJTKSt2X79L3rgGJkZKeCPXui5+TEdIxsa0zh+uADlPBgEMfXX1Nw//0pXlHsjE82V660sXOnBbtd73CzvEgfbc2iMhpS9O8fkLb3SWZ01Ouo5K+5IUXHH8L06xf6/dLQoFJTE13dXnOGSi60s0F7jSkkoBKZQAIqkZG8hx6KlpuLZedObMuWxeWYxgyqWBpSGPxGhur771Fqa+OwqtRy/fe/AHgnTwYg7+mncb73XiqXFDOjrOHjj0PZqYkTfdJqO0MY+2xaBlRS7pc6RgDTXsmf1wsrVkSWoXI6oVcvI2COruxPMlTZpbkxReuASlqmi0wgAZXITA4H3iOPBOJX9mfdvBmIrWW6QSsrM2dY2ZcujcOqUketqsK+YAEAtQ8+SMM11wBQdMstWDZsSOXSYmKU/M2bJ+V+maY5Q9V8wd3cMl0CqmQzMlRNTSqNjftmlZYvt+HzKZSUBM2mIh0x2jZHO4uquSmFBFTZwAioli+3tWpMYWSojNJfIdKRBFQiY3nCZX+OOLVPt3RhqG9Lxj6qTC/7c777Loqm4Rs3juCgQdTffjvegw9G3bOHkquuQnG7U73EqBglf9XVoT/O0pAic7Q1i8pomT5sWObu68tUubk6OTmhIKatLJVR7jdhgj+i7nttBcyRqKqSkr9sst9+zY0p1q9v/lmQkj+RCSSgEhnLe/TR6IqCfdmyuHSgs4ZL/mJtSGEw9lHZMjygcr3zDgDuU08N3WCzUfPkkwTLyrCtWkXhHXekcHXRazmLyunUOy1FEunDmEXVshOclPylVkf7qCJtSGEwGlNEn6GSkr9sYrE0z0ZqWfYnAZXIBBJQiYyllZXhnzABAOecOV0+nqULQ31b8huNKZYsiVvDjGRTKyqwf/EFAJ5TTjFv18rLqXniCXRVJeff/8b16qupWmLUWgZUBx7ok1axGcS44K6oUPF6oaZGMS+mZQZVanS0j8rIUE2cGFn20AiYo51FJRmq7LP3PqpAACoqJKAS6U8CKpHR4tY+3evFEs5ydTVD5R81Cs3pRK2vx7puXdfWlSKuWbNQdB3fpEkE+/ZtdZ9v8mT2/PKXABTdcQfW5ctTscSotQyoZP9UZikr03C5NHRdYds2C+vWhS62+vQJkJcnHf5SoTlD1foyYvdu1cwkjhsXWYbKKOmMpuTP7VZoaJA9VNnG6PS3fHnoPb5zpwVNU7DZdDnPIq1JQCUymrGPyv7pp13a02PZsgVF19FyctDKyrq2qCwY8Ot6+22gRbnfXhpuuAHPUUeheDyUXH01Snh+VzprORBy8mQp98skitK8z2bLFqtZ7jdihGSnUqV5uG/rrJJR7jd0qJ/CwsiCXaMpxbZtllbNCDpiBHJOp05+vgTV2aJlYwpNa92QQpUrVpHG5MdTZLTAqFEE+vVD9XhwzJsX83HMGVQDBxLRLupOmPuoMnDAr2XrVuyLF6MrCu6TTmr7QapKzaOPEujXD+umTRTdcgtRT+VMMiND5XRqEX9yLtKHkcX44QeLGVBJuV/qtDfct2VDikiVl2vYbDp+v2KWd3WmucNfMB6/skWaGDo0gMul0diosmGDVTr8iYwhAZXIbIqCJ3zR75w1K+bDWMIt07u6f8pg7KNyfPFF2gcae3OGm1H4Dj0Urby83cfpxcXUPPUUut2O64MPyH3qqWQtMSZGQHXQQX4cjhQvRkTNyGJs2WKRhhRpwCj5ay9DFU3TF4sF+vVrDpgjUVUVelxZmZSBZZNQY4rQ+/q772zSkEJkDAmoRMZzh5smOGfPhhjL/uLV4c/gPeQQtJwcrBs24IjTnKxk6azcryX/+PHU3XUXAAX334/9yy8TubQuCbVw1jn99KZUL0XEoGVrbWmZnnptNaXQNFi6NJShOvDA6M5Ny4A5EsbrGqWHInuMHRsKxiWgEplEAiqR8fzjx4fK/pqacMZY9meNU4c/g15UROOllwKQ/+c/Z0yWyrJxI/bvvkO3WMzMX2eaLr6YpjPOQAkGKb72WtTKygSvMjann+5mzZoKzjsvs+ZniRCj09/y5TazLExK/lKnrbbpGzZYqKtTcTp1Ro6MLqAyAuaWrfE7YryuZKiyj9GYYtkyCahE5pCASmQ+RcFz8slAc7latIyW6cEuDvVtqfGaa9BcLuzffosjDm3dk8HITnmnTEErLY3sSYpC3QMP4B82DMvOnRRfdx0R7yxPstzczAhsxb6M1tqbNoUuuMvLgxE3PRDxZ2SoKitVczqEsX9qzBgfNlt7z2ybETBHmqEy9m4ZgZ3IHi0bU2zdKgGVyAwSUIms4DYCqg8/jL7sT9exGnuoBgyI25q00lKajCzVww9nRJZqn2G+EdJzc6n5+9/RcnJwLFxI/v/9XyKWJ7oxoymFYfhwKfdLJSMzFAwq1NSELiW++Sb6hhQGI2COtHW6EVCVlcmFdrYZOjSA06nR0KCa+yUloBLpTgIqkRValf3NnRvVc9WdO1E8HnSLhWC/fnFdV0PLLNXHH8f12PFmXbsW26pV6DYbnuOPj/r5gWHDqA0HUvmPPppxe8dEesvL0ykubr6oknK/1LLZoKSk9T6qWBpSGIwM1ebNkWaoQo+TDFX2sVqbG1PoeqiFo3T5E+lOAiqRHVqU/bmiLPszW6b37UvUdSqd0MrKaLrkEiD9s1Rmud/UqehFRTEdw3PaaebescJf/zo05l6IODEuukE6/KWDlvuo3G5YtSr0+zPahhTQnKHatcuC2915H3QjQyXDXrOT0ZgCoKhIk3JtkfYkoBJZw+j25/joo6iG/FpazqBKgIZrr0VzOrEvXYojyuxZ0ug6TqO732mndelQdb/5DcGSEqzbtuF87714rE4IoLlxAUhAlQ6MYGbXLpXly+0EAgo9ewZjKs8qKtLJzw8dr7N9VLreMqCSzEU2MhpTgJT7icwgAZXIGv5x4wj074/a1BRVeZ3Z4S+O+6daSmSWyv7JJ3EpJbSuXIlt/Xp0hwPPscd27WAul/n15j39dFpn5URmMVprAwwdKnuoUq1lY4pvvmku94tl0K6iNO+T66zsr7FRwe2WDFU2MxpTAPTtKx+eiPQnAZXIHi3L/qIY8puIDn97M7NUS5bELUtl/+wzSi+4gNKLLsIxf36XjmWU+3mOOgo9P7/La2u85BJ0hwP7kiXYFy3q8vGEgOYL7h49gpSUSKCeai2H+xod/mJpSGGIdBaVkZ3KyZFSsGw1bFioMQVIhkpkBgmoRFYxuv05Pvww4rI/Y6hvvGZQtUXr0SOuWSp1506Kb7gBJXycop/+FLWqKraD6XpUw3wjofXoQdOZZwKQ+/TTcTmmEBMn+lAUncmTvaleiqB1hqorDSkMRsDc2SwqaUiR/axW2H//UIAtAZXIBBJQiaxilv253RGXwlmMlukJDKhgryxVjAOIAQgEKL7+eiyVlfhHjsQ/YgSWykqKbrklpkDN9u23WDdvRnO58M6YEfu69tJ45ZUAON9/H0s4aBWiK0aNCrB48U7+8pfaVC9F0BzQrFxpY+tWK4qiM25c4jNURldBGeqb3S6+uJGhQ/3MmCEfoIj0JwGVyC5RdvtTGhqw7N4NJK4phUHr0YOmiy8Gupalyn/4YRyff46Wm0v1U09R8/jj6A4HzjlzyH3uuaiPZ3b3O+YY9JycmNbUlsCIEXimTUPRdXL/8Y+4HVd0b716aVgjG1UkEszIUK1ZE8pODR8eID8/9uy70XSkswxVVZUx1FcyF9nsnHPczJ9fKSMSREaQgEpkHbPsL4Juf0bmJFhSEpe9Q51puPZadKcT+zffxLTvyTFvHnmPPgpA3YMPEhw6lMCoUdTdeScABffei3XlysgPqGnN5X5d7O7XlsarrwYg55VXUGpr4358IUTq7F1y15VyP2hui79li6XDz5t27QplsCRDJYRIFxJQiazTquxvzpwOH2sNl/slOjtl0Hr2pPGiiwDIf+ihqLJU6vbtFN14I4qu03jRRbhPP928r+nSS/HMmIHi9VJ8/fUR7x+zL16MZccOtPx8PNOmRfOlRMR7xBH4R45EbWoi9+WX4358IUTq7N2yvCsNKQD69QtlIhoaVGpq2m8VKBkqIUS6kYBKZJ8ouv0ZHf4SvX+qpYbrrmvOUn3ySWRP8vspvu46LNXV+EaPpu6uu1rfryjUPvwwwZ49sa1dS8Hdd0d0WGP2lOfYY8HpjOKriJCi0HDVVQDkPvss+KXVtRDZorhYx2Zr/lCoqxkqpxPKy43W6e2X/UmGSgiRbiSgElkp0iG/Roe/ZGWoIJyl+vGPgcizVPkPPojj66/R8vOpeeqpNoMfrbSU2r/8BYDcf/4T5wcfdHzQYNAMOOPV3a8t7tNPJ9ijB5aKiqja2adcIED+/fdTdPPNKE1NqV6NEGlHUZqzVC6XxogRXd/r0r9/6BgdzaJqzlBJQCWESA8SUIms5B87NqKyP2sKMlTQIku1eDGOTz/t8LGO2bPJf+IJAGofeqjDeVneqVNpuPZaAIp+/nPUHTvafaz9iy+w7NqFVlSEd+rU6L+ISDkcNF56KQC5Tz2VGYN+wxnB/McfJ2fmTIqvuQYCsjFaiL0ZQc24cf64NAsxGlN0nKEyuvxJyZ8QIj1IQCWyk6KYWaqOuv0ZLdMTOdS3LVqvXjReeCHQcZbKsnUrxTffDEDD5ZfjOemkTo9df+ut+MaORa2tpfimmyDY9kWH2YzihBPAbo/ly4hY08UXhwLIZcuwf/FFQl+ry7xeiq+6Cte776Lb7ehOJ845cyj89a8zIxgUIol69AgFVF3dP2UwGlO0l6HSdaiqkjlUQoj0IgGVyFrGPirHnDltl2z5/Vi2bgUgMGBAMpcGQMP114eCjEWL2s5S+XwUX3MNam0tvgkTqP/NbyI7sN1OzWOPoeXk4Fi4kLwnn9z3MX4/znffBcCTwHI/g1ZSQtPZZwNpPujX7abk8stxzZ6N7nRS/Y9/UPPEE+iqSu5LL5EXLqkUQoSccUYTQ4f6Oeus+JTFGiV/7c2iqq9X8HpDDSskQyWESBcSUIms5R87lsCAAe2W/Vm2bUMJBtGdTrRevZK+vpZZqrw25lIV3Hsv9iVL0AoLqXnyyaiySMH99qPu3nsByP/Tn7AtWdLqfseCBVhqagiWluI9/PAufiWRMQf9fvghlvXrk/Ka0VCamii95BKcc+eiuVzsfuEFvNOn4znuOOruuQeAgj/9Cde//53ilQqRPk47zcP8+ZWMGhWfktjmDFXbJX+VlaFAKz9fw+WKy0sKIUSXSUAlspeimDOp2mqGYLRMDwwYAGpq3goN112H7nDg+Ppr7C2yVM733iPv2WcBqHnkEYL9+0d9bPe55+I+5RSUQCDUSr2hwbzPKPfznHQSyZqSGhg6NNTaXdfJe+aZpLxmpJQ9eyi58EIcCxaEBia/9BK+KVPM+5suvZQ9118PQNGtt8Y0Q0wI0TkjQ7V1q6XNauXKytDvaqPUUAgh0oEEVCKreVp2+9ur7M8c6puCcj+DVl7e3PEvnKWybNpE0S23ANBwzTV4jz02toMrCrUPPECgb1+sP/xA4R13hG73es0OgIns7tcWo4W6a+ZMlOrqpL52e5S6OkrPPx/HV1+hFRSw+5VX8B1yyD6P23P77TSdeWYoQL3ySqzLl6dgtSIZrN9/j7ptW6qX0S2Vl2vYbDqBgMKOHfuW/RkNKfaegSWEyA6Fv/oVRTfdhHXlylQvJSoSUIms5h8zJlT25/HsU/aXqg5/ezOyVPavvoL33qP46qtR9+zBN2kS9bff3qVj64WF1D72GLqqkvP667jeegvH/PmodXUEy8vxHXxwnL6KyPgOPxz/AQegejzk/utfSX3ttijV1ZT+6Eeh0sqiInb/+9/4J05s+8GqSu1DD+GdPBm1sZHSiy4y9+CJ7KHu2EHZ8cdTdt55qV5Kt2SxQL9+7TemMBpSSIZKiCyk6zhnzSLnjTdQvN5UryYqElCJ7NZBtz9jqG+yO/ztTSsvN/dScdZZ2JYtI1hcTPWTT4LN1uXj+w4+mIaf/QyAwttvJ+/vfwfAfdJJoauXZGo56Pe55yCFvzDVqirKzj0X+7JlBEtLqXrtNfxjx3b8JLud6meewT9qFJZduyi58EKUmprkLFgkhWPhQlSPB+uGDahpkkXtbgYMaL8xhWSohMhelq1bsVRXo9ts+PffP9XLiYoEVCLrtdftL10yVBDOUtntZoBR+9e/ovXpE7fj7/npT/EedBBqQwOOhQuB5Jf7GdynnkqwvBzLrl24/vvflKxBraig9KyzsK1aRbBXL3a/8QaBCH956wUF7H7xRYK9e2Nbt46Syy4DjyfBKxbJYv/6a/O/rWnYPKU7GDAgFCz98MO++zuNob6SoRIi+9iWLgXAP2oUOBypXUyUJKASWc8/ZgyBgQNDZX8ffRS6UdebM1RpEFBpvXvTeNllAOz52c/wTp8e3xewWql97DG0ggIAAn37tl/almh2O40/+QkAeU8/nfTZTuq2bZSddRa2desI9u5N1euvExg2LKpjaH36sPtf/0IrKMDx1VeheV+aXOBlA/uiReZ/WzZsSOFKui8joGo7QyUlf0JkK/u33wLgHzcuxSuJngRUIvu10e1P3b0btbERXVEIxNBBLxH23HEHrF5Nw623JuT4wX79qH34YTSXK9TCXFES8jqRaLzwQjSXC9uqVdg/+yxpr2vZvJmys87CumkTgf79qXrzTYJDhsR0rMDIkVQ/8wy63Y7r3XcpuPvuOK9WJJtSV4d19Wrz35KhSg2j01/HGSop+RMi2xgZKt/48SldRyyS0y85Rh988AHvvPMOtbW1DBw4kMsuu4yhQ4e2+/h3332X2bNnU1VVRUFBAYcccggXXHAB9ijm94js5DnlFPIffzxU9tfY2Jyd6t07fdLKFguMGAE7diTsJTwnnEDF2rUpaxNv0IuLcf/oR+Q+/zx5Tz9N9RFHJPw1LZs3U3bmmVh27CAwaBBVM2ei9e3bpWP6Jk+m9s9/pvj668l75hmCffvSGN4jJjKPffFilBYZUwmoUsOYRSUZKiG6EU3DtmwZIBmquFq4cCEvvvgiZ599Ng888AADBw7kvvvuo66urs3Hf/bZZ7z88succ845/PnPf+aaa67h888/55VXXknyykU68o8e3arsz5pG5X5Jl+JgytBwxRXoioLz44+xfv99wl+v4J57sOzYgX/YMKrefLPLwZTBffrp1P3mNwAU3n03zvCML5F57F99BUCwvBwAq5T8pYSRodq1y4Lb3ZxJ1zTJUAmRrazr16M2NKC5XFGX4aeD9LiyasOsWbM4+uijmT59Ov369ePKK6/Ebrczd+7cNh+/Zs0aRowYwZQpU+jZsyfjxo1j8uTJrFu3LskrF2mpZbe/WbPMDFU6NKToroKDB+M57jgAcsOdBxPFsn49zvffB6DmqafQevWK6/Ebr7mGhvC+sOKf/tS8MBeZxdg/1XTuuQBYN22izemyIqGKinQKCkIZqJZZqtpahUAgFGCVlUmGSohsYjakGDMGrGldQNemtFxxIBBgw4YNnH766eZtqqoyZswY1q5d2+ZzRowYwaeffsq6desYOnQoO3fuZMmSJRzRTimR3+/H7/eb/1YUBZfLZf53qhlrSIe1ZAvPySeT/9hjOD/+2Nw/FBw0KG2+x93xnDdefTWuDz4g5/XXabj9drTS0oS8Tv5TT6HoOp4ZMwiOHEncv8OKwp7f/x5rRQXO998n/6GHqJ45M8Kndr/znpZ8PuxLlgDgOeMM8p56CsXrxbp1a0JGK8h5b5+iQP/+QVasUNmyxcqIEaGgtqoqdMlSVKThdGbm903Oe/ck571zZkOK8eMz8vuUlgFVfX09mqZRVFTU6vaioiK2b9/e5nOmTJlCfX09d955JwDBYJBjjjmGM888s83Hv/XWW7z++uvmvwcPHswDDzxAjx494vNFxEl5uPRExEF5Oey3H8r69bg++ACAgvHjKejdO8ULa61bnfPTToNJk1AWLaLXm2/Cb38b/9fYsQNeew0A5+9+R+9Enu8HHoD338exdCm9e/aMas5XtzrvhsWLYf16CGeEUurLL0Pt70tK6DF1KgwbBsuX07O2FhL4M9Mtz3sEhg+HFSugrq7E/PavWhX6/9691cS+j5NAznv3JOe9AytXApA3bRp5Gfj+TsuAKhYrVqzgrbfe4oorrmDYsGFUVFTw3HPP8frrr3P22Wfv8/gzzjiDk8Od36D5U4PKykoCgUDS1t0eRVEoLy+noqICPcltpbNZ/gknkPfYY2YZT1VBAf4ENoGIRnc9587LLqN40SKCf/0ruy66CJzOuB4//777yPP58E2axO799kto0w+Ki+mVm4va0EDlJ58QGDmy06d01/OOrtPz1FOxbN9OZWlpxHPAEiX3/fcpADwTJ1KzcydFAwfiWr6cuq+/pikBHae67XmPUM+e+UAey5Y1sGPHHgBWrXICxRQXe9mxIzOHLst5757kvHfC56N86VIUYNfAgQTT5LrMarVGnGhJy4CqoKAAVVWpra1tdXttbe0+WSvDv//9b6ZOncrRRx8NwIABA/B4PDz99NOceeaZqHttxLfZbNhstjaPlU4/7Lqup9V6Ml3TKaeEAqow/4ABaff97W7n3H3iieT36YN1+3ZyXnrJnMcVD0p9PTkvvgjAnuuvT/z3VVXxjx2L4/PPsX3zDf4RIyJ+anc775YtW7CEKw6sq1aFBjmmkC080Nd30EHouk4g3E7fum5dQs9LdzvvkRowIPTB5ubNFvP7U1nZ3JAi079nct67JznvbbOtXo3i9aIVFYX2tmfg9ygtm1JYrVaGDBnC8uXLzds0TWP58uUMHz68zed4vd59ai73DqKECBxwAIHwfgitsBC9uDi1CxJgs9Fwww0A5D/0EEp1/D55zv3Xv1D37ME/fDjeGTPidtyO+CZMAMAW3o8j2tby+2PduDGFKwF03Wwk4jvoIIDmgEo6/aWEMdy35SwqI6CShhRCZBdz/tTYsSmdkdkVaRtxnHzyycyZM4d58+axdetWnnnmGbxeL9OmTQPgscce4+WXXzYfP3HiRD788EMWLFjArl27+O677/j3v//NxIkTJbASzVoM+ZUOf+mj6cIL8Y8ciVpbS/7DD8fnoF4vuc88A0DDNdckrV28PxxQ2SWg6lDL749l06bULST8+paqKnS7PfQHHQjstx8gs6hSxQiotmyxmB9WV1aG9iT27CkBlRDZxGY0pMjA+VOGtCz5Azj88MOpr69n5syZ1NbWMmjQIH7961+bJX9VVVWtMlJnnXUWiqLw6quvUl1dTUFBARMnTuT8889P0Vcg0lXjJZdg/+ormuRnI31YrdTddRdl551H7osv0nTRRQSiKJdrS84bb2DZuZNg7964zzgjTgvtnDHh3bp6NUpTE3pOTtJeO240jYJ77kF3udhz660JeYl0ylAZ2Sn/2LHmHj4jQ2WpqEBpbETPzU3Z+rqjfv1CJX8NDSo1NQolJXqrkj8hRPawGy3TE7BfNVnSNqACOP744zn++OPbvO+uu+5q9W+LxcI555zDOeeck4SViUym9enD7rfeSvUyxF58RxyB+4QTcL3/PgV33UX1yy/HnvoPBsl78kkAGq68Euz2OK60Y1qfPgTLy7FUVGBbtgzfIYck7bXjJe/xx8l7+mkAms4/n2D//vF9Ab8f+7Jl5j9THlCF508Z5X4AenExwZISLNXVWDZuJDB6dKqW1y05nVBeHqSiwsLmzVZKSvzs2hXKUPXoIRkqIbKF4nZjDY9EMioEMpHUwgkh0kb9nXei2+04P/kEx4cfxnwc5//+h3XDBrTCQpouvDCOK4xMJu+jsi1eTP6f/mT+2x5u1hDX11i9GsXjQQtnfdTaWpSamri/TqSMr9F78MGtbpeyv9Tq37+5MQVAVVXokqVnT8lQCZEtbMuXowSDBHv2RMvAdukGCaiEEGkjOHAgDVddBUDh3XeD1xv9QXSdvCeeAELlnXpeXjyXGBGjbCHT9lEpdXUUX389SjCIFi59S0hAFf6++CZOJBiey5KqLJVSXY3t++8B8E+a1Oo+CahSy9hHtXmzlWCwOaCSphRCZA+jIYV/3LiMbUgBElAJIdJMw403EuzVC+umTeQ9+2zUz7d//jn2JUvQnU4aL788ASvsXEZmqHSdottuw7plC4EBA6i7/34gMQGVEWj6J0wgMHgwkLqAyij38w8dilZS0uq+oHT665zfj+WHHxJy6OaAykJNjYqmKSiKTmmpBFRCZAujIYUvgxtSgARUQog0o+flUf+rXwGQ98gjqLt2RfV8IzvVdO65aGVlcV9fJPzjxqErCtZt26Jef6rkvPoqrnfeQbdaqXn8cbxHHQWEm2vU1cX1tcwM1fjxzQFVijr9tbV/yiAZqs4V/PGP9Dr8cFxvvhn3YxuzqLZssbBrV+hypbhYo50RkkKIDJQNDSlAAiohRBpyn3UWvgkTUBsbKfjjHyN+nnXFCpxz56KrKg1XX53AFXZMz8sjEJ6ZZ5QzpDPr999T8JvfALDn1lvxH3ggWo8eBAYPRtF17IsXx+21lPp6rOvWAeA/8ECC4YDKkqoM1V7zp1pqFVBl4KDJhNM0XG+8ARAadxCM796mliV/VVXSMl2IbKPU1ZnVCZncMh0koBJCpCNVpS7cydM1c6ZZEtAZo7Of56STCIYHOKeKUfZn/+ablK6jUx4Pxddei+rx4D3iCBquvda8ywgyjKAjHmxLl6LoOoH+/dHKysxB2ykp+fN4sBvlJm0FVAMGoKsqamMj6s6dyV5d2rMtXYqlshIInT/n//4X1+MbTSm2brWwY4fsnxIi2xh/2wMDBuxTcp1pJKASQqQl/6RJNJ15JoquU/jb33aaIbBs2YLr7bcBaLj++mQssUOZMuC34N57sa1aRbC0lJq//KXVAGRfuOtdPPdRtdw/BaS05M++bBmKz0ewtNTMlLXicBAcMACQfVRtcYY7cerhsQR5TzwR10xeebmG3a4TCCgsWxaq85MOf0JkD3sWDPQ1SEAlhEhb9b/+NZrLhX3RIlz//W+Hj8196imUYBDvEUfgHzMmSStsnzHg1/btt6Cl56fqzv/9j7znngOg9i9/QevVq9X9XiNDtXQp+HxxeU2jBNLI4BmZRLW2FqW6Oi6vESkjUPQdfHC73aWMAb+yj2pfRkBVf9tt6E4n9iVLsH/xRdyOb7FA376hAGrx4lDQlk4ZKsXtxrpmTdq+v4VId2ZDigzfPwUSUAkh0pjWuzcNN94IhDIpSlNTm49Td+8m55VXANhz3XVJW19HAiNHorlcqHv2pOXFuLp9O0W33AJAw9VX450+fZ/HBPfbj2BJCYrHg63FIN6Y6bqZoTICKt3lSlnrdJsRUO3VLr0lCajaZtm6FduqVeiqivvcc2k691yguSlMvAwcGCr7W7ky/TJURTffTM+jjqLXwQeTf//9oeBKCBExe8uW6RlOAiohRFpruOoqAv37Y9mxo92LtdznnkP1ePCNGYPviCOSvMJ2WK34w1Pfbem2jyoYpPjGG1Fra/GNHUv97be3/ThFad5HFYeyP8u2bVgqK9GtVvyjR5u3p6R1uq43Z6ja2D9lMBtTSMlfK46PPgJCwahWUkLD1VejqyrOjz/GunJl3F6nf/9QABUIhDKI6ZKhUnfvxvneewBYduwg//HH6XnUUZQddxy5Tz+dMd09hUgVddcuLDt2oCtKWlSVdJUEVEKI9OZyUX/nnUCo6YRl69ZWdytNTeSGy9YarrsurQYDmgN+06zTX96jj+L44gu03FxqnngCwntg2hLPgMoILP2jRoHLZd5uZoGSuI/Kun49lpoadKezwz/m0jq9bUa5n/eYY4BQ6abnpJOA5uYw8WB0+jOkS5c/56xZKMEgvtGjqX7qKdzHHotutWJfvpzCu++m16RJlPz4x7jeegvF7U71coVIO2ZDimHD0PPyUryarpOASgiR9jwnnoj3sMNQPB4K7r231X05r7yCWltLoMUFXbpIxwG/9i+/DLW4Bur+8Ie2mzG00KrTXxcbDuzdkMJg7KNKZut0Mzs1fnyHAaUR7Fm2bInbPrJMpzQ04Fi4EABPOKACzA6Rrv/+d58PPmJlzKIy9OiRHiV/xp5O9xln4Dn5ZGqee46dS5ZQe999+CZMQAkGcc6dS/ENN9Br3DiKfvYz7J9+GvfW8kJkqmxqSAESUAkhMoGiUHf33eiqiuudd7B/+WXodr+f3KeeAkL7gLBYUrjIfRmBg23VKkiDT6mVmhqKbrgBRdNoOvts3Ged1elz/GPGoDudWKqrsXQxS7N3QwpDKkr+zPlTHeyfAtDKy9Fyc1GCQaybNydjaWnPMX8+is9HYNAgAkOHmrf7x43DO3kySjBI7t//HpfX2jtD1aNH6jNUlm3bcHz5Jbqi4D71VPN2raSEpksvpWrWLHZ+8gl7fvYzAgMGoDY2kvPaa5Sddx49Dz4YHnsshasXIj1kU0MKkIBKCJEhAgccQNMFFwBQ8NvfQjCI6+23sW7bRrCsjKZzzknxCvcV7NuXYI8eKIEAtuXLU7sYXafol7/Eun07gUGDqLvvvsie53DgC3+CaF+0KPbX9/uxffdd6D8PPLDVXa0CqiQN0G3V4a8jiiKNKfZilPt5ZszYp8TWGFmQ8/LLKDU1XX6tlhkqVdUpKUl9QOUMj2fwHXooWp8+bT4muN9+7PnlL9m1cCFVb71F44UXohUWYtmxA268kdw4lkUKkXF03fyATTJUQgiRZHtuvRWtoAD78uXkvPqquVej8fLLW+3JSRuK0jzgN8Vlfzkvvojr/ffRbTZqnnwyqpp1o+zP0YUBv9Y1a1A9HrSCAjNAMQQGDgRAra9HjcNFeGfUqiozG+abOLHTx0tA1UIwiGPOHKB1uZ/BO3Uq/v33R21qIveFF7r8ckVFOgUFoSCqtFRLiyR0zltvAeA+/fTOH6wo+A4+mLoHH6Tim2/YE+6sWXDPPeT8858JXKUQ6cuydSuW6mp0mw3//vunejlxIQGVECJjaKWl5gVJ4Z13Ylu1Ci03l8aLL07xytpnNKawpbAxhW3pUgrvvhsIzfYyug9GKh4Dfu1GQ4px41oNDwbA5SLYuzcAliR00zO+Dv/IkehFRZ0+PhhuTJGMtaU72zffYKmuRisowHfIIfs+QFFCzWGA3H/8Iy6lrkanv3Qo97OuW4dtxQp0qxX3iSdG92Snk4Zf/ALCXTULf/UrXG++mYBVCpHezOzUqFHgcKR2MXEiAZUQIqM0Xnop/qFDUbxeAJp+/OOILopTJZUZKqWxkYJ776Xs1FNRvF48Rx1F4xVXRH0cI4tj3bABtaoqprXsPX9qb2bZXxI6/dkjmD/VknT6a+YMt0v3TJ8ONlubj3GfcgqBfv2w7N5NzsyZXX5NYxZVOjSkcP3nPwB4jzwSvaQktoPcfz+Nl1yCousU/exnOP/3v/gtUIgMkG0NKUACKiFEprHZqL/rLgB0m42GGAKEZDIyVNbNm1F3707Oi+o6zvffp8e0aeQ9+SRKMIj7hBOoefTRfbNDkRyuqAj/yJFA7FkqW6QBVRIaU5gNKTqYP9WSlPw127tdepusVhqvvhqAvKeegkCg/cdGwMhQpXwGla7jMsr9zjgj9uMoCvX33UfTWWehBIMUX3MN9k8+idMihUh/ZoOiLGlIARJQCSEykHf6dGoee4zqF15od1N4utALCvCHO6Elo326ZfNmSi65hJIrrgg1oOjfn90vvEDNM8+gFxfHfNyuzKNS6uuxrlsH7NuQwmAEVAlvne52mw1COm1IEWa2Tt+9G6W2NlErS3uWzZuxrVmDbrGEMlQdaDrvPILFxVh/+MEcgBurM85wM368j7PPburScbrK9t13WDdtQnM68Rx7bNcOpqrUPvww7hNOQPH5KLnsMmxxmPUmRNrTNGzLlgGSoRJCiJRzn3EG3iOPTPUyIuJPRtmfz0feo4/SY/p0nHPmoNts7LnxRirnzsU7Y0bXD99yHlWUbN9+i6LrBPr3Rysra/MxwSSV/Nm//RbF7yfYqxfB/v0jeo6el0ewvBwIlT12V0Z2ynfwwZ2W2eo5OTT95CdAeNBvF7o3jhnj5913q5g6NbVzwMxyv2OPRc/N7foBrVZqHn8cz5FHorrdlF58MdZUdwMVIsGs69ejNjSguVwEhg1L9XLiRgIqIYRIsEQP+LUvXEiPY46h4IEHUD0evIcdRuWHH7Ln9tvR49T90Mjm2JYtQ4my0YA50LeD8o5ktU5vVe63V8vvjpjr68Zlf63apUeg8Sc/QXM6sX/3HfbPPkvk0hIvPKYBoKkr5X57czioeeYZvAcfjFpfT+n552P9/vv4HV+INGM2pBgzBqzW1C4mjiSgEkKIBDMzVEuXxjVYUKuqKLrpJsrOOQfbunUEy8qoefRRdr/2Wtw/+Qv260ewvDw0UyvKjoWd7Z8CCAwYAIRbp1dXx7zOzpgNKSLcP2UwG1N00wyVUl+P/fPPASIud9NKSmg6/3wAc8RBprJ/+SWWigq0wsK4Z8b1nByqX3gB35gxWKqrKT3vPCwyRFpkKVsWNqQACaiEECLh/KNGoTscqHV18Wm9HQyS8+KL9Jw6lZw33kBXFBovvphd8+fjPuusqDIvEVOU2Mr+dL05Q9XO/ikAXC4C4f1wCWtPrmnYFy8GuhBQddMMlWPePJRAAP9++xHca45YRxqvugrdYsE5f35Gl7MZ5X7uE09MSJtnvaCA6pdfxj98OJaKCkrPOw+1oiLur5NSup60wd0ifdmNDFUWNaQACaiEECLxbDb8o0cDXd9HpTQ1UXr22RT96leodXX4xoyh6p13qPvDHxLePj6WeVSW7duxVFaiW634wt+D9iR6H5V17VrUujq0nBz8BxwQ1XPNTn/dNEMVUXe/NgQHDMB9yilABmepfD5c774LRDjMN0ZaSQm7X3mFwMCBWH/4gdLzz09otjaZ1O3bKR89msJf/CLVSxGp5PNhW7ky9J+SoRJCCBEtcx9VFwf85vzrXzi++gotL4+6e+6h6t13zZLCRDMzVIsXQzCymUA2Y6DvqFHQyX6uRLdONwf6TpgQde2+maHauBG01A+YTapAAOfHHwPgiTKgAmi49loAXG+/nZGlbI7581Frawn26oXvsMMS+lpaeTm7X32VYHk5trVrKbnwQpT6+oS+ZjI4P/wQtbaWnJkzUXfsSPVyRIrY1qxB8XrRiooIDhqU6uXElQRUQgiRBL5wuVuXMlR+P3lPPw1A/e9+R+Nll4HFEo/lRfbyo0ah5eai1tdjXbMmoudE0pDCkPCAKsr5Uy0F+/dHt9lQPB4s27fHe2lpzb54MWptLVpRUcTDkFsKjB6NZ+pUFE0jN/zzm0lc//0vEBpYnIz3W3DAAHb/+98ES0qwf/cdJZdcglJTk/DXTSSj1FbRNHLeeCPFqxGpYs6fGjs2MaXpKSQBlRBCJIERUNhWrACPJ6ZjuP7zHyw7dhDs2ZOmM8+M4+oiZLXimzgRiHwfVSQNKQxGyZ8lQSV/9kWLQmuJcP5UK1YrgYEDQ//ZzfZRmd39jjoq5q5cDdddB0DOK68kb8B1HChNTTg/+ABIbLnf3gJDh7L7lVfQCgpwfPUVvSZNovD227GE57llGiOgAnC99prspeqmsrUhBUhAJYQQSREcMIBgSQmK32/WkEdF1809KI2XXw5OZ5xXGBmz7C8cnHTI78f23Xeh/+yoIUVYIlunqxUVWDdvRldVM1sYLaPsL2FNM9KUI8p26W3xTZmCb8wYVI+H3Oefj9PKEs/x4YeobjeBQYOSvok+MHo0u19+Gf/++4e+b//8J72OPJKSiy7C8cknGROUqFVV5r5I3enEtm5dUoaci/STrQ0pQAIqIYRIDkXp0oBfx5w52NasQcvLo/Gii+K9uohF0+nPumYNqseDVlBgBiMdCQwYgK4oqHv2xD2LYeyfCowahZ6fH9Mx4tnpzzF7Njz/fNpfFFs2bsS2bh261Yp3+vTYD6Qo5l6qnOeeQ2lqitMKEyvnrbcAcJ92WkpKlPwTJlA5ezZVr72G+9hj0RUF58cfU3r++fSYMYOcV16BKOfCJZu5j3L48FCXRCBn5sxULkmkgOJ2Y127Fsi+hhQgAZUQQiRNVxpTGNmpph//GL2wMJ7Lior/wAPRLRas27ahbtvW4WPN/VPjxoEawZ8bp5Og0To9zvuoYp0/1ZLRLryrAZVSU0PxlVfCT36CfeHCLh0r0YxyP9+hh6IXFHTpWJ6TTiIwcCCWmhpyXn01HstLKKWmBse8eUByy/32XYiC7/DDqXnuOXZ98gkNl12GlpODbfVqin7xC3odfDD5f/oT6q5dqVtjB8xS20mTaDrnHCDUoCTW0meRmWzLl6MEgwR79ULr3TvVy4k7CaiEECJJzAxV+BPbSNkWL8bxxRfoNhsNV1yRiKVFTM/NNVuOd1b2Z49i/5QhmKDGFOZFXRcCqngN93XOno3i9wOQ99BDaZ2lMvdPxdDdbx9WKw1XXQUQak6Rxl83gOv991H8fvyjRhEYPjzVywFCQX39Pfewc9Ei6u68k0Dfvliqq8l/5BF6HXwwRT/9adrN+zJnv02ciG/yZAJ9+qDW1eGcPTvFKxPJZDakyMLsFEhAJYQQSWP8IbFu2oQSxXwZIzvlPvPMtPhkzwhKHJ2U/UXTkMIQCLfSjWdApTQ2YgtfZHrjEFBZtm3rUpmVMdMIwPHFF2mbpVJqa7F/+SUQp4AKcP/oR+h2O9YtW9K+hbrLKPc744wUr2RfemEhjddcw66FC6n+29/wTZqE4veT8/rr9DzuOEouuADLli2pXmZoH6Wxb2bSJLBYQsPHgZzXXkvhwkSyZXNDCpCASgghkkYvLjYbL9jDf1w6Y1m3zuwyZuxBSTVzH1UHA36VPXuwfv89QFRzsgIJGO5rW7IEJRgk0KcPWt++MR9HKylBKyxE0fWYAz6lvh7Hp5+G/hEOUvIffjgtszXOefNQgkH8w4cTDHc47Crd5QrNJKP5AisdqRUV2D//HAjvn0pXViueU06h6r//pXLWLJpOOw3dYsE5fz49ZszANXNmSn+2bCtXhvZRFhWZw7GNsj/HvHmoO3embG0iubK5IQVIQCWEEEll7qOKsDFF3lNPoeg67mOPJTBsWCKXFjEjoLKuWtXu0FHb0qUouk6gXz+0Hj0iPrZx0RXPPVTm/qlY2qW3pCjm+mIt+3N+9BGKz0dg6FB47jl0uz1ts1SOeJb7teAfMwYA27JlcT1uPLneeQdF1/FNmkSwX79ULyci/gkTqH3iCXbNn49v0iTUhgaKb76Z4quuQo0iIx5PZrnfgQea+yiD++0XyqhpmpkFFNlNqaszP4TyjR2b4tUkhgRUQgiRRNF0+lN37iTn9deB5jk+6UArLycwcCCKprW7H8z8NDKK7BTstYcqTp+sx6MhhaGrnf6c4XI/98knQ9++NF14IZCGWSq/H+fcuQB44x1QhUt+Is3SpoLrP/8BoCkNy/06Exw8mKo336T+V79Ct9lwvfcePY46CsdHHyV9LTZj72J4fp3ByFLlpDiDJpLDyEYHBg5ELylJ8WoSQwIqIYRIolYZqk4uJHKffRbF58N70EH44xAMxJNv0iSg/bK/WPZPAQT69w+1Tm9oQK2q6toiAYLB5k/Jw2vuikAXOv0pjY04w13jPCedBEDDDTekZZbK/vXXqHV1BEtKYp7b1R7jE2rbsmVpeTFt2bgR+9Kl6BYLnpNPTvVyYmOx0HDDDVTOmoV/+HAslZWUXnIJhbfdhtLYmLRltGxI0ZL7lFNCM6nWrEnrTKWID+PDE3+WZqdAAiohhEgq//77o9vtWGpqsPzwQ7uPU+rryX3xRSC9slMGo3yuzXlUut7cMj3KgAqnk2B4n1M89lFZV61CbWhAy8sjEN670xVd6fTnmDMHxeMhMGgQgf33B0Dr3ZvGNMxSGd39vEcfDRZLXI8dGD4c3eFAra/HEse9cvHi+u9/AfAecQRaWVmKV9M1gdGjqXz/fRquvBKA3H/9ix7HHostHOgkklpRgXXrVnRV3ef3gF5YiPu44wBC+7xEVjMyVL4s3T8FElAJIURyORzNbcc7KPvLeekl1D178A8fjnfGjGStLmJGQGX75hsItwA3WLZvx7JrF7rFYu6XiYZR9mfpYntyaNEufeLEuAQGrQKqKIMf13vvAeA+6aRWQ2Ibrr8e3eEIZakWLOjyGuMhru3S92a3Nzem+O67+B+/K3TdLPdL62YU0XA6qb/rLqr+/W8Cffpg3bSJstNPJ//BB/d578aTkZ0KjByJnpe3z/3uc88FwsOTvd6ErUOknlkCnqUd/kACKiGESLpOG1N4veT9/e8ANFxzTWRDcZMsMHQoWlERqseDbcWKVvfZwvuq/KNGobtc0R87jq3TjQxaPPZPQWhtuqKg1tWh7t4d8fMUtxvHnDkAeE48sdV96Zalsqxbh3XjRnS7He+RRybkNYzSH3uaBVTWlSuxff89usOB54QTUr2cuPJNmULlRx/RdOaZKJpG/l/+Qtmpp5rdOOOtvXI/g/eIIwiWl6PW1uIMvzdE9lF37cKyYwe6osT0AVumSL+/0kIIkeU6a0zheustLDt3EiwvT8sZOACoavM+qr3K/mIu9wuLW+v0YBDHJ58A4DvssK4dy+ByNZckRrGPyjFvHmpTE4G+fdv8lLbhuutCWaovv0x5lsoZbl7gPeywNjML8WDMZEu3DJVR7uc5+mj0/PwUryb+9MJCav/6V6r/9je0oiLs331Hj+OPJ/fZZ0HT4vpanQVUWCw0GTOppOwvaxlzyALDhiXs90k6kIBKCCGSzKgjt61YAT5f6zs1jbwnngAI7Xuw25O8usiZ+6j2akxh/AGNtiGFwQiouto63bZ0KZaaGrSCgrg0pDDEso/KGS738+xV7mdIpyyVc/ZsIEHlfmGtWqfH+UI+ZprWXO53+ukpXUqieU45hV1z5uCZNg3F46Hwt78l/89/jt8LeL1msNzRe89tzKT6+GPUysr4vb5IG/YsH+hrkIBKCCGSLDh4MFpREYrXi23Vqlb3OT/8ENv69WgFBWZL7XTVasCvEQAEAuaFlD/G7nDxap1ulBF5jzwSrNaYj7O3qDv9eb3mniT3XuV+LaVDlkqprjYD5Hi3S28pMHw4utOJumdPXGeOdYV98WKs27ah5eXhOeqoVC8n4bTycqr/9S/qb78dgJyXX45bcGtbvhzF5yNYUkIwXMLblsCwYfgmTEAJBmUmVZbqDg0pQAIqIYRIPkVp3kfVco6TrpP3+OMANF58cdqXHPnGjg11LKysNLu1WVevRnW70fLzzUxOtAIDBqCrKmpjY5dapzs+/hgg7hfHxtdliTCgcnz6KeqePQTLy/G3V/5EemSpnHPnomga/lGjEjvQ1mYzG1PY06RttnFB7znhBIhh719GUhQarroKLS8PS0VFxAPHO2OU+/knTmwzI9uSOZPqtdfi8toijei6WbEgGSohhBBx5zfK/sJ/bCCU6bEvXozucNB4+eWpWVg0nM7m5gLhfVTm/qlx42JvpuFwNO9TijF7oe7caV6oe+McUAWjLPlzGcN8Tzyx0+9JqrNUCe3utxfjAsuWDgN+AwGcs2YB2V/utw+HA0+4k6jRibKrzO6aEZTauk89Fd1ux7ZyJdbly+Py+iI9WLZswVJTg26z4Q+PishWElAJIUQKGBkqe4sMlZGdajr7bLSePVOyrmh5jX1U4Qsoe4wDfffW1X1UjrlzQ+sYPz7us4TMkr8ffoBAoOMH+/3Ne5I6KPczJC1L5fGE5gStXo39889xvv8+Oa+8gsMYPJyEgKrVgN8Uc3z2GZbduwmWluKdMiXVy0k642fT+f77cfmZ67QhRQt6cTGeY48FJEuVbeyffw6EOr7icKR4NYkVv6JyIYQQETM64FnXr4eaGqxr1uD86CN0RaHh6qtTvLrImfuowhkqo2TIF+P+KUNw0CD45JOYM1Tm/qkE7IUJ9umD5nSiejxYNm8mGA6w2uJYuBC1tpZgWZnZxKMzDdddR+5LL4WyVJ99hu+II2Jap2POHJz/+x9qTU3of7W1qLW1KLW1qG53u88L9uhhZlATyd8yoNK0lI4HcL3xBhDKlsRzv12m8E6fju50Yv3hB6wrVxIIz8qLhbptG5aKitAcugjLvJrOOQfXrFm43nqL+t/8Bmy2mF9fpAf7559TeMcdAHinTk3xahKv+/3WEEKINKCVlBAYODCU5Vi0iNxnngFC+zeCMe49SgWjpMe2bh2WH34wZ9p09YI80LIxRbT8frNduufoo7u0jjapKsHBg1FXrcK6YUOHAZUzXO7nOf74iAcLG1mqvH/8g/yHH2b3lCmd7kNptbzKSgrvvBPXO+90+DjdYkErKkIrKkIvLjb/u+mss5IS3ASGDQsFpg0NWDZsIDh0aMJfsy1KY2MoMwO4w228uxs9JwfPtGm4PvgA1/vvs6cLAZWRrfYfcAB6Tk5Ez/FOm0awRw8slZU45s7FG85Yicxk//xzSi66CNXtxjN9OntuvjnVS0o4CaiEECJFfBMmhAKqN97A9eabQCg7kUn0khL8w4Zh+/57cp99FkXXCfTt2+WSxa4EVPavvkJtaCBYWmpmQeItMGQItlWrsK5fjze8/2TfBwVwfvABAO6TTorq+GaW6quvIs9S6Tqu116j8O67UWtr0S0Wmn78Y/zDh6MVF6MXFaG1CJz0/PyoArW4s1oJHHAA9sWLsX/3He4UBVTO995DdbsJDB6clMxcuvKccAKuDz7A+f777PnFL2I+TjTlfiarFfeZZ5L31FPkzJwpAVUGs3/xRatgqvqZZ8DpTPWyEk72UAkhRIqYF29PPYUSCOA97LCYh+GmklHKlvPqq0DsA31bCrbcQxXlng5nuLufd/r0hGVazFlUHXT6s3/5ZWhfTnFx1IOFo91LZdmyhZILL6T45ptRa2vxjR5N5XvvUXf//TRdeime007De+SR+MeOJThgAHpBQWqDqTBzH1UKB/waH2Y0nXVWWnxPUsUzYwa61Ypt9eqIO1i2xdgX6o9y9pvR7c/50Ueo1dUxv342UGpq0qNZS5TsX37ZHExNm9ZtgimQgEoIIVJm78YNmZadMhhlf2pjY+jfcQiozNbpTU1RD/xMVLv0liIZ7mt0TPMcd1xMe0Iarr8+1PEvnKVqUzBI7jPP0OOoo3DOn4/udFL/619T9e67BEaPjvo1k82f4oBKrajAEf7eus88MyVrSBd6UZHZkMMVLoGMmtttNhmJKkMFBEaNwjdmDIrfbw5Y7q6Kfv5zepx4Io6PPkr1UiJm/+orSn78Y9SmJjxHHkn1s892m2AKJKASQoiU8Y8ejR7eAO8fNSqUUclAezdbiHWgbyt2uzkHKZqyP8uWLdjWrkW3WEIDfRPE7PTXXkClaTiNgCrKcj/zEOXlNP74x0DbWSrrmjWUnX46hb/7HWpTE95DD2XX7Nk0XH99xjRWMFunL18OwWDSX9/1n/+gaBregw4iOHBg0l8/3XhOOAHA3FMWLfuyZSiBAMGePWOaY+Y+91wAXDNnxvT6WUHXcXzxBQB5Tz2V4sVExv71183B1NSp3S6YAgmohBAidZxO81Pchuuvz9hyo+DAgQTDe6Z0iwX/mDFxOW5g0CAgutbpjnB3P9+kSehFRXFZR1vM4b47d6Ls2bPP/fZFi7Ds2oVWUNClNtzmXKqWWSqfj7yHH6bHccdh/+YbtLw8av/4R3a/9lpGNTQBCAwdiuZyoTY2RjzXK55yXn8d6L7NKPbmOe44dEXBvnQplm3bon5+q/lTMfw+c59+OrrNhn3ZMqyrVkX9/Gygbt+OWlcHhLqEWtesSfGKOmb/+mtKLrwQtbER7xFHUP2Pf3SfwdgtSEAlhBApVPfoo/D223jOOCPVS4mdophlf/5Ro9Dj9Mc0GENjCnP/VALL/QD0wkKC4flWba3P7O53zDFgt8f8OntnqWzffEOPE06g4KGHUPx+PMccw665c2m66KKUth2PmcWCP1yamOyyP+vKldhWrUK323GfckpSXztdaT16mBlno6FKNGyxNKRo+folJeaQ4e46k8q2enWrf+c+91yKVtI5W8tgasoUqp97rlsGUyABlRBCpFSwf3845ZSMzU4ZPMcdB8Q3kIm605/bjX3BgtB6EtEufS9m2d/eG/h13Sz3c598cpdfp2WWqscpp2BbvZpgaSnVTzxB9XPPofXp0+XXSCVzH1WSN+HnhJtReGbMSGg2M9OYZX/hn+GI6brZ4c8fY0AF0GSU/b35ZueDs7OQEVAFBgwAwPX66yjhjFU6sS1aROmPfxwKpiZPpvr55+P2YVomkoBKCCFEl7nPOotd//tfXOeNRBtQOT7/HNXjIdi7N4GRI+O2jva01+nPtnQp1u3b0XJz4zLQsmWWCkLd6HbNm4fntNMyPhCHvQb8JkswiOuttwBpRrE3z4knAqGObdE0hLFs3oylshLdZsPXhbJf7/TpBEtLQzOp5s2L+TiZyih1bDr/fPwjR6K63eT8+98pXlVrtkWLKL3wQtSGBryHH071Cy9062AKJKASQggRD4oS6irXhfK2vZl7qDZtiqh1eqvufkkINMx9VHvt/XEZ5X4zZsRtY/aeW29lz09/yu6XX6b20UfRS0rictx00CqgSlJjCvuCBVgqKtCKihLaDTITBfv2xTduHIqu45w9O+Lnmdmp0aO79nNvs+EOl0B3x7I/I0PlHzmSxksvBSD3hRdA01K4qma2xYubg6nDDpNgKkwCKiGEEGkp2LJ1+q5dHT9Y1839U572Bu3GWbCtkj9db94/FWN3v7boeXnsufXWhHYuTJXAfvuh5eSgut1Y161Lymsa5X7uU04BhyMpr5lJYun2F9NA33aYM6lmz0atqOjy8TKGz2e+BwL774/7rLPQCguxbtqEY+7cFC8ObN980zqYevFF9JycVC8rLUhAJYQQIj3Z7aE9ZnRe9mddvx7rDz+g2+34Jk9Oxupaz6IKZ9CsK1Zg3bwZzenM2Db4SZfkxhSK2928x026+7XJHQ6oHJ99FvH+HVvLDn9dFBg9Gv/++6P4fPQ69FCKf/ITnP/9L0pTU5ePnc6s69ej+P1o+fkE+/ZFz8mh6Uc/AlLfnELduZPSiy5C3bMH76GHSjC1FwmohBBCpK1WZX8dMNqlew89FD03N8GrCgkMGIBusYQyaOFP0V2zZoXWcdRRcrERhWQO+HV+8AFqYyOBgQPjcvGfjYJDh+IfPhzF78cZwXBZpakJW3jvTzwyVAC1//d/+EeNCg36nT2bkuuuo9e4cRTdeGNo4K3fH5fXSSdmQ4oRI8yy5cZLLkFXFJxz52LZuwFOsug6hb/6FWptLb7RoyWYaoMEVEIIIdJWpK3TzXbpSejuZ2qZQVu/HnS9ef9UHMv9ugNjwK89CQGV6403gHAziixo6pEoRnOKSMr+bEuXogSDBHv3jlvXSf+4cVR+9BG7Pv6YPTfdRGDAANSmJnLefJPSSy6h14QJFN52G/Yvvkib/UVdZTX2T40aZd4WHDTI7J6a+8ILKVmX8+23cf3vf+g2G7WPPJK0D60yiQRUQggh0pbZ6a+Doa9KQwP2L78ESHqDgZad/qxr1mDdsAHd4UhK2/ZsYmSorMuXJ7RVtlpZiWP+fACapLtfh8yyv7lzOy21s8ex3G9vgREj2HPbbexauJDKd96h4fLLCfbogaWmhtx//Yuys86i18EHU3DPPaGfnwga2KQr28qVQKghRUuNl10GQM7MmSiNjUldk7p7N4W/+Q0Ae376UwItgj3RTAIqIYQQacso+esoQ+X49FMUv5/AoEFmo4hkabmPytiX4znySPT8/KSuI9MFhgxBy81F9XgS2pjC9Z//oGgavgkTkv6zkmkCBxwQygp5PJ22L49nQ4p2KQr+Aw+k/ve/Z+eiRVS98gpNP/oRWkEBlh07yPvb3+h53HGUnn8+eL2JW0cCGRmqvYMW79SpBIYMQd2zB1eSOx8W3nEHlupq/KNG0XD99Ul97UwiAZUQQoi0ZWSoOmqdbrZLT0FWyBzuu2FDc7lfuFRKREFV8YdnFyVywK9R7td09tkJe42soSiRdfvTdWzJCKhaslrxTZ1K7cMPU7FkCdXPPIP75JNDA7A//ZTC3/0uOeuII6WuDuv27cC+GSpUlcaf/ASA3OefT1oWzvnee7jeeQfdYqH2z3+O61iMbCMBlRBCiLQVNBo/uN2oO3fu+4AW7dKTun8qzMhQ2b/8Etvq1eg2G55jjkn6OrJBogf8Wteuxb5sGbrViufUUxPyGtnGKPtzfvhhu1kfy4YNWGpq0B0Os1tjUjmdeE44gZqnnqL62WfRFYXcf/7TDJ4zhdmQok8f9MLCfe5vOucctNxcbN9/j/2zzxK+HqW6msJf/xqAhuuuMz/wEG2TgEoIIUT6stk6bJ1uXbEiNKDV5cJ7yCHJXp0ZUKnhfQ3eKVPQi4qSvo5sYARU9gRlqIwLbO/06WhZNBg5kfwTJxLs1Qt1zx4cCxa0+Riz3G/s2JRnMLzTp9Pws58BUHjbbVjXrEnpeqJhDXdJDOydnQrT8/Nxh+dzJaOFeuFdd2GprMQ/bBh7br454a+X6SSgEkIIkdbMfVRttE43slO+KVPA6UziqkK0nj3RWnS8ku5+sfMZGaqVK+PfmELTcL31FgBNMnsqcqqK5/jjgfbL/oyGFP40aUG/5+ab8Uydiup2U3zllSgNDaleUkSMtvP+/fdv9zFG2Z/zww+xbNmSsLU4PvqInDfeQFdVah9+WIZfR0ACKiGEEGnN3EfVRobKGZ4/lbKueopiZql0iwXPccelZh1ZIDh4MFpeHorHg3Xt2rge2/7FF1i3bUMrKJCSzCiZZX8ffADB4D7327/5Bkji/qnOWCzUPvYYwd69sa1fT9EvfpERnf/Mkr92MlQAgaFD8R5xBIqmkfPiiwlZh1JfT9FttwHQeOWV+A88MCGvk20koBJCCJHW2ptFpVRXYwtfzHmT3C69JSOg8h12mJSSdUXLxhRx3kdlzp46+eSUZDIzme/QQ9GKirBUV2P/6qtW9yl79pid6dImoAK00lKq//Y3dKsV1zvvkPuPf6R6SR3T9eYZVB0EVAAN4RbquS+/DG533JdScM89WCoqCAweTP0vfxn342crCaiEEEKktfZapzs/+QRF0/CPHEmwb98UrCzEfdppBMvKaLj22pStIVskZB+V2212YHTL7Kno2Wx4jj0WwBwNYLAvWYKi6wQGDEDr2TMVq2uXf9Ik6n/7WwAKfv97bOHSxHRk2boVtaEB3WYzP6Bpj/foown0749aW0vOf/4T13U4PvmE3JdfRlcUah96CFyuuB4/m0lAJYQQIq211zrdkepyvzDvMcew89tv8U6bltJ1ZAPfuHEA2L77Lm7HdH74IeqePQT69sWXgsYl2cAdHgXgeu890DTz9qS3S49S42WX4T7lFJRAgJJrrkHdvTvVS2qT2ZBi6NDOG3tYLDReeilAKPMWp3JGpaGBwnBGqvEnP5H3SpQkoBJCCJHWgv37N7dOr6gI3xjEMXcukNpyPxFf/paNKfz+uBwzxyj3O/NMUOWyJxbeI45Ay83FUlHRak5YUgb6doWiUPt//4d/v/2w7NhB0Q03tLkPLNWM/VP+vQb6tqfpRz9CczqxrVyJ/euv47KGgj/8AevWrQT692fP7bfH5ZjdifxmEUIIkd5atk4Pd/qzLV2KpaYGraAgfS/mRNSCgwahFRSgeL1xaXmt7t6NY948ANzS3S92Tqc5583s9qdpZkCVLh3+2qLnaJvHbwAAHvJJREFU5VHz9NNoLhfOTz4h/89/TvWS9mHrpGX63vTiYrN8NR77w+yffx4aGAzU/ulP6C06l4rISEAlhBAi7QX2akxhdPfzHnkk2GwpW5eIM0UxG1PY49CYwvn22yiBAL6xYwkMG9bl43VnRrc/17vvhpoorFuHWl+P5nJFnFlJlcDIkdQ98AAAeY88Yma300WkDSlaMluov/ce6o4dMb+24naHOiECjRdeiO+II2I+VncmAZUQQoi0t3frdEd4/pRHyv2yjln2F4fGFGa5n2Snusx71FHoDgfWTZuwrl7dnJ0aPx6s1tQuLgLus86i8aKLUHSd4htuwLJtW6qXFOL1Yl2/Hoi85A8gsP/+eA89FCUYJPef/4z55fMfeADrpk0Ee/em/je/ifk43Z0EVEIIIdJey9bp6s6dZvbCO316KpclEsAc8NvFDJVl3TrsS5agWyy4TzstHkvr1vS8PDxHHgmEyv6MrnmZVHJbd9dd+MaORa2tpfjqq8HrTfWSsH7/PUowiFZYiNa7d1TPNZpT5Lz0Ukxfi23RInKfeQaA2gcfRC8oiPoYIkQCKiGEEGnPbJ2+aZNZruMbPx6tR48UrkokQqvGFD5fzMfJefNNIFQWKj8n8eExyv7eey/9G1K0xekM7acqKsK+ZAmFv/99p09RKytxzJ9P7pNPUnTjjfQ4+mhKLrgAPJ64LMnWstxPUaJ6ruf44wmWl2OpqsI1a1Z0L+zxUPTzn6PoOk3nnCPNfboo/XO0Qgghur2WJX/Ojz4CpLtftgoOHIhWWIhaV4d17VoCo0dHfxBdxxUOqKTcL348xxyDbrGYTRQA/JkUUBHqGlrzl79Qeskl5D7/PL5Jk3CfcQYEAljXr8e2ciXWlSuxhf9n2bVrn2PYVq/G8dlneGfM6PJ6jIAqEMs+NJuNxosvpuDBB8l97rn2f9Z9Pqxr12JbsSL0v+XLsa1cibpnD8GePan73e+68BUIkIBKCCFEBgj2749utaJ6PGZAJfunslS4MYXjs8+wf/ttTAGV/euvsW7Zgpabi+e44xKwyO5JLy7Gd/jhOD79FAh90KGVlqZ4VdHzzpjBnhtvJP+vf6Xwl78k9+mnsa1Zg9JG2ZyuKAQHDcK///74998f++LFOD/+GMe8eXEJqIwZVNE0pGip6cILyX/kEexLlmBbsoTAkCGhYHD5cjOAsn7/PUobYwi0/HxqH3kEvbi4S1+DkIBKCCFEJrBaCfbrh3XTJhS/n2BpKf7wEFiRfXzjxuH47LPQgN8LL4z6+a7XXwfAc+KJ6C5XvJfXrblPOMEMqDKq3G8ve375S+zffINjwQLs4UHSWk4OgXDgZPwvMHJkqzbizv/9D+fHH+OcO5f6OKzDFkOHv5a0sjLcp5xCzhtvUHruuahNTW0/rrAw9DWNHo3/gAPwH3BAZIOERUQkoBJCCJERAkOGmHOovNOny5DWLGbuowpf6EbDvmABOa+9BkCTlPvFnef449HvuANF1zM6oMJiofrvfyfntdcI9u6Nf//9CQ4c2OnvFe/kyeg2G9ZNm7Bs3Gg2zImFUl2NJTysPNIZVG1pvOIKXG++aQZTgX79QgHTAQeYAVSwb9+o92iJyElAJYQQIiMEWly4SLlfdjMDqlWrQt3LHI6InmddvpySyy5D8flwn3givilTErnMbknr1QvPiSfimD/fHPabqfTCQhqvuCK65+Tl4TvoIBwLF+KYN4+mLgRU5v6p/v3R8/NjPo5/7FiqZs1CaWzEf8AB6EVFMR9LxEY+3hNCCJERguFOf7rFEhroK7JWsH9/tKIiFL8f25o1ET3HsnkzpRddhNrQgPeww6j561/lE/kEqXniCSq+/TaU9eiGjHENzi4OCDYDqi5kpwz+8ePxTZ4swVSKSEAlhBAiI/gmTQLAO22aXDRkO0VpnkcVQdmfuns3pRdcgGXXLvyjRlH97LPgdCZ6ld2X1dqtv7+eadMAsC9c2KX26VZj/1QsHf5EWpGASgghREbwjx3Lro8/puaxx1K9FJEEke6jUhobKbn4YqwbNxLo14/d//oXemFhMpYouqnAqFEEy8tR3W4cX30V83FsK1cCsTekEOlDAiohhBAZIzBiBHpBQaqXIZIgooDK56P4qquwL11KsLiY3S+9hFZenqQVim5LUcwslSPWsj9NwxouZ41pBpVIKxJQCSGEECLtGG3xbatXt11WpWkU/fznOOfNQ3O5qH7xRYJDhyZ5laK78hoB1bx5MT3fsmULalMTut1OYMiQ+C1MpIQEVEIIIYRIO8G+fQkWF4caU4T3mrRUcN995Lz5JrrVSs3TT+M/8MAUrFJ0V94jjkBXVWxr12LZti3q59vCA30Dw4aF9qSJjCYBlRBCCCHSj6I0Z6n2KvvL/dvfyPvb3wCo/b//wytt9EWS6UVFZhAfS9mfNRxQyf6p7CABlRBCCCHSkn/MGKB1QOV64w0K77kHgPo77sB9zjkpWZsQnnD79FjK/oysq3///eO5JJEiElAJIYQQIi0ZGSp7OKByzJtH0S23ANBwxRU0XHttytYmhDGPyvHpp+D3R/VcI0MVjxlUIvUkoBJCCCFEWjJmUVnXrMH+1VcUX3klSiBA0+mnU/+738ngXpFS/jFjCJaUoDY0YF+8OPInut1YN24MHUMCqqwgAZUQQggh0pLWpw/B0lKUQIDS889HbWrCM3UqtX/+M6hyCSNSTFWbu/1FsY/Ktm4diqYRLC5G69UrQYsTySS/jYQQQgiRnlo0plA8Hnxjx1Lz97+D3Z7ihQkRYpT9OaMIqKzhgb6BkSMly5olJKASQgghRNryhTupBQYNovqf/0TPy0vxioRo5j3ySHRFwbZiBerOnRE9RxpSZB8JqIQQQgiRthovv5y6u+6i6vXX0crKUr0cIVrRSkvxh/f6OebPj+g51nBAJQ0psocEVEIIIYRIW3pBAY1XXonWu3eqlyJEm8x9VBG2T7fJDKqsIwGVEEIIIYQQMTL3Uc2fD8Fgh49Vd+/GUlmJrigERoxIxvJEEkhAJYQQQgghRIx8EyagFRai1tZiW7q0w8ca86eCAwei5+YmYXUiGSSgEkIIIYQQIlZWK94jjgDA2UnZn5T7ZScJqIQQQgghhOgCT7jsr7N5VGZDilGjEr4mkTwSUAkhhBBCCNEF3iOPBMC2dClqdXW7jzNbpkuGKqtYU72AjnzwwQe888471NbWMnDgQC677DKGDh3a7uMbGxt55ZVX+Oqrr2hoaKBHjx5ccsklHBieYSGEEEIIIUS8ab174x81CtuqVTg++QT36afv+6Bg0MxQSUCVXdI2oFq4cCEvvvgiV155JcOGDePdd9/lvvvu45FHHqGwsHCfxwcCAe69914KCgq45ZZbKCkpoaqqipycnBSsXgghhBBCdCee6dNDAdXcuW0GVJYffkD1eNCdToKDByd/gSJh0jagmjVrFkcffTTTwzWpV155Jd988w1z587l9DZ+SD/++GMaGhq45557sFpDX1bPnj3bPb7f78fv95v/VhQFl8tl/neqGWtIh7WI5JBz3j3Jee+e5Lx3T3Les5tv+nR44gkc8+ej6DqooZ01xvk2y/2GD0expu0luIhBWp7NQCDAhg0bWgVOqqoyZswY1q5d2+ZzFi9ezLBhw3j22WdZtGgRBQUFTJ48mdNPPx1V3Xer2FtvvcXrr79u/nvw4ME88MAD9OjRI+5fT1eUl5enegkiyeScd09y3rsnOe/dk5z3LHXqqZCXh6Wykt67dsGECa3uLt6yBQD7gQfSWwZVZ5W0DKjq6+vRNI2ioqJWtxcVFbF9+/Y2n7Nz504qKyuZMmUKv/rVr6ioqOCZZ54hGAxyzjnn7PP4M844g5NPPtn8t/HpQWVlJYFAIH5fTIwURaG8vJyKigp0XU/1ckQSyDnvnuS8d09y3rsnOe/Zr3jyZJz/+x/1M2fSGA6cjfPu+fprnED9oEE07tiR2oWKTlmt1ogTLWkZUMVC13UKCgq4+uqrUVWVIUOGUF1dzdtvv91mQGWz2bDZbO0eK13oup5W6xGJJ+e8e5Lz3j3Jee+e5LxnL8+0aTj/9z8cc+fScOONre4zGlL4RoyQ859l0jKgKigoQFVVamtrW91eW1u7T9bKUFRUhNVqbVXe17dvX2prawkEAua+KiGEEEIIIRLBO20aAPZFi1Dq69ELCkJ3NDZi2bgRkBlU2Sgt51BZrVaGDBnC8uXLzds0TWP58uUMHz68zeeMGDGCiooKNE0zb9uxYwfFxcUSTAkhhBBCiIQLDhiAf7/9UIJBHJ991nzHypUouk6wrAwtzfbri65Ly4AK4OSTT2bOnDnMmzePrVu38swzz+D1epkWjvwfe+wxXn75ZfPxxx57LA0NDTz//PNs376db775hrfeeovjjjsuRV+BEEIIIYTobowslWPu3OYbly0DICDzp7JS2qZuDj/8cOrr65k5cya1tbUMGjSIX//612bJX1VVVau2o2VlZdxxxx288MIL/PKXv6SkpIQTTjihzRbrQgghhBBCJIL3qKPIe/ZZnHPnUqfroCjw3XeADPTNVmkbUAEcf/zxHH/88W3ed9ddd+1z2/Dhw7nvvvsSvCohhBBCCCHa5j3kEHSnE8uOHVjXriU4cqSZofLvv3+KVycSIW1L/oQQQgghhMg4Lhfeww4DwmV/um5mqKTkLztJQCWEEEIIIUQcGfuonHPnolZWQlUVuqIQaKe5mshsElAJIYQQQggRR57p0wGwf/UVtsWLAQgOHozucqVyWSJBJKASQgghhBAijoJDhhAYMADF5yP3H/8AwC/zp7KWBFRCCCGEEELEk6I0t09fsACQgb7ZTAIqIYQQQggh4swo+zNIhip7SUAlhBBCCCFEnPkmT0a32cx/S4e/7CUBlRBCCCGEEHGm5+biO/jg0D9ycggOHJjaBYmEkYBKCCGEEEKIBDDL/kaPBlUuu7OVNdULEEIIIYQQIhs1XXghtrVrybnyylQvRSSQBFRCCCGEEEIkgF5QQN0jj5DTuzfs2JHq5YgEkdyjEEIIIYQQQsRIAiohhBBCCCGEiJEEVEIIIYQQQggRIwmohBBCCCGEECJGElAJIYQQQgghRIwkoBJCCCGEEEKIGElAJYQQQgghhBAxkoBKCCGEEEIIIWIkAZUQQgghhBBCxEgCKiGEEEIIIYSIkQRUQgghhBBCCBEjCaiEEEIIIYQQIkYSUAkhhBBCCCFEjCSgEkIIIYQQQogYSUAlhBBCCCGEEDGSgEoIIYQQQgghYiQBlRBCCCGEEELESAIqIYQQQgghhIiRBFRCCCGEEEIIESMJqIQQQgghhBAiRhJQCSGEEEIIIUSMJKASQgghhBBCiBhJQCWEEEIIIYQQMZKASgghhBBCCCFiJAGVEEIIIYQQQsTImuoFpBurNb2+Jem2HpF4cs67Jznv3ZOc9+5Jznv3JOc9s0RzvhRd1/UErkUIIYQQQgghspaU/KUpt9vNbbfdhtvtTvVSRJLIOe+e5Lx3T3Leuyc5792TnPfsJwFVmtJ1nY0bNyIJxO5Dznn3JOe9e5Lz3j3Jee+e5LxnPwmohBBCCCGEECJGElAJIYQQQgghRIwkoEpTNpuNs88+G5vNluqliCSRc949yXnvnuS8d09y3rsnOe/ZT7r8CSGEEEIIIUSMJEMlhBBCCCGEEDGSgEoIIYQQQgghYiQBlRBCCCGEEELESAIqIYQQQgghhIiRNdULEPv64IMPeOedd6itrWXgwIFcdtllDB06NNXLEnGycuVK3n77bTZu3EhNTQ2/+MUvOPjgg837dV1n5syZzJkzh8bGRkaOHMkVV1xB7969U7hq0VVvvfUWX331Fdu2bcNutzN8+HB+/OMf06dPH/MxPp+PF198kYULF+L3+xk3bhxXXHEFRUVFqVu4iNns2bOZPXs2lZWVAPTr14+zzz6bCRMmAHK+u4v//Oc/vPzyy5x44olceumlgJz7bDRz5kxef/31Vrf16dOHRx55BJBznu0kQ5VmFi5cyIsvvsjZZ5/NAw88wMCBA7nvvvuoq6tL9dJEnHi9XgYNGsTll1/e5v3//e9/ef/997nyyiu5//77cTgc3Hffffh8viSvVMTTypUrOe6447jvvvv4zW9+QzAY5N5778Xj8ZiPeeGFF1i8eDG33HILd999NzU1NTz00EMpXLXoipKSEi644AL++Mc/8oc//IHRo0fz4IMPsmXLFkDOd3ewbt06PvzwQwYOHNjqdjn32al///48/fTT5v9+//vfm/fJOc9uElClmVmzZnH00Uczffp0+vXrx5VXXondbmfu3LmpXpqIkwkTJnDeeee1ykoZdF3nvffe48wzz+Sggw5i4MCB3HDDDdTU1PD111+nYLUiXu644w6mTZtG//79GTRoENdffz1VVVVs2LABgKamJj7++GMuueQSRo8ezZAhQ7juuutYs2YNa9euTfHqRSwmTZrEgQceSO/evenTpw/nn38+TqeT77//Xs53N+DxePjrX//K1VdfTW5urnm7nPvspaoqRUVF5v8KCgoAOefdgQRUaSQQCLBhwwbGjBlj3qaqKmPGjJE3XDexa9cuamtrGTt2rHlbTk4OQ4cOlZ+BLNPU1ARAXl4eABs2bCAYDLZ6//ft25eysjI591lA0zQWLFiA1+tl+PDhcr67gWeeeYYJEya0+n0O8l7PZhUVFVx99dXccMMNPProo1RVVQFyzrsD2UOVRurr69E0bZ962qKiIrZv356aRYmkqq2tBaCwsLDV7YWFheZ9IvNpmsbzzz/PiBEjGDBgABA691artdUn2SDnPtNt3ryZO+64A7/fj9Pp5Be/+AX9+vVj06ZNcr6z2IIFC9i4cSN/+MMf9rlP3uvZadiwYVx33XX06dOHmpoaXn/9dX7729/y0EMPyTnvBiSgEkKIJHv22WfZsmVLq/p6kZ369OnDn/70J5qamvjiiy94/PHHufvuu1O9LJFAVVVVPP/88/zmN7/BbrenejkiSYxmMwADBw40A6zPP/9cfg66AQmo0khBQQGqqu7zaUVtba10gekmjPNcV1dHcXGxeXtdXR2DBg1KzaJEXD377LN888033H333ZSWlpq3FxUVEQgEaGxsbPUpZl1dnbz/M5jVaqW8vByAIUOGsH79et577z0OP/xwOd9ZasOGDdTV1XHbbbeZt2maxqpVq/jggw+444475Nx3A7m5ufTp04eKigrGjh0r5zzLyR6qNGK1WhkyZAjLly83b9M0jeXLlzN8+PAUrkwkS8+ePSkqKmLZsmXmbU1NTaxbt05+BjKcrus8++yzfPXVV/z2t7+lZ8+ere4fMmQIFoul1bnfvn07VVVVcu6ziKZp+P1+Od9ZbMyYMfzf//0fDz74oPm//fbbjylTppj/Lec++3k8HioqKigqKpL3ezcgGao0c/LJJ/P4448zZMgQhg4dynvvvYfX62XatGmpXpqIE+OXrGHXrl1s2rSJvLw8ysrKOPHEE3nzzTfp3bs3PXv25NVXX6W4uJiDDjoohasWXfXss8/y2Wefceutt+JyucxMdE5ODna7nZycHI466ihefPFF8vLyyMnJ4R//+AfDhw+XP7gZ6uWXX2b8+PGUlZXh8Xj47LPPWLlyJXfccYec7yzmcrnMvZEGh8NBfn6+ebuc++zz4osvMmnSJMrKyqipqWHmzJmoqsqUKVPk/d4NKLqu66lehGjtgw8+4O2336a2tpZBgwbxk5/8hGHDhqV6WSJOVqxY0eYeiiOPPJLrr7/eHOz70Ucf0dTUxMiRI7n88stbDYAVmefcc89t8/brrrvO/MDEGPy4YMECAoGADH7McE8++STLly+npqaGnJwcBg4cyGmnnWZ2fZPz3X3cddddDBo0aJ/BvnLus8cjjzzCqlWr2LNnDwUFBYwcOZLzzjvPLPmVc57dJKASQgghhBBCiBjJHiohhBBCCCGEiJEEVEIIIYQQQggRIwmohBBCCCGEECJGElAJIYQQQgghRIwkoBJCCCGEEEKIGElAJYQQQgghhBAxkoBKCCGEEEIIIWIkAZUQQgghhBBCxMia6gUIIYTovq6//noqKys7fdx1113HtGnTEr+gODj33HMBmDlzZopXIoQQIhkkoBJCCJFyI0aMoLy8vN37O7pPCCGESCUJqIQQQqTc0UcfnTEZKCGEEKIl2UMlhBBCCCGEEDGSDJUQQoiM0nKP0kcffcSHH37I9u3bsVgsjBgxgrPOOovhw4e3+dyGhgbefvttFi1axK5du1BVld69e3P44YdzwgknYLfb23xedXU17777LkuXLqWyshJd1ykpKWH48OHMmDGDESNGtPm8L774gnfffZfNmzejaRqDBg3ijDPO4MADD9znsTU1NfznP/9h6dKlVFVVoSgK+fn59O7dm/Hjx3PqqafG+B0TQgiRSBJQCSGEyEgvvPAC7733HiNGjGDSpEls3ryZJUuW8N1333HzzTdz8MEHt3r8zp07+f3vf09lZSUFBQVMmDCBYDDIihUreOmll1i4cCF33nkneXl5rZ63bNkyHn74YRobGyksLGT06NFYrVYqKyv57LPPANoMqGbOnMkbb7zB8OHDmTBhAtu2bWPNmjU88MAD/PznP2+1vtraWm6//XZqamooKytj3Lhx2O12ampq2LRpExs2bJCASggh0pQEVEIIITLShx9+yJ133sno0aPN295++23+9a9/8cQTTzBixAgKCwvN+x599FEqKyuZNGkSN910E06nE4D6+nruu+8+Nm7cyD/+8Q9uuukm8zlVVVU89NBDNDU1cfrpp3PuueditTb/6ayrq2PHjh1tru/999/n3nvvZdiwYeZtM2fO5PXXX+ell15qFVB99NFH1NTUMGPGDK688koURTHvCwQCrFq1qgvfKSGEEIkkAZUQQoiUe+KJJ3jiiSfavf+5554jNze31W0zZsxoFUwBnHrqqXz++eesX7+eOXPmcOaZZwKwevVqvv/+exwOB1dddZUZTAEUFBRw9dVXc/vtt7NgwQIuvPBCSktLAZg1axZNTU1MnDiRCy64YJ91FRYWtgraWjr33HNbBVMAZ5xxBu+99x47duygqqqKsrIyIJShAhg/fnyrYArAarUyZsyYdr83QgghUksCKiGEECnXWdv0llkhQ3tdAadOncr69etZuXKlGVCtWLECgHHjxlFUVLTPc4YMGcLAgQP54YcfWLlyJUcccQQA3377LRAK3qI1ceLEfW6z2Wz06tWLjRs3Ul1dbQZUQ4cOZfbs2bz00kvous64ceNaBX1CCCHSlwRUQgghUi6Wtuk9e/bs8Pbdu3ebt1VXV3f4HIBevXrxww8/mI8FzKHDffv2jWptgBks7c3lcgHg9/vN26ZOncp3333HZ599xkMPPYSqqvTr14+RI0dy6KGH7pOJE0IIkT4koBJCCCESQFUjn0yiqio33XQTZ555Jt988w2rV69mzZo1zJ49m9mzZzNx4kR++ctfRnVMIYQQySEBlRBCiIy0a9cuBg0atM/tRlappKTEvM347127dnV4vL2fV1ZWxvbt29m2bVuHJYnx0q9fP/r168epp56KrussX76cRx99lMWLFzN//nymT5+e8DUIIYSIjnzUJYQQIiN98sknHd5+wAEHmLcZ/7106VKzAURLGzduZNOmTSiKwqhRo8zbx48fD8CcOXPitOrIKYrCmDFjmDx5MgCbNm1K+hqEEEJ0TgIqIYQQGWn27NlmswnDrFmzWLduHS6Xi6OOOsq8feTIkQwbNgyfz8fTTz+N1+s176uvr+fpp58GYPLkya32Pp188sm4XC4WLVrEq6++SiAQaPV6dXV1rF69ustfy/z589mwYcM+t7vdblauXAlAjx49uvw6Qggh4k9K/oQQQqTcnDlz9gmOWho3bhxTpkxpdduMGTP4/e9/z8iRIykpKWHLli1s3rwZVVW59tpr9+nmd9NNN/H73/+eRYsWccMNNzBq1CgCgQArVqzA7XYzePBgLrvsslbPKSsr45ZbbuHhhx/mzTffZM6cOQwfPhyLxUJVVRUbN25kypQpjBw5sktf/5dffsnjjz9OcXExgwYNIjc3l8bGRtasWUNTUxP9+/fn6KOP7tJrCCGESAwJqIQQQqTcmjVrWLNmTbv35+bm7hNQXXrppfTp04ePPvqIr7/+GovFwvjx4znrrLMYMWLEPsfo1asXDzzwAG+//TZff/01ixcvRlVV+vTpw2GHHcaJJ56I3W7f53njxo3joYceYtasWSxdupSlS5disVgoLi5m6tSpcQl0TjnlFHr27MnatWvZuHEjDQ0N5OXl0a9fP6ZMmcK0adOkjboQQqQpRdd1PdWLEEIIISJ17rnnAjBz5swUr0QIIYSQPVRCCCGEEEIIETMJqIQQQgghhBAiRhJQCSGEEEIIIUSMZA+VEEIIIYQQQsRIMlRCCCGEEEIIESMJqIQQQgghhBAiRhJQCSGEEEIIIUSMJKASQgghhBBCiBhJQCWEEEIIIYQQMZKASgghhBBCCCFiJAGVEEIIIYQQQsRIAiohhBBCCCGEiNH/A9Z8/0/OvL7uAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# loss curve（モデルの正確性を表す損失関数の学習過程における変化）の表示\n",
        "plt.figure(figsize=[10,8]) #グラフの大きさを設定\n",
        "plt.plot(model.history.history['loss'], 'r') #学習データの損失関数を赤色（'r'）で表示する\n",
        "plt.plot(model.history.history['val_loss'], 'b') #検証データの損失関数を青色（'b'）で表示する\n",
        "plt.legend(['Training loss', 'Validation Loss']) #グラフに反例を追加する\n",
        "plt.xlabel('Epochs', fontsize=16) #横軸のラベルを設定する\n",
        "plt.ylabel('Loss', fontsize=16) #縦軸のラベルを設定する\n",
        "plt.title('Loss Curves', fontsize=16) #グラフのタイトルを設定する\n",
        "\n",
        "#グラフを表示する\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け次のコード解説\n",
        "```\n",
        "このコードは、モデルの「正確性（Accuracy）」が時間の経過とともにどう変化していったかを示すグラフを描くためのものです。\n",
        "\n",
        "・赤い線（学習データの正確性）：モデルが学習する過程で、正解率がどう上がっていったかを示しています。\n",
        "・青い線（検証データの正確性）：学習後、別のデータを使ってモデルがどれだけ正しく予測できたかを示しています。\n",
        "\n",
        "このグラフは、モデルが学習を進めるにつれてどれだけ正確に問題を解けるようになったか、またその正確さが新しいデータに対しても\n",
        "どのように変わっているかを確認するために使います。\n",
        "\n",
        "＜理想のカーブ＞\n",
        "・両方の線が徐々に増加：エポックが進むごとに、学習と検証の両方で正確性が上がるのが理想です。\n",
        "・検証データの正確性が安定：ある時点で検証データの正確性（青い線）が横ばいになっても、それは自然なことです。\n",
        "モデルがそのデータセットに対して最大の能力を発揮し、これ以上改善しない場合もあります。\n",
        "```"
      ],
      "metadata": {
        "id": "kBu-TZBnyczs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9uKokKdSUbtl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "outputId": "3fa15a25-b47f-41c3-cf5c-6985a6ada0b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# accuracy curve（モデルの正確性の指標の学習過程における変化）の表示\n",
        "plt.figure(figsize=[10,8])\n",
        "plt.plot(model.history.history['accuracy'], 'r')\n",
        "plt.plot(model.history.history['val_accuracy'], 'b')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####損失（モデルがどれだけ予測を間違えたか）の変化を表すグラフを表示しました。<br>赤い線で学習データ、青い線で確認用データの結果を示しています。<br>また、正確さの変化を表すグラフも表示し、学習データと確認用データの両方を比較しました。<br>これにより、どれだけうまく学習できているかがわかるようになりました。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "C9YQUriZVasg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls8XtECgUbtl"
      },
      "source": [
        "## 7. モデルによる判定\n",
        "学習・検証用データに構築したモデルで良品、不良品の判定を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VhSZQek3Ubtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f10b3a-9908-49a0-f68f-f40dc1863b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model...\n"
          ]
        }
      ],
      "source": [
        "# weightファイルの読み込み\n",
        "print('load model...')\n",
        "model.load_weights(save_weights_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、モデルが画像を見て、その画像がどのクラス（カテゴリー）に属しているかを予測するためのものです。\n",
        "\n",
        "何をするコードなのか？\n",
        "目的:\n",
        "コンピュータが画像の分類を予測し、その予測結果を本当の答え（クラス）と比べて、どれくらい正確に分類できたかを確認するための関数です。\n",
        "\n",
        "使われるデータ:\n",
        "学習用画像：コンピュータがすでに学習しているデータです。このデータで、クラス名がどう割り当てられているかを把握します。\n",
        "テスト用画像：コンピュータがまだ見たことがない画像です。この画像を使って、コンピュータがどれだけ正しく予測できるかをテストします。\n",
        "\n",
        "コードの流れとしては、\n",
        "1.テスト用画像を読み込む準備をする\n",
        "2.テスト用画像を1枚ずつ読み込む\n",
        "3.モデルに画像を渡して予測する\n",
        "4.予測結果からクラスを取り出す\n",
        "5.クラス番号からクラス名を取得する\n",
        "6.本当のクラス名を取得する\n",
        "7.結果を返す\n",
        "という一連の動作を行なっています。\n",
        "```"
      ],
      "metadata": {
        "id": "uhszaJcIzRi0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NRJxRGtGUbtl"
      },
      "outputs": [],
      "source": [
        "# 良否判定を行うための関数\n",
        "def get_predict(model,\n",
        "                train_data_dir: str,\n",
        "                test_data_dir: str):\n",
        "    \"\"\"この関数は、テスト用の画像データを使ってモデルの予測を行い、\n",
        "    その結果をリストに保存する。\n",
        "\n",
        "    Args:\n",
        "        model (object): 訓練済みのモデル。\n",
        "        train_data_dir (str): 学習用画像が保存されているフォルダのパス。\n",
        "        test_data_dir (str): テスト用画像が保存されているフォルダのパス。\n",
        "\n",
        "    Returns:\n",
        "        filenames (list): 予測した画像のファイル名のリスト。\n",
        "        true_classes (list): 予測した画像の本当のクラス（カテゴリー）のリスト。\n",
        "        pred_classes (list): モデルが予測したクラス（カテゴリー）のリスト。\n",
        "    \"\"\"\n",
        "\n",
        "    # テスト用画像を読み込み、モデルに入力するための準備をする\n",
        "    # 画像の色の値を0から1の範囲に変換して扱いやすくする\n",
        "    data_datagen = ImageDataGenerator()\n",
        "\n",
        "    # テスト用の画像を一枚ずつ読み込んでモデルに渡す準備をする\n",
        "    test_generator = data_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=TARGET_SIZE,  # 画像の大きさを指定されたサイズに変更する\n",
        "        class_mode=None,  # ラベル（正解）は指定しない\n",
        "        batch_size=1,  # 一度に1枚の画像を処理する\n",
        "        shuffle=False,  # 画像の順番をシャッフルしない（後でファイル名と予測結果を対応させるため）\n",
        "    )\n",
        "\n",
        "    # モデルにテスト用の画像を入力して、どのクラスに分類されるかを予測する\n",
        "    preds = model.predict_generator(test_generator)\n",
        "\n",
        "    # 予測結果から、一番高い確率で選ばれたクラスの番号を取り出す\n",
        "    preds_class_idx = preds.argmax(axis=-1)\n",
        "\n",
        "    # 予測したクラスの名前を取得するための準備\n",
        "    # 学習用画像の情報を使って、クラス名（カテゴリー名）を取得する\n",
        "    train_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    # モデルが使っている番号とクラス名（カテゴリー名）を対応させる辞書を作る\n",
        "    idx_to_class = {v: k for k, v in train_generator.class_indices.items()}\n",
        "    # 予測されたクラスの番号をクラス名に変換する\n",
        "    pred_classes = np.vectorize(idx_to_class.get)(preds_class_idx)\n",
        "    # ファイル名と予測されたクラス名をペアにしたリストを作成する\n",
        "    filenames_to_class = list(zip(test_generator.filenames, pred_classes))\n",
        "\n",
        "    # 本当のクラス名（カテゴリー名）を取得するための準備\n",
        "    filenames = []\n",
        "    true_classes = []\n",
        "\n",
        "    for item in test_generator.filenames:\n",
        "        filenames.append(item)\n",
        "        # ファイル名から本当のクラス名（カテゴリー名）を取り出す\n",
        "        true_class = item.split('/')[0]\n",
        "        true_classes.append(true_class)\n",
        "\n",
        "    return filenames, true_classes, pred_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####保存された重みファイルを読み込み、モデルに画像データを渡してその予測結果を取得する関数を定義しました。<br>画像を1枚ずつ読み込み、モデルに入力して分類を予測します。<br>予測結果は、ファイル名と対応させてリストに保存され、実際の答えとモデルが予測した答えを比較できるようにします。<br>これにより、モデルがどれだけ正確に画像を分類できるかを確認できます。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "ggMaRANHWQCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、コンピュータが「どれだけ正確に答えを予測できたか」を評価するために、\n",
        "F1スコア、精度（Precision）、再現率（Recall）という3つの指標を計算する関数です。\n",
        "これらの指標を使うと、モデルの予測がどれくらい優れているかがわかります。\n",
        "\n",
        "F1スコア：予測の全体的なバランスを示す指標。精度と再現率のバランスが良いほどF1スコアが高くなります。\n",
        "精度（Precision）：コンピュータが「正しい」と予測した中で、本当に正しかったものの割合。\n",
        "再現率（Recall）：本当に正しかったものを、コンピュータがどれだけ正しく見つけたか。\n",
        "```"
      ],
      "metadata": {
        "id": "crwNDZdlzaTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QkvF2sCVUbtm"
      },
      "outputs": [],
      "source": [
        "# 精度算出関数（F1スコア、精度、再現率を計算する関数）\n",
        "def get_f1(true_labels_list: list,\n",
        "           predictions_list: list,\n",
        "           average_method: str,\n",
        "          ) -> (float, float, float):\n",
        "    \"\"\"この関数は、モデルの予測結果に基づいて、F1スコア、精度、再現率を計算する。\n",
        "\n",
        "    Args:\n",
        "        true_labels_list (list): 正解ラベルのリスト。\n",
        "        predictions_list (list): 予測ラベルのリスト。\n",
        "        average_method (string): スコアを平均化する方法（マルチクラス分類の場合）。\n",
        "\n",
        "    Returns:\n",
        "        f1 (float): F1スコアを返す。\n",
        "        precision (float): 精度を返す。\n",
        "        recall (float): 再現率を返す。\n",
        "    \"\"\"\n",
        "\n",
        "    # F1スコアを計算する。F1スコアは精度と再現率のバランスをとる指標。\n",
        "    f1 = f1_score(\n",
        "        y_true=true_labels_list,  # 正解ラベルのリスト\n",
        "        y_pred=predictions_list,  # 予測ラベルのリスト\n",
        "        average=average_method    # 複数クラスの場合にどう平均化するかを指定\n",
        "    )\n",
        "\n",
        "    # 精度（Precision）を計算する。精度は、モデルが予測した「正しい」予測の割合を示す指標。\n",
        "    precision = precision_score(\n",
        "        y_true=true_labels_list,  # 正解ラベルのリスト\n",
        "        y_pred=predictions_list,  # 予測ラベルのリスト\n",
        "        average=average_method,   # 複数クラスの場合にどう平均化するかを指定\n",
        "    )\n",
        "\n",
        "    # 再現率（Recall）を計算する。再現率は、実際に正解であったものを、どれだけ正しく予測できたかを示す指標。\n",
        "    recall = recall_score(\n",
        "        y_true=true_labels_list,  # 正解ラベルのリスト\n",
        "        y_pred=predictions_list,  # 予測ラベルのリスト\n",
        "        average=average_method,   # 複数クラスの場合にどう平均化するかを指定\n",
        "    )\n",
        "\n",
        "    # 計算したF1スコア、精度、再現率を少数第2位まで丸める\n",
        "    f1 = round(f1, 2)\n",
        "    precision = round(precision, 2)\n",
        "    recall = round(recall, 2)\n",
        "\n",
        "    # F1スコア、精度、再現率を返す\n",
        "    return f1, precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、コンピュータがどれだけ正しく画像を分類できるかをテストしています。\n",
        "まず、学習に使ったデータ（学習データ）で正しく予測できるかを見て、次に学習していない検証データで正しく予測できるかを確認します。\n",
        "これにより、コンピュータが実際に新しいデータに対応できるかどうかをチェックしています。\n",
        "\n",
        "get_predict関数を使って、学習データと検証データでコンピュータがどれくらい正しく予測できるかを確認しています。\n",
        "\n",
        "このコードの結果について、\n",
        "Found 290 images belonging to 4 classes:\n",
        "\n",
        "これは、290枚の画像があって、それらが4つのクラスに分類されていることを示しています。コンピュータは、この290枚の画像を使って予測を行います。\n",
        "4回同じメッセージ（Found 290 images belonging to 4 classes）が表示されているのは、\n",
        "コンピュータが複数回にわたって同じ処理をしていることを示しています。\n",
        "それぞれの処理の段階で、290枚の画像が4つのクラスに分類されていることを確認しているのです。\n",
        "```"
      ],
      "metadata": {
        "id": "ogykJy0szkaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pRp51Ow0Ubtm",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0a519d-e484-41e9-fba1-a7c07f60193a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 290 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-93f27d49ad7e>:33: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  preds = model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 290 images belonging to 4 classes.\n",
            "Found 290 images belonging to 4 classes.\n",
            "Found 290 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# 良否判定実行（学習データに対してモデルの予測を行う）\n",
        "train_filenames, train_true_classes, train_pred_classes = get_predict(\n",
        "    model=model,  # 使用するモデルを指定\n",
        "    train_data_dir=train_data_dir,  # 学習データが保存されているフォルダのパスを指定\n",
        "    test_data_dir=train_data_dir,  # 学習データをテストデータとして使用し、モデルの予測を実行\n",
        ")\n",
        "\n",
        "# 良否判定実行（検証データに対してモデルの予測を行う）\n",
        "valid_filenames, valid_true_classes, valid_pred_classes = get_predict(\n",
        "    model=model,  # 使用するモデルを指定\n",
        "    train_data_dir=train_data_dir,  # 学習データが保存されているフォルダのパスを指定\n",
        "    test_data_dir=validation_data_dir,  # 検証データをテストデータとして使用し、モデルの予測を実行\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####モデルの性能を評価するために、学習データと検証データに対して予測を行い、その結果を基にモデルの精度を測定しました。<br>後述するF1-scoreなどの指標を使って、モデルがどれだけ正確にデータを分類できているかの確認もしています。<br>最終的に、モデルの予測結果と実際の結果を比較し、モデルの性能を評価するための準備が整いました。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "jKVuvehJWFqf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHFlW842Ubtm"
      },
      "source": [
        "## 8. 学習・検証データに対する精度評価\n",
        "学習・検証データに対する精度をF1-score、Precision、Recallで評価します。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐️初学者向け解説（F1スコア / 精度（precision） / 再現率（recall））\n",
        "```\n",
        "このコードは、モデルの予測がどれくらい正確かをF1スコア、精度（precision）、再現率（recall）という3つの指標で評価しています。\n",
        "まずは、これらの指標について簡単に説明します。\n",
        "\n",
        "・F1スコア\n",
        "F1スコアは、精度と再現率のバランスを取った指標です。どちらか一方が高くても、もう一方が低いとモデルの性能が十分ではないので、\n",
        "両方のバランスを考慮して評価するのがF1スコアです。値が1に近いほど良いモデルを意味します。\n",
        "\n",
        "・精度（precision）\n",
        "精度は、モデルが「正しい」と予測したものの中で、本当に正しかったものの割合です。\n",
        "たとえば、100回予測して50回「正しい」と予測したけど、そのうち40回が本当に正しかった場合、精度は40/50 = 80%です。\n",
        "\n",
        "・再現率（recall）\n",
        "再現率は、実際に正しいものの中で、モデルが「正しい」と予測できた割合です。\n",
        "たとえば、実際には50回正しい答えがあったけど、モデルが40回しか正しく予測できなかった場合、再現率は40/50 = 80%です。\n",
        "```"
      ],
      "metadata": {
        "id": "dV3HHLBr0gXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aeGTHSO5Ubtm"
      },
      "outputs": [],
      "source": [
        "# 学習データに対する精度の算出（F1スコア、精度、再現率を計算）\n",
        "train_f1, train_prec, train_recall = get_f1(\n",
        "    true_labels_list=train_true_classes,  # 学習データの正解クラスのリストを指定\n",
        "    predictions_list=train_pred_classes,  # 学習データに対するモデルの予測結果のリストを指定\n",
        "    average_method='weighted',  # 各クラスの重要度に応じて平均を取る方法を指定（クラスの不均衡がある場合に有効）\n",
        ")\n",
        "\n",
        "# 検証データに対する精度の算出（F1スコア、精度、再現率を計算）\n",
        "valid_f1, valid_prec, valid_recall = get_f1(\n",
        "    true_labels_list=valid_true_classes,  # 検証データの正解クラスのリストを指定\n",
        "    predictions_list=valid_pred_classes,  # 検証データに対するモデルの予測結果のリストを指定\n",
        "    average_method='weighted',  # 各クラスの重要度に応じて平均を取る方法を指定（クラスの不均衡がある場合に有効）\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔔初学者向け次のコード解説\n",
        "```\n",
        "このコードは、左からそれぞれ前のコードで算出した学習データと検証データのF1スコア、精度、再現率を表示します。\n",
        "\n",
        "表示する際に、数値を小数点以下2桁まででそろえて、学習データ（勉強したデータ）と検証データ（テストデータ）の結果が見やすくなるようにしています。\n",
        "これにより、学習結果とテスト結果を簡単に比較できます。\n",
        "```"
      ],
      "metadata": {
        "id": "c_uMUb2_1Qrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jlq2ugpcUbtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20174908-81ee-45c0-cdc8-5e410e469900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score:      0.85           0.85           \n",
            "Precision:     0.88           0.88           \n",
            "Recall:        0.85           0.85           \n"
          ]
        }
      ],
      "source": [
        "# 精度表示\n",
        "print('{:15}{:<15.2f}{:<15.2f}'.format('F1-score:', train_f1, valid_f1))\n",
        "print('{:15}{:<15.2f}{:<15.2f}'.format('Precision:', train_prec, valid_prec))\n",
        "print('{:15}{:<15.2f}{:<15.2f}'.format('Recall:', train_recall, valid_recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####学習データと検証データに対して、F1スコア、精度、再現率を計算し、それぞれの結果を表示しました。<br>これにより、モデルが学習データと検証データに対してどれだけ正確に予測できたかを比較することができ、<br>モデルのパフォーマンスを総合的に評価することができます。<br>次のセクションに進みましょう。\n",
        "---"
      ],
      "metadata": {
        "id": "6x1FOgfKXOb5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naWyl3-tUbtm"
      },
      "source": [
        "## 9. 提出ファイルの出力\n",
        "テストデータに対して良否判定を行い、その結果を提出フォーマットであるtsv形式で出力を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uEmwgxkRUbtn"
      },
      "outputs": [],
      "source": [
        "# Kerasの画像前処理ユーティリティをインポートする\n",
        "# これにより、画像の読み込みやサイズ変更、データ拡張（オーギュメンテーション）などを簡単に行うことができる。\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# ファイル名やパスのパターンマッチングを行うための標準ライブラリをインポートする\n",
        "# 例えば、特定のフォルダ内のすべての画像ファイル（.jpgや.png）を取得したいときに便利。\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "U2dOfSFyUbtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7dc3d9e-ca59-4d5e-a7ff-55d0c31c07bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bridge': 0, 'horn': 1, 'potato': 2, 'regular': 3}\n"
          ]
        }
      ],
      "source": [
        "# 分類とラベル（どの番号がどのクラスか）の対応を確認する\n",
        "label_map = (train_generator.class_indices)\n",
        "print(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VN4yUt_MUbtn",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39f3302-fc94-44a9-95d0-9e97254fe4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n"
          ]
        }
      ],
      "source": [
        "# テストデータに対して1つずつ予測し、ファイル名と判定結果をリストに保存する\n",
        "file_list = []  # 予測したファイル名を保存するリスト\n",
        "pred_list = []  # 予測結果を保存するリスト\n",
        "\n",
        "# テストデータのディレクトリ内のすべてのファイルに対して処理を行う\n",
        "for file in glob.glob(test_data_dir + '/*'):\n",
        "    image_data = file  # 現在処理しているファイルのパスを取得\n",
        "    filename = file.split('/')[-1]  # ファイル名を取得（パスからファイル名だけを取り出す）\n",
        "\n",
        "    # 画像を指定されたデータ形式に変換する\n",
        "    img = image.load_img(image_data, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    #x = x / 255\n",
        "\n",
        "    # モデルを使って予測を行い、結果を取得する\n",
        "    pred = model.predict(x)[0]\n",
        "\n",
        "    # 予測結果の中で最も高い確率を持つクラス（ラベル）を選ぶ\n",
        "    judge = np.argmax(pred)\n",
        "\n",
        "    # 予測結果を良品（'0'）か不良（'1'）に変換する\n",
        "    # *bridge, horn, potatoを不良（'1'）に、regularを良品（'0'）に変換する\n",
        "    # この条件分岐は、前に確認した「分類とラベルの対応確認」セルの結果を参考にして調整する\n",
        "    if judge == 0:\n",
        "        judge = 1  # クラス0（例えばbridge）は不良品と判定\n",
        "    elif judge == 1:\n",
        "        judge = 1  # クラス1（例えばhorn）も不良品と判定\n",
        "    elif judge == 2:\n",
        "        judge = 1  # クラス2（例えばpotato）も不良品と判定\n",
        "    else:\n",
        "        judge = 0  # それ以外のクラス（例えばregular）は良品と判定\n",
        "\n",
        "    # 判定結果とファイル名をそれぞれリストに追加する\n",
        "    pred_list.append(judge)\n",
        "    file_list.append(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####分類とラベルの対応を確認することで、モデルがどのクラスに対してどのラベルを使っているかを理解できました。<br>そして、テストデータの各画像に対して予測を行うことで、その画像が「良品」か「不良品」かを判断し、結果をリストに保存できました。\n",
        "---"
      ],
      "metadata": {
        "id": "bUhBlpTvXrU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "d_1242zKUbtn"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "now = datetime.now()\n",
        "\n",
        "# ファイル名と予測結果をDataFrameに変換\n",
        "#判別結果をDataFrameに変換し、tsvファイルに出力\n",
        "df = pd.DataFrame([file_list, pred_list]).T\n",
        "df.to_csv(f'/content/drive/MyDrive/DXQuest_PBL02/ID100822_PBL02_ver{now:%Y%m%d%H%M%S}.tsv',\n",
        "         index=False,\n",
        "         header=False,\n",
        "         sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61500593-bacd-43cc-eea6-680bd4f4e3a9",
        "id": "5rLKtV0ufMj6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model...\n"
          ]
        }
      ],
      "source": [
        "# weightファイルの読み込み\n",
        "print('load model...')\n",
        "\n",
        "def load_models(save_weights_paths):\n",
        "  models = []\n",
        "  for save_weights_path in save_weights_paths:\n",
        "    model = gen_model()\n",
        "    model.load_weights(save_weights_path)\n",
        "    models.append(model)\n",
        "  return models\n",
        "\n",
        "save_weights_paths = [os.path.join(weight_dir, f'weights.weights_{ix}_effb6_mix_v2.h5') for ix in range(8)]\n",
        "models = load_models(save_weights_paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_predict(model,dir):\n",
        "  file_list = []  # 予測したファイル名を保存するリスト\n",
        "  pred_list = []  # 予測結果を保存するリスト\n",
        "\n",
        "  # テストデータのディレクトリ内のすべてのファイルに対して処理を行う\n",
        "  for file in sorted(glob.glob(dir + '/*')):\n",
        "      image_data = file  # 現在処理しているファイルのパスを取得\n",
        "      filename = file.split('/')[-1]  # ファイル名を取得（パスからファイル名だけを取り出す）\n",
        "\n",
        "      # 画像を指定されたデータ形式に変換する\n",
        "      img = image.load_img(image_data, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
        "      x = image.img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      #x = x / 255\n",
        "\n",
        "      # モデルを使って予測を行い、結果を取得する\n",
        "      pred = model.predict(x)[0]\n",
        "\n",
        "      # 予測結果の中で最も高い確率を持つクラス（ラベル）を選ぶ\n",
        "      judge = np.argmax(pred)\n",
        "\n",
        "      # 予測結果を良品（'0'）か不良（'1'）に変換する\n",
        "      # *bridge, horn, potatoを不良（'1'）に、regularを良品（'0'）に変換する\n",
        "      # この条件分岐は、前に確認した「分類とラベルの対応確認」セルの結果を参考にして調整する\n",
        "      if judge == 0:\n",
        "          judge = 1  # クラス0（例えばbridge）は不良品と判定\n",
        "      elif judge == 1:\n",
        "          judge = 1  # クラス1（例えばhorn）も不良品と判定\n",
        "      elif judge == 2:\n",
        "          judge = 1  # クラス2（例えばpotato）も不良品と判定\n",
        "      else:\n",
        "          judge = 0  # それ以外のクラス（例えばregular）は良品と判定\n",
        "\n",
        "      # 判定結果とファイル名をそれぞれリストに追加する\n",
        "      pred_list.append(judge)\n",
        "      file_list.append(filename)\n",
        "  return pd.DataFrame({'key':file_list, 'value':pred_list})"
      ],
      "metadata": {
        "id": "50mMRuKLR4MF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_dir = '/content/drive/MyDrive/DXQuest_PBL02/test_conv'\n",
        "df_all = pd.DataFrame()\n",
        "for ix, model in enumerate(models):\n",
        "  df = test_predict(model,test_data_dir)\n",
        "  df_all[ix] = df['value'].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Fj_QSxmjcR",
        "outputId": "cae4cfb1-b69f-4cbd-83a1-f070651aa20d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 8s 8s/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "df_all.to_csv(f'/content/drive/MyDrive/DXQuest_PBL02/PBL02_sample_code_effb6_mix_v2_conv.csv')\n",
        "\n",
        "now = datetime.now()\n",
        "pred_list = list(df_all.apply(lambda x:np.mean(x)>=0.5, axis=1).astype(int))\n",
        "file_list = list(df['key'].values)\n",
        "df_sub = pd.DataFrame([file_list, pred_list]).T\n",
        "\n",
        "submit_file = f'/content/drive/MyDrive/DXQuest_PBL02/ID100822_PBL02_ver{now:%Y%m%d%H%M%S}.tsv'\n",
        "print(submit_file)\n",
        "df_sub.to_csv(submit_file,\n",
        "         index=False,\n",
        "         header=False,\n",
        "         sep='\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a9f41f-104a-4d22-960d-11cdb99cc851",
        "id": "xnK9ADc8fojs"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DXQuest_PBL02/ID100822_PBL02_ver20240929072217.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_dir = '/content/drive/MyDrive/DXQuest_PBL02/test'\n",
        "df_all = pd.DataFrame()\n",
        "for ix, model in enumerate(models):\n",
        "  df = test_predict(model,test_data_dir)\n",
        "  df_all[ix] = df['value'].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afffc297-0ae4-41ef-c554-0e58ab1a0ffb",
        "id": "NihgEnx2qOPG"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 303ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "df_all.to_csv(f'/content/drive/MyDrive/DXQuest_PBL02/PBL02_sample_code_effb6_mix_v2.csv')\n",
        "\n",
        "now = datetime.now()\n",
        "pred_list = list(df_all.apply(lambda x:np.mean(x)>=0.5, axis=1).astype(int))\n",
        "file_list = list(df['key'].values)\n",
        "df_sub = pd.DataFrame([file_list, pred_list]).T\n",
        "\n",
        "submit_file = f'/content/drive/MyDrive/DXQuest_PBL02/ID100822_PBL02_ver{now:%Y%m%d%H%M%S}.tsv'\n",
        "print(submit_file)\n",
        "df_sub.to_csv(submit_file,\n",
        "         index=False,\n",
        "         header=False,\n",
        "         sep='\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f05dbb4-c72e-4c25-a96a-c9c071d3250e",
        "id": "AMW4GvGKqSSY"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DXQuest_PBL02/ID100822_PBL02_ver20240929073005.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#####予測結果が格納されたCSVファイルを「IDXXXXXX_PBL02_verXX.tsv」という名前で保存することができました。<br>ファイルを識別するためにファイル名を変更しておきましょう。<br>(例：ID123456_PBL02_ver1.tsv)<br>まだこれまでに一度も提出していない方は、こちらのファイルを一回目の投稿としてAIモデル精度評価サイトに提出しましょう。<br>\n",
        "---\n",
        "\n",
        "###AIモデル精度評価サイト　https://pbl-eval.life-is-tech.com/"
      ],
      "metadata": {
        "id": "-KxZ1xWAeMbU"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}